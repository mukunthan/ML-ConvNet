{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt01034\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (6,18,29,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Finalplfam_id_Multilabel_Ecoli_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y=df[['ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole']]\n",
    "droppeddf=df.drop(columns=['genome_id', 'genome_name', 'taxon_id', 'ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole'])\n",
    "X=droppeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seeds so that we get the same initialization across different trials\n",
    "seed_numpy = 1989\n",
    "seed_tensorflow = 1989\n",
    "seed_value=1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycnt=Y\n",
    "Ycnt=Ycnt.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ampicillin  amoxicillin_clavulanic_acid  cefoxitin  ceftriaxone  \\\n",
      "1.0         1395                          700        199          247   \n",
      "-1.0         826                          641       2180         2287   \n",
      "0.0          550                         1378        363          239   \n",
      "0.5            4                           56         33            2   \n",
      "\n",
      "      chloramphenicol  ciprofloxacin  gentamicin  streptomycin  tetracycline  \\\n",
      "1.0               121            635         335           130           267   \n",
      "-1.0             2424            808         810          2545          2356   \n",
      "0.0               225           1305        1583            86           146   \n",
      "0.5                 5             27          47            14             1   \n",
      "\n",
      "      trimethoprim_sulphamethoxazole  ...  tigecycline  cefazolin  aztreonam  \\\n",
      "1.0                              242  ...            2        186        104   \n",
      "-1.0                            2373  ...         1616       2499       2274   \n",
      "0.0                              151  ...         1138         69        383   \n",
      "0.5                                9  ...            2         21         14   \n",
      "\n",
      "      cefuroxime  tobramycin  trimethoprim  amoxicillin  colistin  \\\n",
      "1.0        362.0         232           366          558        26   \n",
      "-1.0      1371.0        1868          2013         1800      2561   \n",
      "0.0       1042.0         641           393          398       101   \n",
      "0.5          NaN          34             3           19        12   \n",
      "\n",
      "      norfloxacin  sulfamethoxazole  \n",
      "1.0            37             111.0  \n",
      "-1.0         2616            2616.0  \n",
      "0.0           118              48.0  \n",
      "0.5             4               NaN  \n",
      "\n",
      "[4 rows x 32 columns]\n",
      "0.6891216216216216\n"
     ]
    }
   ],
   "source": [
    "###Data distribution check\n",
    "nancnt=0\n",
    "for index, label in enumerate(labels):\n",
    "    V= Ycnt[label].value_counts()\n",
    "    if(index==0):\n",
    "        df_val_counts = pd.DataFrame(V)\n",
    "    else:\n",
    "        df_val_counts_t = pd.DataFrame(V)\n",
    "        df_val_counts = df_val_counts.join(df_val_counts_t)\n",
    "    \n",
    "    nancnt=nancnt+V[-1.0]\n",
    "        \n",
    "print (df_val_counts)\n",
    "df_val_counts.to_csv('Input_Label_Supplementry.csv')\n",
    "print(nancnt/(Y.shape[1]*Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2775, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "nan_mat = np.random.random(Y.shape)<0.3  ### Update to 06 to get more missing labels\n",
    "nan_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False,  True],\n",
       "       [False, False,  True, ...,  True,  True, False],\n",
       "       [False,  True,  True, ..., False, False,  True],\n",
       "       ...,\n",
       "       [ True, False,  True, ...,  True, False, False],\n",
       "       [False, False, False, ..., False,  True,  True],\n",
       "       [ True, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.mask(nan_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycnt=Y\n",
    "Ycnt=Ycnt.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ampicillin</th>\n",
       "      <th>amoxicillin_clavulanic_acid</th>\n",
       "      <th>cefoxitin</th>\n",
       "      <th>ceftriaxone</th>\n",
       "      <th>chloramphenicol</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>gentamicin</th>\n",
       "      <th>streptomycin</th>\n",
       "      <th>tetracycline</th>\n",
       "      <th>trimethoprim_sulphamethoxazole</th>\n",
       "      <th>...</th>\n",
       "      <th>tigecycline</th>\n",
       "      <th>cefazolin</th>\n",
       "      <th>aztreonam</th>\n",
       "      <th>cefuroxime</th>\n",
       "      <th>tobramycin</th>\n",
       "      <th>trimethoprim</th>\n",
       "      <th>amoxicillin</th>\n",
       "      <th>colistin</th>\n",
       "      <th>norfloxacin</th>\n",
       "      <th>sulfamethoxazole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2775 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ampicillin  amoxicillin_clavulanic_acid  cefoxitin  ceftriaxone  \\\n",
       "1            1.0                         -1.0       -1.0         -1.0   \n",
       "2            1.0                         -1.0       -1.0         -1.0   \n",
       "3            1.0                         -1.0       -1.0         -1.0   \n",
       "4            0.0                         -1.0        0.0         -1.0   \n",
       "5           -1.0                         -1.0       -1.0         -1.0   \n",
       "...          ...                          ...        ...          ...   \n",
       "2771        -1.0                         -1.0       -1.0         -1.0   \n",
       "2772         1.0                         -1.0       -1.0         -1.0   \n",
       "2773        -1.0                          1.0       -1.0         -1.0   \n",
       "2774        -1.0                         -1.0       -1.0         -1.0   \n",
       "2775        -1.0                         -1.0        1.0         -1.0   \n",
       "\n",
       "      chloramphenicol  ciprofloxacin  gentamicin  streptomycin tetracycline  \\\n",
       "1                 0.0            0.0         0.0           1.0          1.0   \n",
       "2                -1.0           -1.0         0.0          -1.0           -1   \n",
       "3                -1.0           -1.0        -1.0          -1.0          1.0   \n",
       "4                -1.0            0.0        -1.0          -1.0           -1   \n",
       "5                -1.0            0.0         0.0          -1.0           -1   \n",
       "...               ...            ...         ...           ...          ...   \n",
       "2771             -1.0           -1.0        -1.0          -1.0           -1   \n",
       "2772             -1.0           -1.0        -1.0          -1.0           -1   \n",
       "2773             -1.0           -1.0        -1.0          -1.0           -1   \n",
       "2774             -1.0           -1.0        -1.0          -1.0          0.0   \n",
       "2775             -1.0            1.0        -1.0          -1.0           -1   \n",
       "\n",
       "      trimethoprim_sulphamethoxazole  ...  tigecycline cefazolin  aztreonam  \\\n",
       "1                               -1.0  ...           -1      -1.0       -1.0   \n",
       "2                               -1.0  ...           -1      -1.0       -1.0   \n",
       "3                               -1.0  ...           -1      -1.0       -1.0   \n",
       "4                               -1.0  ...          0.0      -1.0        0.0   \n",
       "5                               -1.0  ...          0.0      -1.0       -1.0   \n",
       "...                              ...  ...          ...       ...        ...   \n",
       "2771                            -1.0  ...           -1      -1.0       -1.0   \n",
       "2772                            -1.0  ...           -1      -1.0       -1.0   \n",
       "2773                            -1.0  ...           -1      -1.0       -1.0   \n",
       "2774                            -1.0  ...           -1      -1.0       -1.0   \n",
       "2775                            -1.0  ...           -1      -1.0       -1.0   \n",
       "\n",
       "      cefuroxime  tobramycin  trimethoprim  amoxicillin  colistin  \\\n",
       "1           -1.0         0.0           1.0         -1.0        -1   \n",
       "2            0.0         1.0           1.0         -1.0        -1   \n",
       "3           -1.0        -1.0           1.0         -1.0       1.0   \n",
       "4           -1.0         0.0           0.0         -1.0        -1   \n",
       "5            0.0        -1.0          -1.0         -1.0        -1   \n",
       "...          ...         ...           ...          ...       ...   \n",
       "2771        -1.0        -1.0          -1.0          1.0        -1   \n",
       "2772        -1.0        -1.0          -1.0          1.0        -1   \n",
       "2773        -1.0        -1.0          -1.0         -1.0        -1   \n",
       "2774        -1.0        -1.0          -1.0         -1.0        -1   \n",
       "2775        -1.0        -1.0          -1.0         -1.0       0.0   \n",
       "\n",
       "      norfloxacin  sulfamethoxazole  \n",
       "1             0.0              -1.0  \n",
       "2            -1.0              -1.0  \n",
       "3            -1.0              -1.0  \n",
       "4            -1.0              -1.0  \n",
       "5            -1.0              -1.0  \n",
       "...           ...               ...  \n",
       "2771         -1.0              -1.0  \n",
       "2772         -1.0              -1.0  \n",
       "2773         -1.0              -1.0  \n",
       "2774         -1.0              -1.0  \n",
       "2775         -1.0              -1.0  \n",
       "\n",
       "[2775 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ycnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ampicillin  amoxicillin_clavulanic_acid  cefoxitin  ceftriaxone  \\\n",
      "-1.0        1426                         1347       2358         2416   \n",
      "1.0          976                          468        137          189   \n",
      "0.0          371                          925        258          169   \n",
      "0.5            2                           35         22            1   \n",
      "\n",
      "      chloramphenicol  ciprofloxacin  gentamicin  streptomycin  tetracycline  \\\n",
      "-1.0             2535           1404        1403          2598          2498   \n",
      "1.0                88            446         238           104           170   \n",
      "0.0               150            905        1100            67           101   \n",
      "0.5                 2             20          34             6             1   \n",
      "\n",
      "      trimethoprim_sulphamethoxazole  ...  tigecycline  cefazolin  aztreonam  \\\n",
      "-1.0                            2494  ...         1950       2580       2407   \n",
      "1.0                              172  ...            1        133         82   \n",
      "0.0                              103  ...          810         48        277   \n",
      "0.5                                6  ...            2         14          9   \n",
      "\n",
      "      cefuroxime  tobramycin  trimethoprim  amoxicillin  colistin  \\\n",
      "-1.0      1768.0        2109          2241         2087      2640   \n",
      "1.0        266.0         173           250          406        19   \n",
      "0.0        741.0         471           283          268        63   \n",
      "0.5          NaN          22             1           14         8   \n",
      "\n",
      "      norfloxacin  sulfamethoxazole  \n",
      "-1.0         2661            2659.0  \n",
      "1.0            27              87.0  \n",
      "0.0            84              29.0  \n",
      "0.5             3               NaN  \n",
      "\n",
      "[4 rows x 32 columns]\n",
      "0.7821734234234234\n"
     ]
    }
   ],
   "source": [
    "###Data distribution check\n",
    "nancnt=0\n",
    "for index, label in enumerate(labels):\n",
    "    V= Ycnt[label].value_counts()\n",
    "    if(index==0):\n",
    "        df_val_counts = pd.DataFrame(V)\n",
    "    else:\n",
    "        df_val_counts_t = pd.DataFrame(V)\n",
    "        df_val_counts = df_val_counts.join(df_val_counts_t)\n",
    "    \n",
    "    nancnt=nancnt+V[-1.0]\n",
    "        \n",
    "print (df_val_counts)\n",
    "df_val_counts.to_csv('../output/Input_Label_0.3_Supplementry.csv')\n",
    "print(nancnt/(Y.shape[1]*Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(seed_numpy)\n",
    "tf.compat.v1.random.set_random_seed(seed_tensorflow)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2775, 16345)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train_features, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(1000, activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(256, activation='relu'), #LeakyReLU\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(64, activation='relu'), #LeakyReLU\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(32, activation='sigmoid',bias_initializer=output_bias),# activation='softmax' don;t use softmax\n",
    "  ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metric(history, labels, n,metrics):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "  for metric in metrics:\n",
    "        plt.semilogy(history.epoch, history.history[metric],\n",
    "                color=colors[n], label='Train '+labels[n])\n",
    "        plt.semilogy(history.epoch, history.history['val_'+metric],\n",
    "                color=colors[n], label='Val '+labels[n],\n",
    "                linestyle=\"--\")\n",
    "        n=n+1\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Metrics')\n",
    "\n",
    "  plt.legend()\n",
    "  plt.savefig('../output/'+'Plot_masked_'.join(labels)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_value=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true, y_pred):\n",
    "    dtype = K.floatx()\n",
    "    total = K.sum(K.cast(K.not_equal(y_true, mask_value), dtype))\n",
    "    #total=K.cast(len(y_true),dtype)\n",
    "    correct = K.sum(K.cast(K.equal(y_true, K.round(y_pred)), dtype))\n",
    "    #print(correct,total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss_function(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    #print(mask)\n",
    "    return K.binary_crossentropy(y_true * mask, y_pred * mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_f1(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred*mask, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true*mask, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred *mask, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred*mask, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_precision(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred *mask, 0, 1)))\n",
    "    Pred_Positives = K.sum(K.round(K.clip(y_pred*mask, 0, 1)))\n",
    "\n",
    "    precision = TP / (Pred_Positives+K.epsilon())\n",
    "    return precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_recall(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred*mask, 0, 1)))\n",
    "    Positives = K.sum(K.round(K.clip(y_true*mask, 0, 1)))\n",
    "\n",
    "    recall = TP / (Positives+K.epsilon())    \n",
    "    return recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      #tf.keras.metrics.TruePositives(name='tp'),\n",
    "      #tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      #tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      #tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      masked_accuracy,\n",
    "      masked_precision,\n",
    "      masked_recall,\n",
    "      masked_f1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_masked_accuracy', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ampicillin</th>\n",
       "      <th>amoxicillin_clavulanic_acid</th>\n",
       "      <th>cefoxitin</th>\n",
       "      <th>ceftriaxone</th>\n",
       "      <th>chloramphenicol</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>gentamicin</th>\n",
       "      <th>streptomycin</th>\n",
       "      <th>tetracycline</th>\n",
       "      <th>trimethoprim_sulphamethoxazole</th>\n",
       "      <th>...</th>\n",
       "      <th>tigecycline</th>\n",
       "      <th>cefazolin</th>\n",
       "      <th>aztreonam</th>\n",
       "      <th>cefuroxime</th>\n",
       "      <th>tobramycin</th>\n",
       "      <th>trimethoprim</th>\n",
       "      <th>amoxicillin</th>\n",
       "      <th>colistin</th>\n",
       "      <th>norfloxacin</th>\n",
       "      <th>sulfamethoxazole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2775 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ampicillin  amoxicillin_clavulanic_acid  cefoxitin  ceftriaxone  \\\n",
       "1            1.0                          NaN        NaN          NaN   \n",
       "2            1.0                          NaN        NaN          NaN   \n",
       "3            1.0                          NaN        NaN          NaN   \n",
       "4            0.0                          NaN        0.0          NaN   \n",
       "5            NaN                          NaN        NaN          NaN   \n",
       "...          ...                          ...        ...          ...   \n",
       "2771         NaN                          NaN        NaN          NaN   \n",
       "2772         1.0                          NaN        NaN          NaN   \n",
       "2773         NaN                          1.0        NaN          NaN   \n",
       "2774         NaN                          NaN        NaN          NaN   \n",
       "2775         NaN                          NaN        1.0          NaN   \n",
       "\n",
       "      chloramphenicol  ciprofloxacin  gentamicin  streptomycin tetracycline  \\\n",
       "1                 0.0            0.0         0.0           1.0          1.0   \n",
       "2                 NaN            NaN         0.0           NaN          NaN   \n",
       "3                 NaN            NaN         NaN           NaN          1.0   \n",
       "4                 NaN            0.0         NaN           NaN          NaN   \n",
       "5                 NaN            0.0         0.0           NaN          NaN   \n",
       "...               ...            ...         ...           ...          ...   \n",
       "2771              NaN            NaN         NaN           NaN          NaN   \n",
       "2772              NaN            NaN         NaN           NaN          NaN   \n",
       "2773              NaN            NaN         NaN           NaN          NaN   \n",
       "2774              NaN            NaN         NaN           NaN          0.0   \n",
       "2775              NaN            1.0         NaN           NaN          NaN   \n",
       "\n",
       "      trimethoprim_sulphamethoxazole  ...  tigecycline cefazolin  aztreonam  \\\n",
       "1                                NaN  ...          NaN       NaN        NaN   \n",
       "2                                NaN  ...          NaN       NaN        NaN   \n",
       "3                                NaN  ...          NaN       NaN        NaN   \n",
       "4                                NaN  ...          0.0       NaN        0.0   \n",
       "5                                NaN  ...          0.0       NaN        NaN   \n",
       "...                              ...  ...          ...       ...        ...   \n",
       "2771                             NaN  ...          NaN       NaN        NaN   \n",
       "2772                             NaN  ...          NaN       NaN        NaN   \n",
       "2773                             NaN  ...          NaN       NaN        NaN   \n",
       "2774                             NaN  ...          NaN       NaN        NaN   \n",
       "2775                             NaN  ...          NaN       NaN        NaN   \n",
       "\n",
       "      cefuroxime  tobramycin  trimethoprim  amoxicillin  colistin  \\\n",
       "1            NaN         0.0           1.0          NaN       NaN   \n",
       "2            0.0         1.0           1.0          NaN       NaN   \n",
       "3            NaN         NaN           1.0          NaN       1.0   \n",
       "4            NaN         0.0           0.0          NaN       NaN   \n",
       "5            0.0         NaN           NaN          NaN       NaN   \n",
       "...          ...         ...           ...          ...       ...   \n",
       "2771         NaN         NaN           NaN          1.0       NaN   \n",
       "2772         NaN         NaN           NaN          1.0       NaN   \n",
       "2773         NaN         NaN           NaN          NaN       NaN   \n",
       "2774         NaN         NaN           NaN          NaN       NaN   \n",
       "2775         NaN         NaN           NaN          NaN       0.0   \n",
       "\n",
       "      norfloxacin  sulfamethoxazole  \n",
       "1             0.0               NaN  \n",
       "2             NaN               NaN  \n",
       "3             NaN               NaN  \n",
       "4             NaN               NaN  \n",
       "5             NaN               NaN  \n",
       "...           ...               ...  \n",
       "2771          NaN               NaN  \n",
       "2772          NaN               NaN  \n",
       "2773          NaN               NaN  \n",
       "2774          NaN               NaN  \n",
       "2775          NaN               NaN  \n",
       "\n",
       "[2775 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 4s 46ms/step - loss: 0.2071 - masked_accuracy: 0.6153 - masked_precision: 0.4042 - masked_recall: 0.4982 - masked_f1: 0.4408 - val_loss: 0.1352 - val_masked_accuracy: 0.7147 - val_masked_precision: 0.5885 - val_masked_recall: 0.4102 - val_masked_f1: 0.4759\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1264 - masked_accuracy: 0.6847 - masked_precision: 0.4936 - masked_recall: 0.4967 - masked_f1: 0.4907 - val_loss: 0.1186 - val_masked_accuracy: 0.7540 - val_masked_precision: 0.6433 - val_masked_recall: 0.5308 - val_masked_f1: 0.5772\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1139 - masked_accuracy: 0.7253 - masked_precision: 0.5654 - masked_recall: 0.4749 - masked_f1: 0.5115 - val_loss: 0.1111 - val_masked_accuracy: 0.7318 - val_masked_precision: 0.6590 - val_masked_recall: 0.3580 - val_masked_f1: 0.4573\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1095 - masked_accuracy: 0.7361 - masked_precision: 0.6011 - masked_recall: 0.4498 - masked_f1: 0.5112 - val_loss: 0.1047 - val_masked_accuracy: 0.7521 - val_masked_precision: 0.7250 - val_masked_recall: 0.3801 - val_masked_f1: 0.4932\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1042 - masked_accuracy: 0.7519 - masked_precision: 0.6241 - masked_recall: 0.5016 - masked_f1: 0.5494 - val_loss: 0.1019 - val_masked_accuracy: 0.7584 - val_masked_precision: 0.6765 - val_masked_recall: 0.4814 - val_masked_f1: 0.5578\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1024 - masked_accuracy: 0.7606 - masked_precision: 0.6499 - masked_recall: 0.4917 - masked_f1: 0.5551 - val_loss: 0.0999 - val_masked_accuracy: 0.7620 - val_masked_precision: 0.7492 - val_masked_recall: 0.3999 - val_masked_f1: 0.5185\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0951 - masked_accuracy: 0.7690 - masked_precision: 0.6788 - masked_recall: 0.4856 - masked_f1: 0.5625 - val_loss: 0.0952 - val_masked_accuracy: 0.7717 - val_masked_precision: 0.7367 - val_masked_recall: 0.4501 - val_masked_f1: 0.5573\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0923 - masked_accuracy: 0.7842 - masked_precision: 0.6841 - masked_recall: 0.5635 - masked_f1: 0.6131 - val_loss: 0.0987 - val_masked_accuracy: 0.7700 - val_masked_precision: 0.7566 - val_masked_recall: 0.4154 - val_masked_f1: 0.5349\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0946 - masked_accuracy: 0.7722 - masked_precision: 0.6403 - masked_recall: 0.5979 - masked_f1: 0.6140 - val_loss: 0.0915 - val_masked_accuracy: 0.7991 - val_masked_precision: 0.7810 - val_masked_recall: 0.5217 - val_masked_f1: 0.6238\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0940 - masked_accuracy: 0.7672 - masked_precision: 0.6417 - masked_recall: 0.5743 - masked_f1: 0.6002 - val_loss: 0.0924 - val_masked_accuracy: 0.7932 - val_masked_precision: 0.7422 - val_masked_recall: 0.5455 - val_masked_f1: 0.6268\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0945 - masked_accuracy: 0.7651 - masked_precision: 0.6381 - masked_recall: 0.5560 - masked_f1: 0.5904 - val_loss: 0.0932 - val_masked_accuracy: 0.7760 - val_masked_precision: 0.7090 - val_masked_recall: 0.5153 - val_masked_f1: 0.5940\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0917 - masked_accuracy: 0.7699 - masked_precision: 0.6534 - masked_recall: 0.5527 - masked_f1: 0.5944 - val_loss: 0.0916 - val_masked_accuracy: 0.7749 - val_masked_precision: 0.7497 - val_masked_recall: 0.4461 - val_masked_f1: 0.5582\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0926 - masked_accuracy: 0.7719 - masked_precision: 0.6512 - masked_recall: 0.5657 - masked_f1: 0.6007 - val_loss: 0.0891 - val_masked_accuracy: 0.7969 - val_masked_precision: 0.7553 - val_masked_recall: 0.5396 - val_masked_f1: 0.6281\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0911 - masked_accuracy: 0.7722 - masked_precision: 0.6408 - masked_recall: 0.5837 - masked_f1: 0.6077 - val_loss: 0.0910 - val_masked_accuracy: 0.7944 - val_masked_precision: 0.7869 - val_masked_recall: 0.4865 - val_masked_f1: 0.6005\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0834 - masked_accuracy: 0.7919 - masked_precision: 0.6993 - masked_recall: 0.5310 - masked_f1: 0.6006\n",
      "[0.08339234441518784, 0.791854739189148, 0.6992936134338379, 0.5309693217277527, 0.6006021499633789]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2192 - masked_accuracy: 0.6122 - masked_precision: 0.3932 - masked_recall: 0.4804 - masked_f1: 0.4278 - val_loss: 0.1213 - val_masked_accuracy: 0.7190 - val_masked_precision: 0.5284 - val_masked_recall: 0.4753 - val_masked_f1: 0.4973\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1295 - masked_accuracy: 0.6756 - masked_precision: 0.4706 - masked_recall: 0.4553 - masked_f1: 0.4574 - val_loss: 0.1119 - val_masked_accuracy: 0.7459 - val_masked_precision: 0.5914 - val_masked_recall: 0.4660 - val_masked_f1: 0.5184\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1160 - masked_accuracy: 0.7150 - masked_precision: 0.5430 - masked_recall: 0.4404 - masked_f1: 0.4821 - val_loss: 0.0955 - val_masked_accuracy: 0.7478 - val_masked_precision: 0.6102 - val_masked_recall: 0.4229 - val_masked_f1: 0.4962\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1111 - masked_accuracy: 0.7316 - masked_precision: 0.5799 - masked_recall: 0.4491 - masked_f1: 0.5009 - val_loss: 0.0926 - val_masked_accuracy: 0.7689 - val_masked_precision: 0.6608 - val_masked_recall: 0.4446 - val_masked_f1: 0.5301\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1086 - masked_accuracy: 0.7331 - masked_precision: 0.5884 - masked_recall: 0.4131 - masked_f1: 0.4806 - val_loss: 0.0910 - val_masked_accuracy: 0.7689 - val_masked_precision: 0.6694 - val_masked_recall: 0.4215 - val_masked_f1: 0.5138\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1027 - masked_accuracy: 0.7547 - masked_precision: 0.6315 - masked_recall: 0.4826 - masked_f1: 0.5418 - val_loss: 0.0863 - val_masked_accuracy: 0.7995 - val_masked_precision: 0.7251 - val_masked_recall: 0.5227 - val_masked_f1: 0.6054\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0994 - masked_accuracy: 0.7672 - masked_precision: 0.6510 - masked_recall: 0.5092 - masked_f1: 0.5663 - val_loss: 0.0832 - val_masked_accuracy: 0.8204 - val_masked_precision: 0.7140 - val_masked_recall: 0.6574 - val_masked_f1: 0.6810\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0947 - masked_accuracy: 0.7774 - masked_precision: 0.6773 - masked_recall: 0.5206 - masked_f1: 0.5855 - val_loss: 0.0866 - val_masked_accuracy: 0.7822 - val_masked_precision: 0.7500 - val_masked_recall: 0.3962 - val_masked_f1: 0.5155\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0913 - masked_accuracy: 0.7845 - masked_precision: 0.6870 - masked_recall: 0.5404 - masked_f1: 0.5998 - val_loss: 0.0802 - val_masked_accuracy: 0.8183 - val_masked_precision: 0.6955 - val_masked_recall: 0.6929 - val_masked_f1: 0.6909\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0915 - masked_accuracy: 0.7854 - masked_precision: 0.6678 - masked_recall: 0.5836 - masked_f1: 0.6190 - val_loss: 0.0813 - val_masked_accuracy: 0.8121 - val_masked_precision: 0.6694 - val_masked_recall: 0.7338 - val_masked_f1: 0.6970\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0896 - masked_accuracy: 0.7889 - masked_precision: 0.6717 - masked_recall: 0.6019 - masked_f1: 0.6293 - val_loss: 0.0796 - val_masked_accuracy: 0.8136 - val_masked_precision: 0.7367 - val_masked_recall: 0.5809 - val_masked_f1: 0.6452\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0877 - masked_accuracy: 0.7924 - masked_precision: 0.6828 - masked_recall: 0.5998 - masked_f1: 0.6345 - val_loss: 0.0756 - val_masked_accuracy: 0.8347 - val_masked_precision: 0.7249 - val_masked_recall: 0.7130 - val_masked_f1: 0.7164\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0897 - masked_accuracy: 0.7809 - masked_precision: 0.6477 - masked_recall: 0.6192 - masked_f1: 0.6286 - val_loss: 0.0795 - val_masked_accuracy: 0.8269 - val_masked_precision: 0.7021 - val_masked_recall: 0.7199 - val_masked_f1: 0.7084\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0874 - masked_accuracy: 0.7948 - masked_precision: 0.6881 - masked_recall: 0.5914 - masked_f1: 0.6308 - val_loss: 0.0765 - val_masked_accuracy: 0.8248 - val_masked_precision: 0.6897 - val_masked_recall: 0.7360 - val_masked_f1: 0.7094\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0853 - masked_accuracy: 0.7991 - masked_precision: 0.6882 - masked_recall: 0.6260 - masked_f1: 0.6508 - val_loss: 0.0742 - val_masked_accuracy: 0.8262 - val_masked_precision: 0.7429 - val_masked_recall: 0.6314 - val_masked_f1: 0.6779\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0850 - masked_accuracy: 0.7970 - masked_precision: 0.6820 - masked_recall: 0.6236 - masked_f1: 0.6476 - val_loss: 0.0743 - val_masked_accuracy: 0.8273 - val_masked_precision: 0.7010 - val_masked_recall: 0.7203 - val_masked_f1: 0.7081\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0831 - masked_accuracy: 0.8067 - masked_precision: 0.6919 - masked_recall: 0.6547 - masked_f1: 0.6687 - val_loss: 0.0741 - val_masked_accuracy: 0.8445 - val_masked_precision: 0.7863 - val_masked_recall: 0.6497 - val_masked_f1: 0.7075\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0828 - masked_accuracy: 0.8035 - masked_precision: 0.6893 - masked_recall: 0.6470 - masked_f1: 0.6627 - val_loss: 0.0747 - val_masked_accuracy: 0.8282 - val_masked_precision: 0.7275 - val_masked_recall: 0.6686 - val_masked_f1: 0.6932\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0831 - masked_accuracy: 0.7980 - masked_precision: 0.6662 - masked_recall: 0.6681 - masked_f1: 0.6633 - val_loss: 0.0750 - val_masked_accuracy: 0.8262 - val_masked_precision: 0.6945 - val_masked_recall: 0.7349 - val_masked_f1: 0.7124\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0834 - masked_accuracy: 0.8018 - masked_precision: 0.6919 - masked_recall: 0.6396 - masked_f1: 0.6605 - val_loss: 0.0751 - val_masked_accuracy: 0.8287 - val_masked_precision: 0.7668 - val_masked_recall: 0.6056 - val_masked_f1: 0.6741\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0811 - masked_accuracy: 0.8045 - masked_precision: 0.6909 - masked_recall: 0.6480 - masked_f1: 0.6649 - val_loss: 0.0726 - val_masked_accuracy: 0.8378 - val_masked_precision: 0.7454 - val_masked_recall: 0.6784 - val_masked_f1: 0.7078\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0827 - masked_accuracy: 0.7999 - masked_precision: 0.6797 - masked_recall: 0.6416 - masked_f1: 0.6569 - val_loss: 0.0718 - val_masked_accuracy: 0.8382 - val_masked_precision: 0.7401 - val_masked_recall: 0.6931 - val_masked_f1: 0.7125\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0782 - masked_accuracy: 0.8269 - masked_precision: 0.7926 - masked_recall: 0.6269 - masked_f1: 0.6964\n",
      "[0.07817188650369644, 0.826885461807251, 0.7926250696182251, 0.6268783807754517, 0.6963797807693481]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2214 - masked_accuracy: 0.6171 - masked_precision: 0.3910 - masked_recall: 0.4604 - masked_f1: 0.4173 - val_loss: 0.1274 - val_masked_accuracy: 0.6968 - val_masked_precision: 0.5556 - val_masked_recall: 0.4908 - val_masked_f1: 0.5165\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1259 - masked_accuracy: 0.6899 - masked_precision: 0.4911 - masked_recall: 0.4660 - masked_f1: 0.4716 - val_loss: 0.1136 - val_masked_accuracy: 0.7273 - val_masked_precision: 0.6430 - val_masked_recall: 0.4236 - val_masked_f1: 0.5070\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1138 - masked_accuracy: 0.7298 - masked_precision: 0.5677 - masked_recall: 0.4708 - masked_f1: 0.5106 - val_loss: 0.1040 - val_masked_accuracy: 0.7492 - val_masked_precision: 0.6556 - val_masked_recall: 0.5299 - val_masked_f1: 0.5829\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1064 - masked_accuracy: 0.7506 - masked_precision: 0.6135 - masked_recall: 0.4914 - masked_f1: 0.5416 - val_loss: 0.0996 - val_masked_accuracy: 0.7697 - val_masked_precision: 0.6991 - val_masked_recall: 0.5473 - val_masked_f1: 0.6117\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1009 - masked_accuracy: 0.7643 - masked_precision: 0.6323 - masked_recall: 0.5267 - masked_f1: 0.5702 - val_loss: 0.0903 - val_masked_accuracy: 0.7985 - val_masked_precision: 0.7114 - val_masked_recall: 0.6692 - val_masked_f1: 0.6873\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0976 - masked_accuracy: 0.7721 - masked_precision: 0.6482 - masked_recall: 0.5546 - masked_f1: 0.5926 - val_loss: 0.0886 - val_masked_accuracy: 0.8024 - val_masked_precision: 0.6949 - val_masked_recall: 0.7324 - val_masked_f1: 0.7097\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0926 - masked_accuracy: 0.7803 - masked_precision: 0.6688 - masked_recall: 0.5517 - masked_f1: 0.5992 - val_loss: 0.0914 - val_masked_accuracy: 0.7659 - val_masked_precision: 0.7352 - val_masked_recall: 0.4673 - val_masked_f1: 0.5698\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0915 - masked_accuracy: 0.7840 - masked_precision: 0.6666 - masked_recall: 0.5726 - masked_f1: 0.6107 - val_loss: 0.0879 - val_masked_accuracy: 0.7905 - val_masked_precision: 0.7118 - val_masked_recall: 0.6272 - val_masked_f1: 0.6633\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0912 - masked_accuracy: 0.7807 - masked_precision: 0.6580 - masked_recall: 0.5739 - masked_f1: 0.6088 - val_loss: 0.0829 - val_masked_accuracy: 0.8103 - val_masked_precision: 0.7280 - val_masked_recall: 0.6838 - val_masked_f1: 0.7006\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0867 - masked_accuracy: 0.7960 - masked_precision: 0.6871 - masked_recall: 0.6027 - masked_f1: 0.6371 - val_loss: 0.0876 - val_masked_accuracy: 0.7918 - val_masked_precision: 0.7520 - val_masked_recall: 0.5623 - val_masked_f1: 0.6411\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0862 - masked_accuracy: 0.7977 - masked_precision: 0.6805 - masked_recall: 0.6211 - masked_f1: 0.6461 - val_loss: 0.0803 - val_masked_accuracy: 0.8259 - val_masked_precision: 0.7478 - val_masked_recall: 0.7188 - val_masked_f1: 0.7299\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0837 - masked_accuracy: 0.8023 - masked_precision: 0.6940 - masked_recall: 0.6104 - masked_f1: 0.6459 - val_loss: 0.0856 - val_masked_accuracy: 0.7953 - val_masked_precision: 0.7712 - val_masked_recall: 0.5438 - val_masked_f1: 0.6345\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0839 - masked_accuracy: 0.8023 - masked_precision: 0.6807 - masked_recall: 0.6436 - masked_f1: 0.6575 - val_loss: 0.0797 - val_masked_accuracy: 0.8228 - val_masked_precision: 0.7466 - val_masked_recall: 0.7095 - val_masked_f1: 0.7249\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0846 - masked_accuracy: 0.7996 - masked_precision: 0.6962 - masked_recall: 0.5905 - masked_f1: 0.6340 - val_loss: 0.0840 - val_masked_accuracy: 0.7997 - val_masked_precision: 0.7532 - val_masked_recall: 0.5925 - val_masked_f1: 0.6605\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0843 - masked_accuracy: 0.7971 - masked_precision: 0.6923 - masked_recall: 0.5964 - masked_f1: 0.6359 - val_loss: 0.0860 - val_masked_accuracy: 0.7823 - val_masked_precision: 0.7373 - val_masked_recall: 0.5374 - val_masked_f1: 0.6195\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0853 - masked_accuracy: 0.7913 - masked_precision: 0.6772 - masked_recall: 0.5982 - masked_f1: 0.6296 - val_loss: 0.0834 - val_masked_accuracy: 0.8047 - val_masked_precision: 0.7360 - val_masked_recall: 0.6433 - val_masked_f1: 0.6830\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0803 - masked_accuracy: 0.8307 - masked_precision: 0.7295 - masked_recall: 0.6915 - masked_f1: 0.7073\n",
      "[0.0802760124206543, 0.8306983113288879, 0.7294830083847046, 0.6915332674980164, 0.7072795033454895]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.2093 - masked_accuracy: 0.5889 - masked_precision: 0.3676 - masked_recall: 0.4694 - masked_f1: 0.4065 - val_loss: 0.1142 - val_masked_accuracy: 0.7308 - val_masked_precision: 0.5964 - val_masked_recall: 0.4354 - val_masked_f1: 0.4969\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1250 - masked_accuracy: 0.6891 - masked_precision: 0.4911 - masked_recall: 0.4444 - masked_f1: 0.4607 - val_loss: 0.1037 - val_masked_accuracy: 0.7332 - val_masked_precision: 0.6063 - val_masked_recall: 0.4046 - val_masked_f1: 0.4812\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1145 - masked_accuracy: 0.7224 - masked_precision: 0.5552 - masked_recall: 0.4287 - masked_f1: 0.4807 - val_loss: 0.1016 - val_masked_accuracy: 0.7380 - val_masked_precision: 0.6367 - val_masked_recall: 0.3790 - val_masked_f1: 0.4708\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1063 - masked_accuracy: 0.7377 - masked_precision: 0.6003 - masked_recall: 0.4351 - masked_f1: 0.4991 - val_loss: 0.0982 - val_masked_accuracy: 0.7533 - val_masked_precision: 0.6631 - val_masked_recall: 0.4290 - val_masked_f1: 0.5176\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1031 - masked_accuracy: 0.7527 - masked_precision: 0.6312 - masked_recall: 0.4499 - masked_f1: 0.5215 - val_loss: 0.0976 - val_masked_accuracy: 0.7441 - val_masked_precision: 0.6884 - val_masked_recall: 0.3286 - val_masked_f1: 0.4401\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1071 - masked_accuracy: 0.7482 - masked_precision: 0.6170 - masked_recall: 0.4625 - masked_f1: 0.5234 - val_loss: 0.0945 - val_masked_accuracy: 0.7519 - val_masked_precision: 0.6770 - val_masked_recall: 0.4010 - val_masked_f1: 0.4979\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1015 - masked_accuracy: 0.7567 - masked_precision: 0.6446 - masked_recall: 0.4436 - masked_f1: 0.5205 - val_loss: 0.0920 - val_masked_accuracy: 0.7517 - val_masked_precision: 0.6728 - val_masked_recall: 0.4034 - val_masked_f1: 0.5001\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0952 - masked_accuracy: 0.7585 - masked_precision: 0.6627 - masked_recall: 0.4335 - masked_f1: 0.5209 - val_loss: 0.0888 - val_masked_accuracy: 0.7551 - val_masked_precision: 0.6825 - val_masked_recall: 0.4092 - val_masked_f1: 0.5074\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0908 - masked_accuracy: 0.7752 - masked_precision: 0.6764 - masked_recall: 0.4951 - masked_f1: 0.5674 - val_loss: 0.0870 - val_masked_accuracy: 0.7858 - val_masked_precision: 0.6949 - val_masked_recall: 0.5596 - val_masked_f1: 0.6154\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0933 - masked_accuracy: 0.7714 - masked_precision: 0.6456 - masked_recall: 0.5591 - masked_f1: 0.5935 - val_loss: 0.0855 - val_masked_accuracy: 0.8051 - val_masked_precision: 0.7452 - val_masked_recall: 0.5669 - val_masked_f1: 0.6403\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0923 - masked_accuracy: 0.7721 - masked_precision: 0.6379 - masked_recall: 0.5784 - masked_f1: 0.6029 - val_loss: 0.0850 - val_masked_accuracy: 0.8031 - val_masked_precision: 0.7239 - val_masked_recall: 0.5940 - val_masked_f1: 0.6489\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0922 - masked_accuracy: 0.7742 - masked_precision: 0.6469 - masked_recall: 0.5749 - masked_f1: 0.6052 - val_loss: 0.0843 - val_masked_accuracy: 0.7836 - val_masked_precision: 0.7113 - val_masked_recall: 0.5200 - val_masked_f1: 0.5971\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0911 - masked_accuracy: 0.7743 - masked_precision: 0.6474 - masked_recall: 0.5672 - masked_f1: 0.5996 - val_loss: 0.0858 - val_masked_accuracy: 0.7909 - val_masked_precision: 0.7151 - val_masked_recall: 0.5534 - val_masked_f1: 0.6194\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0907 - masked_accuracy: 0.7766 - masked_precision: 0.6417 - masked_recall: 0.5978 - masked_f1: 0.6147 - val_loss: 0.0847 - val_masked_accuracy: 0.7820 - val_masked_precision: 0.7264 - val_masked_recall: 0.4860 - val_masked_f1: 0.5784\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0903 - masked_accuracy: 0.7757 - masked_precision: 0.6544 - masked_recall: 0.5701 - masked_f1: 0.6044 - val_loss: 0.0830 - val_masked_accuracy: 0.7958 - val_masked_precision: 0.7252 - val_masked_recall: 0.5568 - val_masked_f1: 0.6269\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0901 - masked_accuracy: 0.7981 - masked_precision: 0.7482 - masked_recall: 0.5372 - masked_f1: 0.6205\n",
      "[0.09010734409093857, 0.7981090545654297, 0.7482211589813232, 0.5371509194374084, 0.6204988956451416]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2152 - masked_accuracy: 0.5896 - masked_precision: 0.3768 - masked_recall: 0.4969 - masked_f1: 0.4223 - val_loss: 0.1260 - val_masked_accuracy: 0.7273 - val_masked_precision: 0.6184 - val_masked_recall: 0.4220 - val_masked_f1: 0.4983\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1279 - masked_accuracy: 0.6785 - masked_precision: 0.4755 - masked_recall: 0.4425 - masked_f1: 0.4526 - val_loss: 0.1072 - val_masked_accuracy: 0.7410 - val_masked_precision: 0.6892 - val_masked_recall: 0.3775 - val_masked_f1: 0.4836\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1173 - masked_accuracy: 0.7157 - masked_precision: 0.5480 - masked_recall: 0.4158 - masked_f1: 0.4681 - val_loss: 0.0970 - val_masked_accuracy: 0.7493 - val_masked_precision: 0.7015 - val_masked_recall: 0.4064 - val_masked_f1: 0.5099\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1093 - masked_accuracy: 0.7413 - masked_precision: 0.6126 - masked_recall: 0.4169 - masked_f1: 0.4913 - val_loss: 0.0923 - val_masked_accuracy: 0.7779 - val_masked_precision: 0.7403 - val_masked_recall: 0.4832 - val_masked_f1: 0.5828\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1040 - masked_accuracy: 0.7530 - masked_precision: 0.6375 - masked_recall: 0.4478 - masked_f1: 0.5205 - val_loss: 0.0892 - val_masked_accuracy: 0.7718 - val_masked_precision: 0.7339 - val_masked_recall: 0.4607 - val_masked_f1: 0.5639\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1007 - masked_accuracy: 0.7640 - masked_precision: 0.6571 - masked_recall: 0.4808 - masked_f1: 0.5499 - val_loss: 0.0824 - val_masked_accuracy: 0.8001 - val_masked_precision: 0.7357 - val_masked_recall: 0.5989 - val_masked_f1: 0.6591\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0980 - masked_accuracy: 0.7742 - masked_precision: 0.6658 - masked_recall: 0.5186 - masked_f1: 0.5778 - val_loss: 0.0846 - val_masked_accuracy: 0.7887 - val_masked_precision: 0.7831 - val_masked_recall: 0.4778 - val_masked_f1: 0.5905\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0948 - masked_accuracy: 0.7777 - masked_precision: 0.6716 - masked_recall: 0.5222 - masked_f1: 0.5819 - val_loss: 0.0831 - val_masked_accuracy: 0.8038 - val_masked_precision: 0.7732 - val_masked_recall: 0.5552 - val_masked_f1: 0.6441\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0976 - masked_accuracy: 0.7753 - masked_precision: 0.6761 - masked_recall: 0.5209 - masked_f1: 0.5801 - val_loss: 0.0852 - val_masked_accuracy: 0.8035 - val_masked_precision: 0.7043 - val_masked_recall: 0.6825 - val_masked_f1: 0.6911\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0939 - masked_accuracy: 0.7811 - masked_precision: 0.6822 - masked_recall: 0.5243 - masked_f1: 0.5887 - val_loss: 0.0780 - val_masked_accuracy: 0.8185 - val_masked_precision: 0.7644 - val_masked_recall: 0.6372 - val_masked_f1: 0.6933\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0930 - masked_accuracy: 0.7788 - masked_precision: 0.6783 - masked_recall: 0.5208 - masked_f1: 0.5842 - val_loss: 0.0826 - val_masked_accuracy: 0.7983 - val_masked_precision: 0.7526 - val_masked_recall: 0.5647 - val_masked_f1: 0.6428\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0904 - masked_accuracy: 0.7909 - masked_precision: 0.6907 - masked_recall: 0.5636 - masked_f1: 0.6175 - val_loss: 0.0820 - val_masked_accuracy: 0.8150 - val_masked_precision: 0.6971 - val_masked_recall: 0.7626 - val_masked_f1: 0.7255\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0926 - masked_accuracy: 0.7816 - masked_precision: 0.6726 - masked_recall: 0.5565 - masked_f1: 0.6031 - val_loss: 0.0754 - val_masked_accuracy: 0.8212 - val_masked_precision: 0.7372 - val_masked_recall: 0.6980 - val_masked_f1: 0.7139\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0887 - masked_accuracy: 0.7868 - masked_precision: 0.6759 - masked_recall: 0.5699 - masked_f1: 0.6132 - val_loss: 0.0755 - val_masked_accuracy: 0.8222 - val_masked_precision: 0.7695 - val_masked_recall: 0.6439 - val_masked_f1: 0.6978\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0896 - masked_accuracy: 0.7914 - masked_precision: 0.6869 - masked_recall: 0.5841 - masked_f1: 0.6263 - val_loss: 0.0757 - val_masked_accuracy: 0.8219 - val_masked_precision: 0.7298 - val_masked_recall: 0.7196 - val_masked_f1: 0.7218\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0874 - masked_accuracy: 0.7927 - masked_precision: 0.6975 - masked_recall: 0.5727 - masked_f1: 0.6242 - val_loss: 0.0796 - val_masked_accuracy: 0.8056 - val_masked_precision: 0.7832 - val_masked_recall: 0.5537 - val_masked_f1: 0.6463\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0906 - masked_accuracy: 0.7917 - masked_precision: 0.6900 - masked_recall: 0.5784 - masked_f1: 0.6243 - val_loss: 0.0752 - val_masked_accuracy: 0.8201 - val_masked_precision: 0.7472 - val_masked_recall: 0.6730 - val_masked_f1: 0.7048\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0884 - masked_accuracy: 0.7865 - masked_precision: 0.7024 - masked_recall: 0.5239 - masked_f1: 0.5953 - val_loss: 0.0822 - val_masked_accuracy: 0.7938 - val_masked_precision: 0.7690 - val_masked_recall: 0.5134 - val_masked_f1: 0.6126\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0865 - masked_accuracy: 0.7950 - masked_precision: 0.6943 - masked_recall: 0.5813 - masked_f1: 0.6291 - val_loss: 0.0785 - val_masked_accuracy: 0.8117 - val_masked_precision: 0.7799 - val_masked_recall: 0.5818 - val_masked_f1: 0.6642\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0739 - masked_accuracy: 0.8448 - masked_precision: 0.7534 - masked_recall: 0.7129 - masked_f1: 0.7292\n",
      "[0.07390066236257553, 0.8447620868682861, 0.7533760070800781, 0.7129102945327759, 0.7291843891143799]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.2081 - masked_accuracy: 0.5942 - masked_precision: 0.3619 - masked_recall: 0.4332 - masked_f1: 0.3902 - val_loss: 0.1393 - val_masked_accuracy: 0.6851 - val_masked_precision: 0.4819 - val_masked_recall: 0.5311 - val_masked_f1: 0.5023\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1270 - masked_accuracy: 0.6746 - masked_precision: 0.4611 - masked_recall: 0.4289 - masked_f1: 0.4407 - val_loss: 0.1251 - val_masked_accuracy: 0.7455 - val_masked_precision: 0.5797 - val_masked_recall: 0.5794 - val_masked_f1: 0.5772\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1134 - masked_accuracy: 0.7267 - masked_precision: 0.5656 - masked_recall: 0.4510 - masked_f1: 0.4965 - val_loss: 0.1113 - val_masked_accuracy: 0.7496 - val_masked_precision: 0.6478 - val_masked_recall: 0.3879 - val_masked_f1: 0.4811\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1049 - masked_accuracy: 0.7539 - masked_precision: 0.6316 - masked_recall: 0.4521 - masked_f1: 0.5223 - val_loss: 0.1019 - val_masked_accuracy: 0.7740 - val_masked_precision: 0.6626 - val_masked_recall: 0.5342 - val_masked_f1: 0.5868\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1007 - masked_accuracy: 0.7648 - masked_precision: 0.6544 - masked_recall: 0.4714 - masked_f1: 0.5443 - val_loss: 0.0930 - val_masked_accuracy: 0.7839 - val_masked_precision: 0.7014 - val_masked_recall: 0.5070 - val_masked_f1: 0.5840\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0958 - masked_accuracy: 0.7730 - masked_precision: 0.6638 - masked_recall: 0.4913 - masked_f1: 0.5605 - val_loss: 0.0930 - val_masked_accuracy: 0.7850 - val_masked_precision: 0.7489 - val_masked_recall: 0.4381 - val_masked_f1: 0.5499\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0940 - masked_accuracy: 0.7724 - masked_precision: 0.6669 - masked_recall: 0.4977 - masked_f1: 0.5644 - val_loss: 0.0871 - val_masked_accuracy: 0.8095 - val_masked_precision: 0.7537 - val_masked_recall: 0.5593 - val_masked_f1: 0.6403\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0912 - masked_accuracy: 0.7835 - masked_precision: 0.6863 - masked_recall: 0.5276 - masked_f1: 0.5911 - val_loss: 0.0898 - val_masked_accuracy: 0.7924 - val_masked_precision: 0.7455 - val_masked_recall: 0.4837 - val_masked_f1: 0.5839\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0888 - masked_accuracy: 0.7911 - masked_precision: 0.6863 - masked_recall: 0.5656 - masked_f1: 0.6159 - val_loss: 0.0872 - val_masked_accuracy: 0.8063 - val_masked_precision: 0.7702 - val_masked_recall: 0.5244 - val_masked_f1: 0.6203\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0880 - masked_accuracy: 0.7916 - masked_precision: 0.6746 - masked_recall: 0.6085 - masked_f1: 0.6348 - val_loss: 0.0874 - val_masked_accuracy: 0.8118 - val_masked_precision: 0.7293 - val_masked_recall: 0.6043 - val_masked_f1: 0.6573\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0855 - masked_accuracy: 0.7965 - masked_precision: 0.6914 - masked_recall: 0.5869 - masked_f1: 0.6297 - val_loss: 0.0862 - val_masked_accuracy: 0.8229 - val_masked_precision: 0.7041 - val_masked_recall: 0.7247 - val_masked_f1: 0.7128\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0896 - masked_accuracy: 0.7869 - masked_precision: 0.6682 - masked_recall: 0.5973 - masked_f1: 0.6270 - val_loss: 0.0840 - val_masked_accuracy: 0.8299 - val_masked_precision: 0.7274 - val_masked_recall: 0.7006 - val_masked_f1: 0.7122\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0889 - masked_accuracy: 0.7897 - masked_precision: 0.6716 - masked_recall: 0.5998 - masked_f1: 0.6280 - val_loss: 0.0814 - val_masked_accuracy: 0.8321 - val_masked_precision: 0.7315 - val_masked_recall: 0.7029 - val_masked_f1: 0.7152\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0866 - masked_accuracy: 0.7936 - masked_precision: 0.6936 - masked_recall: 0.5762 - masked_f1: 0.6256 - val_loss: 0.0853 - val_masked_accuracy: 0.8258 - val_masked_precision: 0.7129 - val_masked_recall: 0.7163 - val_masked_f1: 0.7130\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0894 - masked_accuracy: 0.7953 - masked_precision: 0.6825 - masked_recall: 0.6009 - masked_f1: 0.6339 - val_loss: 0.0836 - val_masked_accuracy: 0.8318 - val_masked_precision: 0.7462 - val_masked_recall: 0.6644 - val_masked_f1: 0.7015\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0865 - masked_accuracy: 0.7976 - masked_precision: 0.7054 - masked_recall: 0.5725 - masked_f1: 0.6290 - val_loss: 0.0834 - val_masked_accuracy: 0.8298 - val_masked_precision: 0.7228 - val_masked_recall: 0.7120 - val_masked_f1: 0.7162\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0856 - masked_accuracy: 0.8001 - masked_precision: 0.6926 - masked_recall: 0.5918 - masked_f1: 0.6348 - val_loss: 0.0830 - val_masked_accuracy: 0.8279 - val_masked_precision: 0.7681 - val_masked_recall: 0.6149 - val_masked_f1: 0.6811\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0840 - masked_accuracy: 0.8036 - masked_precision: 0.7052 - masked_recall: 0.5980 - masked_f1: 0.6442 - val_loss: 0.0847 - val_masked_accuracy: 0.8251 - val_masked_precision: 0.6946 - val_masked_recall: 0.7550 - val_masked_f1: 0.7218\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0744 - masked_accuracy: 0.8188 - masked_precision: 0.7332 - masked_recall: 0.7174 - masked_f1: 0.7211\n",
      "[0.0743778720498085, 0.8188170194625854, 0.7331926226615906, 0.7174112796783447, 0.7211238145828247]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2126 - masked_accuracy: 0.6186 - masked_precision: 0.4034 - masked_recall: 0.4593 - masked_f1: 0.4255 - val_loss: 0.1257 - val_masked_accuracy: 0.7047 - val_masked_precision: 0.5039 - val_masked_recall: 0.4381 - val_masked_f1: 0.4661\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1229 - masked_accuracy: 0.6890 - masked_precision: 0.5040 - masked_recall: 0.4340 - masked_f1: 0.4614 - val_loss: 0.1051 - val_masked_accuracy: 0.7474 - val_masked_precision: 0.6230 - val_masked_recall: 0.3918 - val_masked_f1: 0.4781\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1113 - masked_accuracy: 0.7263 - masked_precision: 0.5854 - masked_recall: 0.4433 - masked_f1: 0.4971 - val_loss: 0.0994 - val_masked_accuracy: 0.7634 - val_masked_precision: 0.7021 - val_masked_recall: 0.3568 - val_masked_f1: 0.4703\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1081 - masked_accuracy: 0.7383 - masked_precision: 0.6081 - masked_recall: 0.4554 - masked_f1: 0.5166 - val_loss: 0.0946 - val_masked_accuracy: 0.7825 - val_masked_precision: 0.7042 - val_masked_recall: 0.4601 - val_masked_f1: 0.5539\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1031 - masked_accuracy: 0.7505 - masked_precision: 0.6344 - masked_recall: 0.4745 - masked_f1: 0.5380 - val_loss: 0.0889 - val_masked_accuracy: 0.7924 - val_masked_precision: 0.6894 - val_masked_recall: 0.5544 - val_masked_f1: 0.6124\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0987 - masked_accuracy: 0.7633 - masked_precision: 0.6577 - masked_recall: 0.5023 - masked_f1: 0.5652 - val_loss: 0.0863 - val_masked_accuracy: 0.7989 - val_masked_precision: 0.6896 - val_masked_recall: 0.5903 - val_masked_f1: 0.6338\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0968 - masked_accuracy: 0.7710 - masked_precision: 0.6722 - masked_recall: 0.5283 - masked_f1: 0.5838 - val_loss: 0.0941 - val_masked_accuracy: 0.8026 - val_masked_precision: 0.6864 - val_masked_recall: 0.6196 - val_masked_f1: 0.6494\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0973 - masked_accuracy: 0.7662 - masked_precision: 0.6671 - masked_recall: 0.5083 - masked_f1: 0.5718 - val_loss: 0.0863 - val_masked_accuracy: 0.7931 - val_masked_precision: 0.7360 - val_masked_recall: 0.4759 - val_masked_f1: 0.5759\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0937 - masked_accuracy: 0.7724 - masked_precision: 0.6669 - masked_recall: 0.5336 - masked_f1: 0.5882 - val_loss: 0.0838 - val_masked_accuracy: 0.8053 - val_masked_precision: 0.7384 - val_masked_recall: 0.5394 - val_masked_f1: 0.6202\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0935 - masked_accuracy: 0.7706 - masked_precision: 0.6566 - masked_recall: 0.5592 - masked_f1: 0.5984 - val_loss: 0.0832 - val_masked_accuracy: 0.8004 - val_masked_precision: 0.7359 - val_masked_recall: 0.5114 - val_masked_f1: 0.6011\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0937 - masked_accuracy: 0.7693 - masked_precision: 0.6525 - masked_recall: 0.5518 - masked_f1: 0.5936 - val_loss: 0.0822 - val_masked_accuracy: 0.8065 - val_masked_precision: 0.7315 - val_masked_recall: 0.5549 - val_masked_f1: 0.6285\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0912 - masked_accuracy: 0.7762 - masked_precision: 0.6560 - masked_recall: 0.5937 - masked_f1: 0.6173 - val_loss: 0.0839 - val_masked_accuracy: 0.8186 - val_masked_precision: 0.7244 - val_masked_recall: 0.6271 - val_masked_f1: 0.6697\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0915 - masked_accuracy: 0.7735 - masked_precision: 0.6447 - masked_recall: 0.5954 - masked_f1: 0.6155 - val_loss: 0.0862 - val_masked_accuracy: 0.8173 - val_masked_precision: 0.7219 - val_masked_recall: 0.6284 - val_masked_f1: 0.6690\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0895 - masked_accuracy: 0.7771 - masked_precision: 0.6514 - masked_recall: 0.5993 - masked_f1: 0.6199 - val_loss: 0.0821 - val_masked_accuracy: 0.8179 - val_masked_precision: 0.7419 - val_masked_recall: 0.5936 - val_masked_f1: 0.6562\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0881 - masked_accuracy: 0.7828 - masked_precision: 0.6653 - masked_recall: 0.6172 - masked_f1: 0.6355 - val_loss: 0.0809 - val_masked_accuracy: 0.8292 - val_masked_precision: 0.7374 - val_masked_recall: 0.6664 - val_masked_f1: 0.6958\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0903 - masked_accuracy: 0.7739 - masked_precision: 0.6405 - masked_recall: 0.6313 - masked_f1: 0.6326 - val_loss: 0.0809 - val_masked_accuracy: 0.8271 - val_masked_precision: 0.7258 - val_masked_recall: 0.6761 - val_masked_f1: 0.6963\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0901 - masked_accuracy: 0.7718 - masked_precision: 0.6358 - masked_recall: 0.6290 - masked_f1: 0.6294 - val_loss: 0.0813 - val_masked_accuracy: 0.8091 - val_masked_precision: 0.7549 - val_masked_recall: 0.5268 - val_masked_f1: 0.6168\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0895 - masked_accuracy: 0.7778 - masked_precision: 0.6623 - masked_recall: 0.5970 - masked_f1: 0.6231 - val_loss: 0.0807 - val_masked_accuracy: 0.8154 - val_masked_precision: 0.7631 - val_masked_recall: 0.5528 - val_masked_f1: 0.6371\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0900 - masked_accuracy: 0.7733 - masked_precision: 0.6491 - masked_recall: 0.5994 - masked_f1: 0.6196 - val_loss: 0.0817 - val_masked_accuracy: 0.8160 - val_masked_precision: 0.7388 - val_masked_recall: 0.5924 - val_masked_f1: 0.6536\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0896 - masked_accuracy: 0.7711 - masked_precision: 0.6507 - masked_recall: 0.5822 - masked_f1: 0.6094 - val_loss: 0.0808 - val_masked_accuracy: 0.8120 - val_masked_precision: 0.7341 - val_masked_recall: 0.5806 - val_masked_f1: 0.6448\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0807 - masked_accuracy: 0.8238 - masked_precision: 0.7362 - masked_recall: 0.6581 - masked_f1: 0.6923\n",
      "[0.08065003901720047, 0.8237699270248413, 0.7361750602722168, 0.6580883264541626, 0.6922976970672607]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.2125 - masked_accuracy: 0.6115 - masked_precision: 0.3836 - masked_recall: 0.4509 - masked_f1: 0.4102 - val_loss: 0.1235 - val_masked_accuracy: 0.7109 - val_masked_precision: 0.5830 - val_masked_recall: 0.4341 - val_masked_f1: 0.4925\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.1273 - masked_accuracy: 0.6861 - masked_precision: 0.4850 - masked_recall: 0.4265 - masked_f1: 0.4495 - val_loss: 0.1104 - val_masked_accuracy: 0.7052 - val_masked_precision: 0.6256 - val_masked_recall: 0.2692 - val_masked_f1: 0.3726\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1138 - masked_accuracy: 0.7220 - masked_precision: 0.5542 - masked_recall: 0.4360 - masked_f1: 0.4833 - val_loss: 0.0996 - val_masked_accuracy: 0.7302 - val_masked_precision: 0.7199 - val_masked_recall: 0.2987 - val_masked_f1: 0.4171\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1066 - masked_accuracy: 0.7481 - masked_precision: 0.6106 - masked_recall: 0.4734 - masked_f1: 0.5281 - val_loss: 0.0923 - val_masked_accuracy: 0.7828 - val_masked_precision: 0.7307 - val_masked_recall: 0.5453 - val_masked_f1: 0.6195\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1008 - masked_accuracy: 0.7596 - masked_precision: 0.6241 - masked_recall: 0.5230 - masked_f1: 0.5650 - val_loss: 0.0890 - val_masked_accuracy: 0.7940 - val_masked_precision: 0.7083 - val_masked_recall: 0.6414 - val_masked_f1: 0.6703\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0945 - masked_accuracy: 0.7788 - masked_precision: 0.6661 - masked_recall: 0.5581 - masked_f1: 0.6021 - val_loss: 0.0852 - val_masked_accuracy: 0.8139 - val_masked_precision: 0.7172 - val_masked_recall: 0.7259 - val_masked_f1: 0.7169\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0916 - masked_accuracy: 0.7870 - masked_precision: 0.6657 - masked_recall: 0.6018 - masked_f1: 0.6272 - val_loss: 0.0818 - val_masked_accuracy: 0.8141 - val_masked_precision: 0.7575 - val_masked_recall: 0.6494 - val_masked_f1: 0.6939\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0902 - masked_accuracy: 0.7909 - masked_precision: 0.6709 - masked_recall: 0.6151 - masked_f1: 0.6375 - val_loss: 0.0828 - val_masked_accuracy: 0.8048 - val_masked_precision: 0.6961 - val_masked_recall: 0.7326 - val_masked_f1: 0.7091\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0888 - masked_accuracy: 0.7961 - masked_precision: 0.6750 - masked_recall: 0.6304 - masked_f1: 0.6469 - val_loss: 0.0793 - val_masked_accuracy: 0.8152 - val_masked_precision: 0.7572 - val_masked_recall: 0.6503 - val_masked_f1: 0.6957\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0870 - masked_accuracy: 0.8008 - masked_precision: 0.6969 - masked_recall: 0.6011 - masked_f1: 0.6409 - val_loss: 0.0795 - val_masked_accuracy: 0.8174 - val_masked_precision: 0.7264 - val_masked_recall: 0.7192 - val_masked_f1: 0.7190\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0837 - masked_accuracy: 0.8011 - masked_precision: 0.6933 - masked_recall: 0.6254 - masked_f1: 0.6524 - val_loss: 0.0816 - val_masked_accuracy: 0.8040 - val_masked_precision: 0.7917 - val_masked_recall: 0.5581 - val_masked_f1: 0.6487\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0931 - masked_accuracy: 0.7763 - masked_precision: 0.6593 - masked_recall: 0.5633 - masked_f1: 0.6033 - val_loss: 0.0859 - val_masked_accuracy: 0.7892 - val_masked_precision: 0.7417 - val_masked_recall: 0.5599 - val_masked_f1: 0.6342\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0935 - masked_accuracy: 0.7669 - masked_precision: 0.6354 - masked_recall: 0.5527 - masked_f1: 0.5869 - val_loss: 0.0891 - val_masked_accuracy: 0.7755 - val_masked_precision: 0.7105 - val_masked_recall: 0.5531 - val_masked_f1: 0.6166\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0905 - masked_accuracy: 0.7790 - masked_precision: 0.6615 - masked_recall: 0.5684 - masked_f1: 0.6049 - val_loss: 0.0836 - val_masked_accuracy: 0.8122 - val_masked_precision: 0.7524 - val_masked_recall: 0.6475 - val_masked_f1: 0.6922\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0889 - masked_accuracy: 0.7849 - masked_precision: 0.6637 - masked_recall: 0.6062 - masked_f1: 0.6273 - val_loss: 0.0797 - val_masked_accuracy: 0.8108 - val_masked_precision: 0.7903 - val_masked_recall: 0.5858 - val_masked_f1: 0.6692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0807 - masked_accuracy: 0.8251 - masked_precision: 0.7133 - masked_recall: 0.7182 - masked_f1: 0.7140\n",
      "[0.08070869743824005, 0.8251349925994873, 0.7133104801177979, 0.7181915044784546, 0.7140262126922607]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.1963 - masked_accuracy: 0.6117 - masked_precision: 0.3987 - masked_recall: 0.5080 - masked_f1: 0.4401 - val_loss: 0.1269 - val_masked_accuracy: 0.7129 - val_masked_precision: 0.5294 - val_masked_recall: 0.5126 - val_masked_f1: 0.5171\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.1226 - masked_accuracy: 0.6907 - masked_precision: 0.5007 - masked_recall: 0.4542 - masked_f1: 0.4707 - val_loss: 0.1056 - val_masked_accuracy: 0.7300 - val_masked_precision: 0.5818 - val_masked_recall: 0.4262 - val_masked_f1: 0.4872\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1102 - masked_accuracy: 0.7330 - masked_precision: 0.5932 - masked_recall: 0.4450 - masked_f1: 0.5038 - val_loss: 0.1028 - val_masked_accuracy: 0.7341 - val_masked_precision: 0.5948 - val_masked_recall: 0.4314 - val_masked_f1: 0.4940\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1041 - masked_accuracy: 0.7491 - masked_precision: 0.6370 - masked_recall: 0.4424 - masked_f1: 0.5189 - val_loss: 0.0955 - val_masked_accuracy: 0.7772 - val_masked_precision: 0.6698 - val_masked_recall: 0.5402 - val_masked_f1: 0.5940\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0982 - masked_accuracy: 0.7596 - masked_precision: 0.6570 - masked_recall: 0.4618 - masked_f1: 0.5381 - val_loss: 0.0948 - val_masked_accuracy: 0.7514 - val_masked_precision: 0.6486 - val_masked_recall: 0.4206 - val_masked_f1: 0.5046\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1005 - masked_accuracy: 0.7696 - masked_precision: 0.6716 - masked_recall: 0.4927 - masked_f1: 0.5646 - val_loss: 0.0926 - val_masked_accuracy: 0.7903 - val_masked_precision: 0.6737 - val_masked_recall: 0.6075 - val_masked_f1: 0.6357\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0943 - masked_accuracy: 0.7819 - masked_precision: 0.6908 - masked_recall: 0.5314 - masked_f1: 0.5951 - val_loss: 0.0898 - val_masked_accuracy: 0.7918 - val_masked_precision: 0.6812 - val_masked_recall: 0.6020 - val_masked_f1: 0.6349\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0916 - masked_accuracy: 0.7782 - masked_precision: 0.6866 - masked_recall: 0.5197 - masked_f1: 0.5870 - val_loss: 0.0858 - val_masked_accuracy: 0.7884 - val_masked_precision: 0.7000 - val_masked_recall: 0.5416 - val_masked_f1: 0.6062\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0867 - masked_accuracy: 0.7903 - masked_precision: 0.6901 - masked_recall: 0.5738 - masked_f1: 0.6226 - val_loss: 0.0989 - val_masked_accuracy: 0.7472 - val_masked_precision: 0.6470 - val_masked_recall: 0.3919 - val_masked_f1: 0.4835\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0871 - masked_accuracy: 0.7879 - masked_precision: 0.6780 - masked_recall: 0.5965 - masked_f1: 0.6273 - val_loss: 0.0803 - val_masked_accuracy: 0.8056 - val_masked_precision: 0.6987 - val_masked_recall: 0.6407 - val_masked_f1: 0.6656\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0842 - masked_accuracy: 0.7972 - masked_precision: 0.6918 - masked_recall: 0.6191 - masked_f1: 0.6493 - val_loss: 0.0834 - val_masked_accuracy: 0.8024 - val_masked_precision: 0.7212 - val_masked_recall: 0.5823 - val_masked_f1: 0.6399\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0848 - masked_accuracy: 0.7990 - masked_precision: 0.6852 - masked_recall: 0.6404 - masked_f1: 0.6576 - val_loss: 0.0796 - val_masked_accuracy: 0.8083 - val_masked_precision: 0.6917 - val_masked_recall: 0.6685 - val_masked_f1: 0.6765\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0833 - masked_accuracy: 0.7999 - masked_precision: 0.6787 - masked_recall: 0.6572 - masked_f1: 0.6647 - val_loss: 0.0854 - val_masked_accuracy: 0.7884 - val_masked_precision: 0.7028 - val_masked_recall: 0.5363 - val_masked_f1: 0.6047\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0815 - masked_accuracy: 0.8014 - masked_precision: 0.6922 - masked_recall: 0.6442 - masked_f1: 0.6632 - val_loss: 0.0796 - val_masked_accuracy: 0.8092 - val_masked_precision: 0.7187 - val_masked_recall: 0.6185 - val_masked_f1: 0.6611\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0836 - masked_accuracy: 0.7965 - masked_precision: 0.6735 - masked_recall: 0.6523 - masked_f1: 0.6587 - val_loss: 0.0785 - val_masked_accuracy: 0.8148 - val_masked_precision: 0.6939 - val_masked_recall: 0.7031 - val_masked_f1: 0.6954\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0815 - masked_accuracy: 0.8041 - masked_precision: 0.6983 - masked_recall: 0.6425 - masked_f1: 0.6652 - val_loss: 0.0791 - val_masked_accuracy: 0.8126 - val_masked_precision: 0.7182 - val_masked_recall: 0.6352 - val_masked_f1: 0.6701\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0818 - masked_accuracy: 0.7997 - masked_precision: 0.6944 - masked_recall: 0.6329 - masked_f1: 0.6573 - val_loss: 0.0789 - val_masked_accuracy: 0.8122 - val_masked_precision: 0.7065 - val_masked_recall: 0.6555 - val_masked_f1: 0.6767\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0795 - masked_accuracy: 0.8054 - masked_precision: 0.6875 - masked_recall: 0.6675 - masked_f1: 0.6748 - val_loss: 0.0786 - val_masked_accuracy: 0.8151 - val_masked_precision: 0.7289 - val_masked_recall: 0.6272 - val_masked_f1: 0.6714\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0793 - masked_accuracy: 0.8088 - masked_precision: 0.7022 - masked_recall: 0.6619 - masked_f1: 0.6766 - val_loss: 0.0785 - val_masked_accuracy: 0.8159 - val_masked_precision: 0.7118 - val_masked_recall: 0.6666 - val_masked_f1: 0.6849\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0815 - masked_accuracy: 0.7987 - masked_precision: 0.6838 - masked_recall: 0.6605 - masked_f1: 0.6654 - val_loss: 0.0771 - val_masked_accuracy: 0.8194 - val_masked_precision: 0.6933 - val_masked_recall: 0.7251 - val_masked_f1: 0.7064\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0808 - masked_accuracy: 0.7996 - masked_precision: 0.6909 - masked_recall: 0.6369 - masked_f1: 0.6565 - val_loss: 0.0778 - val_masked_accuracy: 0.8175 - val_masked_precision: 0.7145 - val_masked_recall: 0.6673 - val_masked_f1: 0.6871\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0780 - masked_accuracy: 0.8062 - masked_precision: 0.6979 - masked_recall: 0.6505 - masked_f1: 0.6686 - val_loss: 0.0774 - val_masked_accuracy: 0.8163 - val_masked_precision: 0.7160 - val_masked_recall: 0.6609 - val_masked_f1: 0.6834\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0760 - masked_accuracy: 0.8183 - masked_precision: 0.7085 - masked_recall: 0.6921 - masked_f1: 0.6961 - val_loss: 0.0778 - val_masked_accuracy: 0.8192 - val_masked_precision: 0.7243 - val_masked_recall: 0.6558 - val_masked_f1: 0.6855\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0768 - masked_accuracy: 0.8141 - masked_precision: 0.7085 - masked_recall: 0.6755 - masked_f1: 0.6883 - val_loss: 0.0778 - val_masked_accuracy: 0.8218 - val_masked_precision: 0.7421 - val_masked_recall: 0.6351 - val_masked_f1: 0.6817\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0778 - masked_accuracy: 0.8125 - masked_precision: 0.6952 - masked_recall: 0.6864 - masked_f1: 0.6875 - val_loss: 0.0776 - val_masked_accuracy: 0.8186 - val_masked_precision: 0.7308 - val_masked_recall: 0.6420 - val_masked_f1: 0.6806\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0749 - masked_accuracy: 0.8209 - masked_precision: 0.7125 - masked_recall: 0.6971 - masked_f1: 0.7006 - val_loss: 0.0776 - val_masked_accuracy: 0.8180 - val_masked_precision: 0.7282 - val_masked_recall: 0.6439 - val_masked_f1: 0.6798\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0766 - masked_accuracy: 0.8121 - masked_precision: 0.6951 - masked_recall: 0.6749 - masked_f1: 0.6813 - val_loss: 0.0768 - val_masked_accuracy: 0.8215 - val_masked_precision: 0.7162 - val_masked_recall: 0.6880 - val_masked_f1: 0.6990\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0750 - masked_accuracy: 0.8172 - masked_precision: 0.7073 - masked_recall: 0.6841 - masked_f1: 0.6901 - val_loss: 0.0766 - val_masked_accuracy: 0.8185 - val_masked_precision: 0.7156 - val_masked_recall: 0.6716 - val_masked_f1: 0.6895\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0767 - masked_accuracy: 0.8101 - masked_precision: 0.6969 - masked_recall: 0.6645 - masked_f1: 0.6758 - val_loss: 0.0765 - val_masked_accuracy: 0.8171 - val_masked_precision: 0.7233 - val_masked_recall: 0.6481 - val_masked_f1: 0.6805\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0800 - masked_accuracy: 0.8283 - masked_precision: 0.7474 - masked_recall: 0.6557 - masked_f1: 0.6945\n",
      "[0.07999149709939957, 0.8283087015151978, 0.7473605871200562, 0.6556533575057983, 0.694541335105896]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.2083 - masked_accuracy: 0.6178 - masked_precision: 0.4183 - masked_recall: 0.4921 - masked_f1: 0.4461 - val_loss: 0.1241 - val_masked_accuracy: 0.7006 - val_masked_precision: 0.4857 - val_masked_recall: 0.5217 - val_masked_f1: 0.5001\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1250 - masked_accuracy: 0.6960 - masked_precision: 0.5182 - masked_recall: 0.5121 - masked_f1: 0.5100 - val_loss: 0.1037 - val_masked_accuracy: 0.7469 - val_masked_precision: 0.5681 - val_masked_recall: 0.5368 - val_masked_f1: 0.5497\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1115 - masked_accuracy: 0.7334 - masked_precision: 0.5956 - masked_recall: 0.4959 - masked_f1: 0.5383 - val_loss: 0.0987 - val_masked_accuracy: 0.7753 - val_masked_precision: 0.6386 - val_masked_recall: 0.5282 - val_masked_f1: 0.5761\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1036 - masked_accuracy: 0.7562 - masked_precision: 0.6432 - masked_recall: 0.5205 - masked_f1: 0.5724 - val_loss: 0.0892 - val_masked_accuracy: 0.7984 - val_masked_precision: 0.6619 - val_masked_recall: 0.6272 - val_masked_f1: 0.6421\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0986 - masked_accuracy: 0.7732 - masked_precision: 0.6759 - masked_recall: 0.5573 - masked_f1: 0.6060 - val_loss: 0.0904 - val_masked_accuracy: 0.7985 - val_masked_precision: 0.6416 - val_masked_recall: 0.6875 - val_masked_f1: 0.6627\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0987 - masked_accuracy: 0.7742 - masked_precision: 0.6658 - masked_recall: 0.5759 - masked_f1: 0.6127 - val_loss: 0.0836 - val_masked_accuracy: 0.8100 - val_masked_precision: 0.6742 - val_masked_recall: 0.6625 - val_masked_f1: 0.6666\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0973 - masked_accuracy: 0.7729 - masked_precision: 0.6641 - masked_recall: 0.5717 - masked_f1: 0.6099 - val_loss: 0.0885 - val_masked_accuracy: 0.7905 - val_masked_precision: 0.6477 - val_masked_recall: 0.6039 - val_masked_f1: 0.6242\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0923 - masked_accuracy: 0.7924 - masked_precision: 0.6905 - masked_recall: 0.6277 - masked_f1: 0.6532 - val_loss: 0.0804 - val_masked_accuracy: 0.8091 - val_masked_precision: 0.7024 - val_masked_recall: 0.5831 - val_masked_f1: 0.6358\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0899 - masked_accuracy: 0.7944 - masked_precision: 0.6872 - masked_recall: 0.6516 - masked_f1: 0.6644 - val_loss: 0.0806 - val_masked_accuracy: 0.8073 - val_masked_precision: 0.6409 - val_masked_recall: 0.7585 - val_masked_f1: 0.6933\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0867 - masked_accuracy: 0.8007 - masked_precision: 0.6974 - masked_recall: 0.6621 - masked_f1: 0.6755 - val_loss: 0.0770 - val_masked_accuracy: 0.8204 - val_masked_precision: 0.6743 - val_masked_recall: 0.7252 - val_masked_f1: 0.6984\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0903 - masked_accuracy: 0.7854 - masked_precision: 0.6645 - masked_recall: 0.6568 - masked_f1: 0.6556 - val_loss: 0.0812 - val_masked_accuracy: 0.8078 - val_masked_precision: 0.6687 - val_masked_recall: 0.6626 - val_masked_f1: 0.6646\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0908 - masked_accuracy: 0.7852 - masked_precision: 0.6661 - masked_recall: 0.6542 - masked_f1: 0.6554 - val_loss: 0.0798 - val_masked_accuracy: 0.8108 - val_masked_precision: 0.6741 - val_masked_recall: 0.6645 - val_masked_f1: 0.6685\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0896 - masked_accuracy: 0.7929 - masked_precision: 0.6715 - masked_recall: 0.6769 - masked_f1: 0.6696 - val_loss: 0.0808 - val_masked_accuracy: 0.8034 - val_masked_precision: 0.6819 - val_masked_recall: 0.5962 - val_masked_f1: 0.6352\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0878 - masked_accuracy: 0.7944 - masked_precision: 0.6850 - masked_recall: 0.6540 - masked_f1: 0.6649 - val_loss: 0.0798 - val_masked_accuracy: 0.8099 - val_masked_precision: 0.6651 - val_masked_recall: 0.6873 - val_masked_f1: 0.6749\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0872 - masked_accuracy: 0.7943 - masked_precision: 0.6698 - masked_recall: 0.6771 - masked_f1: 0.6698 - val_loss: 0.0805 - val_masked_accuracy: 0.8110 - val_masked_precision: 0.6333 - val_masked_recall: 0.8087 - val_masked_f1: 0.7096\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0785 - masked_accuracy: 0.8194 - masked_precision: 0.7037 - masked_recall: 0.6885 - masked_f1: 0.6929\n",
      "[0.07851647585630417, 0.819382905960083, 0.7037436366081238, 0.688530683517456, 0.6929001808166504]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2009 - masked_accuracy: 0.6139 - masked_precision: 0.3989 - masked_recall: 0.4891 - masked_f1: 0.4331 - val_loss: 0.1271 - val_masked_accuracy: 0.7302 - val_masked_precision: 0.6190 - val_masked_recall: 0.4710 - val_masked_f1: 0.5336\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1228 - masked_accuracy: 0.6937 - masked_precision: 0.5049 - masked_recall: 0.4609 - masked_f1: 0.4763 - val_loss: 0.1137 - val_masked_accuracy: 0.7401 - val_masked_precision: 0.6748 - val_masked_recall: 0.4077 - val_masked_f1: 0.5067\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1136 - masked_accuracy: 0.7249 - masked_precision: 0.5690 - masked_recall: 0.4437 - masked_f1: 0.4947 - val_loss: 0.1087 - val_masked_accuracy: 0.7624 - val_masked_precision: 0.7053 - val_masked_recall: 0.4786 - val_masked_f1: 0.5682\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1084 - masked_accuracy: 0.7394 - masked_precision: 0.6066 - masked_recall: 0.4422 - masked_f1: 0.5049 - val_loss: 0.1014 - val_masked_accuracy: 0.7574 - val_masked_precision: 0.7388 - val_masked_recall: 0.4056 - val_masked_f1: 0.5217\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.1058 - masked_accuracy: 0.7467 - masked_precision: 0.6113 - masked_recall: 0.4819 - masked_f1: 0.5335 - val_loss: 0.1046 - val_masked_accuracy: 0.7849 - val_masked_precision: 0.7563 - val_masked_recall: 0.5123 - val_masked_f1: 0.6091\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1005 - masked_accuracy: 0.7553 - masked_precision: 0.6426 - masked_recall: 0.4690 - masked_f1: 0.5366 - val_loss: 0.0978 - val_masked_accuracy: 0.7637 - val_masked_precision: 0.7431 - val_masked_recall: 0.4356 - val_masked_f1: 0.5478\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0975 - masked_accuracy: 0.7557 - masked_precision: 0.6492 - masked_recall: 0.4289 - masked_f1: 0.5121 - val_loss: 0.0949 - val_masked_accuracy: 0.7606 - val_masked_precision: 0.7305 - val_masked_recall: 0.4333 - val_masked_f1: 0.5429\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0958 - masked_accuracy: 0.7584 - masked_precision: 0.6602 - masked_recall: 0.4395 - masked_f1: 0.5219 - val_loss: 0.1048 - val_masked_accuracy: 0.7730 - val_masked_precision: 0.6951 - val_masked_recall: 0.5574 - val_masked_f1: 0.6173\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0928 - masked_accuracy: 0.7687 - masked_precision: 0.6767 - masked_recall: 0.4821 - masked_f1: 0.5583 - val_loss: 0.0934 - val_masked_accuracy: 0.7900 - val_masked_precision: 0.7779 - val_masked_recall: 0.5172 - val_masked_f1: 0.6198\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0896 - masked_accuracy: 0.7783 - masked_precision: 0.6802 - masked_recall: 0.5224 - masked_f1: 0.5877 - val_loss: 0.0931 - val_masked_accuracy: 0.7963 - val_masked_precision: 0.7373 - val_masked_recall: 0.5971 - val_masked_f1: 0.6588\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0904 - masked_accuracy: 0.7836 - masked_precision: 0.6704 - masked_recall: 0.5772 - masked_f1: 0.6158 - val_loss: 0.0894 - val_masked_accuracy: 0.8115 - val_masked_precision: 0.7501 - val_masked_recall: 0.6483 - val_masked_f1: 0.6940\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0871 - masked_accuracy: 0.7883 - masked_precision: 0.6674 - masked_recall: 0.6201 - masked_f1: 0.6373 - val_loss: 0.0891 - val_masked_accuracy: 0.8031 - val_masked_precision: 0.7592 - val_masked_recall: 0.5966 - val_masked_f1: 0.6659\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0845 - masked_accuracy: 0.8017 - masked_precision: 0.6857 - masked_recall: 0.6448 - masked_f1: 0.6592 - val_loss: 0.0884 - val_masked_accuracy: 0.8133 - val_masked_precision: 0.7355 - val_masked_recall: 0.6786 - val_masked_f1: 0.7044\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0850 - masked_accuracy: 0.7963 - masked_precision: 0.6665 - masked_recall: 0.6626 - masked_f1: 0.6598 - val_loss: 0.0865 - val_masked_accuracy: 0.8107 - val_masked_precision: 0.7586 - val_masked_recall: 0.6245 - val_masked_f1: 0.6837\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0843 - masked_accuracy: 0.8028 - masked_precision: 0.6811 - masked_recall: 0.6773 - masked_f1: 0.6736 - val_loss: 0.0876 - val_masked_accuracy: 0.8139 - val_masked_precision: 0.7343 - val_masked_recall: 0.6858 - val_masked_f1: 0.7078\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0835 - masked_accuracy: 0.8004 - masked_precision: 0.6765 - masked_recall: 0.6675 - masked_f1: 0.6664 - val_loss: 0.0868 - val_masked_accuracy: 0.8195 - val_masked_precision: 0.7406 - val_masked_recall: 0.6997 - val_masked_f1: 0.7179\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0812 - masked_accuracy: 0.8147 - masked_precision: 0.7022 - masked_recall: 0.6932 - masked_f1: 0.6911 - val_loss: 0.0864 - val_masked_accuracy: 0.8232 - val_masked_precision: 0.7294 - val_masked_recall: 0.7446 - val_masked_f1: 0.7349\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0836 - masked_accuracy: 0.8007 - masked_precision: 0.6711 - masked_recall: 0.6807 - masked_f1: 0.6698 - val_loss: 0.0861 - val_masked_accuracy: 0.8285 - val_masked_precision: 0.7523 - val_masked_recall: 0.7149 - val_masked_f1: 0.7324\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0815 - masked_accuracy: 0.8119 - masked_precision: 0.6899 - masked_recall: 0.6895 - masked_f1: 0.6869 - val_loss: 0.0837 - val_masked_accuracy: 0.8297 - val_masked_precision: 0.7575 - val_masked_recall: 0.7115 - val_masked_f1: 0.7329\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0796 - masked_accuracy: 0.8173 - masked_precision: 0.6960 - masked_recall: 0.7092 - masked_f1: 0.6996 - val_loss: 0.0822 - val_masked_accuracy: 0.8314 - val_masked_precision: 0.7692 - val_masked_recall: 0.6996 - val_masked_f1: 0.7315\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0809 - masked_accuracy: 0.8111 - masked_precision: 0.6805 - masked_recall: 0.7148 - masked_f1: 0.6934 - val_loss: 0.0842 - val_masked_accuracy: 0.8248 - val_masked_precision: 0.7387 - val_masked_recall: 0.7340 - val_masked_f1: 0.7337\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0795 - masked_accuracy: 0.8163 - masked_precision: 0.7000 - masked_recall: 0.7090 - masked_f1: 0.6999 - val_loss: 0.0843 - val_masked_accuracy: 0.8269 - val_masked_precision: 0.7581 - val_masked_recall: 0.7015 - val_masked_f1: 0.7273\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0788 - masked_accuracy: 0.8190 - masked_precision: 0.7010 - masked_recall: 0.7039 - masked_f1: 0.6998 - val_loss: 0.0829 - val_masked_accuracy: 0.8318 - val_masked_precision: 0.7529 - val_masked_recall: 0.7298 - val_masked_f1: 0.7403\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0779 - masked_accuracy: 0.8188 - masked_precision: 0.7051 - masked_recall: 0.7154 - masked_f1: 0.7044 - val_loss: 0.0845 - val_masked_accuracy: 0.8305 - val_masked_precision: 0.7316 - val_masked_recall: 0.7646 - val_masked_f1: 0.7469\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0782 - masked_accuracy: 0.8206 - masked_precision: 0.7013 - masked_recall: 0.7213 - masked_f1: 0.7064 - val_loss: 0.0840 - val_masked_accuracy: 0.8284 - val_masked_precision: 0.7341 - val_masked_recall: 0.7474 - val_masked_f1: 0.7399\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0806 - masked_accuracy: 0.8120 - masked_precision: 0.6793 - masked_recall: 0.7333 - masked_f1: 0.7014 - val_loss: 0.0850 - val_masked_accuracy: 0.8225 - val_masked_precision: 0.7712 - val_masked_recall: 0.6552 - val_masked_f1: 0.7068\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0789 - masked_accuracy: 0.8187 - masked_precision: 0.7007 - masked_recall: 0.7133 - masked_f1: 0.7027 - val_loss: 0.0853 - val_masked_accuracy: 0.8239 - val_masked_precision: 0.7435 - val_masked_recall: 0.7161 - val_masked_f1: 0.7273\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0794 - masked_accuracy: 0.8117 - masked_precision: 0.6799 - masked_recall: 0.7350 - masked_f1: 0.7034 - val_loss: 0.0827 - val_masked_accuracy: 0.8257 - val_masked_precision: 0.7877 - val_masked_recall: 0.6512 - val_masked_f1: 0.7109\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0756 - masked_accuracy: 0.8425 - masked_precision: 0.7140 - masked_recall: 0.7567 - masked_f1: 0.7314\n",
      "[0.07555048167705536, 0.8425074815750122, 0.713988721370697, 0.7566549777984619, 0.7313870191574097]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 54ms/step - loss: 0.2113 - masked_accuracy: 0.6226 - masked_precision: 0.4047 - masked_recall: 0.4804 - masked_f1: 0.4329 - val_loss: 0.1197 - val_masked_accuracy: 0.6915 - val_masked_precision: 0.4780 - val_masked_recall: 0.3762 - val_masked_f1: 0.4174\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 42ms/step - loss: 0.1234 - masked_accuracy: 0.6955 - masked_precision: 0.5022 - masked_recall: 0.4284 - masked_f1: 0.4578 - val_loss: 0.1112 - val_masked_accuracy: 0.7435 - val_masked_precision: 0.5987 - val_masked_recall: 0.4555 - val_masked_f1: 0.5115\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1126 - masked_accuracy: 0.7230 - masked_precision: 0.5618 - masked_recall: 0.4186 - masked_f1: 0.4735 - val_loss: 0.1066 - val_masked_accuracy: 0.7516 - val_masked_precision: 0.6471 - val_masked_recall: 0.3859 - val_masked_f1: 0.4796\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1050 - masked_accuracy: 0.7402 - masked_precision: 0.6061 - masked_recall: 0.4211 - masked_f1: 0.4913 - val_loss: 0.0977 - val_masked_accuracy: 0.7759 - val_masked_precision: 0.6731 - val_masked_recall: 0.4993 - val_masked_f1: 0.5688\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0995 - masked_accuracy: 0.7607 - masked_precision: 0.6400 - masked_recall: 0.4824 - masked_f1: 0.5455 - val_loss: 0.0904 - val_masked_accuracy: 0.7936 - val_masked_precision: 0.7132 - val_masked_recall: 0.5314 - val_masked_f1: 0.6040\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0979 - masked_accuracy: 0.7715 - masked_precision: 0.6588 - masked_recall: 0.5177 - masked_f1: 0.5740 - val_loss: 0.0898 - val_masked_accuracy: 0.7929 - val_masked_precision: 0.6977 - val_masked_recall: 0.5634 - val_masked_f1: 0.6156\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0943 - masked_accuracy: 0.7813 - masked_precision: 0.6676 - masked_recall: 0.5661 - masked_f1: 0.6080 - val_loss: 0.0897 - val_masked_accuracy: 0.7943 - val_masked_precision: 0.6511 - val_masked_recall: 0.6883 - val_masked_f1: 0.6626\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0935 - masked_accuracy: 0.7778 - masked_precision: 0.6546 - masked_recall: 0.5900 - masked_f1: 0.6152 - val_loss: 0.0881 - val_masked_accuracy: 0.8048 - val_masked_precision: 0.6710 - val_masked_recall: 0.6872 - val_masked_f1: 0.6740\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0928 - masked_accuracy: 0.7832 - masked_precision: 0.6537 - masked_recall: 0.6158 - masked_f1: 0.6277 - val_loss: 0.0879 - val_masked_accuracy: 0.8072 - val_masked_precision: 0.6948 - val_masked_recall: 0.6325 - val_masked_f1: 0.6581\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0925 - masked_accuracy: 0.7760 - masked_precision: 0.6433 - masked_recall: 0.5979 - masked_f1: 0.6159 - val_loss: 0.0859 - val_masked_accuracy: 0.8109 - val_masked_precision: 0.7181 - val_masked_recall: 0.6016 - val_masked_f1: 0.6507\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0878 - masked_accuracy: 0.7914 - masked_precision: 0.6779 - masked_recall: 0.6072 - masked_f1: 0.6357 - val_loss: 0.0831 - val_masked_accuracy: 0.8122 - val_masked_precision: 0.6974 - val_masked_recall: 0.6509 - val_masked_f1: 0.6698\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0864 - masked_accuracy: 0.7917 - masked_precision: 0.6841 - masked_recall: 0.5806 - masked_f1: 0.6236 - val_loss: 0.0838 - val_masked_accuracy: 0.8049 - val_masked_precision: 0.7195 - val_masked_recall: 0.5714 - val_masked_f1: 0.6339\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0873 - masked_accuracy: 0.7912 - masked_precision: 0.6656 - masked_recall: 0.6249 - masked_f1: 0.6413 - val_loss: 0.0826 - val_masked_accuracy: 0.8117 - val_masked_precision: 0.7220 - val_masked_recall: 0.6069 - val_masked_f1: 0.6552\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0855 - masked_accuracy: 0.8004 - masked_precision: 0.6762 - masked_recall: 0.6608 - masked_f1: 0.6647 - val_loss: 0.0819 - val_masked_accuracy: 0.8091 - val_masked_precision: 0.6735 - val_masked_recall: 0.7080 - val_masked_f1: 0.6851\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0852 - masked_accuracy: 0.7996 - masked_precision: 0.6749 - masked_recall: 0.6602 - masked_f1: 0.6633 - val_loss: 0.0812 - val_masked_accuracy: 0.8153 - val_masked_precision: 0.6927 - val_masked_recall: 0.6851 - val_masked_f1: 0.6856\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0834 - masked_accuracy: 0.8029 - masked_precision: 0.6680 - masked_recall: 0.6813 - masked_f1: 0.6696 - val_loss: 0.0799 - val_masked_accuracy: 0.8088 - val_masked_precision: 0.7031 - val_masked_recall: 0.6336 - val_masked_f1: 0.6593\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0825 - masked_accuracy: 0.8021 - masked_precision: 0.6803 - masked_recall: 0.6662 - masked_f1: 0.6700 - val_loss: 0.0822 - val_masked_accuracy: 0.8112 - val_masked_precision: 0.7039 - val_masked_recall: 0.6475 - val_masked_f1: 0.6693\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0804 - masked_accuracy: 0.8126 - masked_precision: 0.6921 - masked_recall: 0.6845 - masked_f1: 0.6844 - val_loss: 0.0784 - val_masked_accuracy: 0.8200 - val_masked_precision: 0.7069 - val_masked_recall: 0.6865 - val_masked_f1: 0.6913\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0816 - masked_accuracy: 0.8122 - masked_precision: 0.6930 - masked_recall: 0.6792 - masked_f1: 0.6825 - val_loss: 0.0803 - val_masked_accuracy: 0.8197 - val_masked_precision: 0.6718 - val_masked_recall: 0.7741 - val_masked_f1: 0.7155\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0801 - masked_accuracy: 0.8088 - masked_precision: 0.6919 - masked_recall: 0.6760 - masked_f1: 0.6787 - val_loss: 0.0823 - val_masked_accuracy: 0.8181 - val_masked_precision: 0.6927 - val_masked_recall: 0.7095 - val_masked_f1: 0.6978\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0815 - masked_accuracy: 0.8086 - masked_precision: 0.6936 - masked_recall: 0.6753 - masked_f1: 0.6787 - val_loss: 0.0808 - val_masked_accuracy: 0.8180 - val_masked_precision: 0.7016 - val_masked_recall: 0.6830 - val_masked_f1: 0.6884\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0795 - masked_accuracy: 0.8163 - masked_precision: 0.6896 - masked_recall: 0.7095 - masked_f1: 0.6945 - val_loss: 0.0792 - val_masked_accuracy: 0.8274 - val_masked_precision: 0.7419 - val_masked_recall: 0.6473 - val_masked_f1: 0.6875\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0808 - masked_accuracy: 0.8113 - masked_precision: 0.6850 - masked_recall: 0.7133 - masked_f1: 0.6944 - val_loss: 0.0802 - val_masked_accuracy: 0.8188 - val_masked_precision: 0.6918 - val_masked_recall: 0.7080 - val_masked_f1: 0.6963\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0834 - masked_accuracy: 0.8034 - masked_precision: 0.6611 - masked_recall: 0.7201 - masked_f1: 0.6843 - val_loss: 0.0805 - val_masked_accuracy: 0.8173 - val_masked_precision: 0.7646 - val_masked_recall: 0.5682 - val_masked_f1: 0.6459\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0840 - masked_accuracy: 0.7950 - masked_precision: 0.6585 - masked_recall: 0.6852 - masked_f1: 0.6663 - val_loss: 0.0791 - val_masked_accuracy: 0.8187 - val_masked_precision: 0.6838 - val_masked_recall: 0.7369 - val_masked_f1: 0.7054\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0803 - masked_accuracy: 0.8043 - masked_precision: 0.6737 - masked_recall: 0.6750 - masked_f1: 0.6701 - val_loss: 0.0797 - val_masked_accuracy: 0.8209 - val_masked_precision: 0.6903 - val_masked_recall: 0.7274 - val_masked_f1: 0.7043\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0800 - masked_accuracy: 0.8048 - masked_precision: 0.6807 - masked_recall: 0.6589 - masked_f1: 0.6658 - val_loss: 0.0789 - val_masked_accuracy: 0.8212 - val_masked_precision: 0.7296 - val_masked_recall: 0.6406 - val_masked_f1: 0.6774\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0775 - masked_accuracy: 0.8376 - masked_precision: 0.7937 - masked_recall: 0.6557 - masked_f1: 0.7167\n",
      "[0.07749149948358536, 0.8375973105430603, 0.7937123775482178, 0.6557204723358154, 0.7166568040847778]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2041 - masked_accuracy: 0.6008 - masked_precision: 0.3866 - masked_recall: 0.4754 - masked_f1: 0.4212 - val_loss: 0.1170 - val_masked_accuracy: 0.7305 - val_masked_precision: 0.5817 - val_masked_recall: 0.4451 - val_masked_f1: 0.5003\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.1238 - masked_accuracy: 0.6886 - masked_precision: 0.5029 - masked_recall: 0.4673 - masked_f1: 0.4801 - val_loss: 0.1113 - val_masked_accuracy: 0.7630 - val_masked_precision: 0.6455 - val_masked_recall: 0.4952 - val_masked_f1: 0.5584\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1124 - masked_accuracy: 0.7273 - masked_precision: 0.5800 - masked_recall: 0.4420 - masked_f1: 0.4970 - val_loss: 0.0988 - val_masked_accuracy: 0.7691 - val_masked_precision: 0.6935 - val_masked_recall: 0.4405 - val_masked_f1: 0.5362\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1084 - masked_accuracy: 0.7414 - masked_precision: 0.6122 - masked_recall: 0.4536 - masked_f1: 0.5167 - val_loss: 0.0980 - val_masked_accuracy: 0.7614 - val_masked_precision: 0.6841 - val_masked_recall: 0.4073 - val_masked_f1: 0.5087\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.1024 - masked_accuracy: 0.7561 - masked_precision: 0.6345 - masked_recall: 0.5056 - masked_f1: 0.5581 - val_loss: 0.0942 - val_masked_accuracy: 0.7636 - val_masked_precision: 0.7145 - val_masked_recall: 0.3843 - val_masked_f1: 0.4977\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1020 - masked_accuracy: 0.7561 - masked_precision: 0.6401 - masked_recall: 0.5021 - masked_f1: 0.5578 - val_loss: 0.0895 - val_masked_accuracy: 0.8038 - val_masked_precision: 0.7187 - val_masked_recall: 0.5841 - val_masked_f1: 0.6421\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0959 - masked_accuracy: 0.7716 - masked_precision: 0.6677 - masked_recall: 0.5342 - masked_f1: 0.5889 - val_loss: 0.0912 - val_masked_accuracy: 0.8002 - val_masked_precision: 0.7102 - val_masked_recall: 0.5786 - val_masked_f1: 0.6361\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0937 - masked_accuracy: 0.7715 - masked_precision: 0.6584 - masked_recall: 0.5378 - masked_f1: 0.5889 - val_loss: 0.0830 - val_masked_accuracy: 0.8058 - val_masked_precision: 0.7241 - val_masked_recall: 0.5862 - val_masked_f1: 0.6452\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0900 - masked_accuracy: 0.7799 - masked_precision: 0.6666 - masked_recall: 0.5909 - masked_f1: 0.6231 - val_loss: 0.0813 - val_masked_accuracy: 0.8117 - val_masked_precision: 0.7267 - val_masked_recall: 0.6097 - val_masked_f1: 0.6611\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.0893 - masked_accuracy: 0.7874 - masked_precision: 0.6632 - masked_recall: 0.6346 - masked_f1: 0.6437 - val_loss: 0.0811 - val_masked_accuracy: 0.8198 - val_masked_precision: 0.7286 - val_masked_recall: 0.6524 - val_masked_f1: 0.6869\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0889 - masked_accuracy: 0.7859 - masked_precision: 0.6635 - masked_recall: 0.6309 - masked_f1: 0.6426 - val_loss: 0.0799 - val_masked_accuracy: 0.8213 - val_masked_precision: 0.7157 - val_masked_recall: 0.6868 - val_masked_f1: 0.6988\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0852 - masked_accuracy: 0.7986 - masked_precision: 0.6802 - masked_recall: 0.6711 - masked_f1: 0.6725 - val_loss: 0.0789 - val_masked_accuracy: 0.8232 - val_masked_precision: 0.7140 - val_masked_recall: 0.6965 - val_masked_f1: 0.7025\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0851 - masked_accuracy: 0.7991 - masked_precision: 0.6783 - masked_recall: 0.6756 - masked_f1: 0.6733 - val_loss: 0.0777 - val_masked_accuracy: 0.8333 - val_masked_precision: 0.7175 - val_masked_recall: 0.7439 - val_masked_f1: 0.7290\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0825 - masked_accuracy: 0.8000 - masked_precision: 0.6769 - masked_recall: 0.6841 - masked_f1: 0.6766 - val_loss: 0.0770 - val_masked_accuracy: 0.8259 - val_masked_precision: 0.7233 - val_masked_recall: 0.6973 - val_masked_f1: 0.7080\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0820 - masked_accuracy: 0.8054 - masked_precision: 0.6855 - masked_recall: 0.7029 - masked_f1: 0.6902 - val_loss: 0.0773 - val_masked_accuracy: 0.8268 - val_masked_precision: 0.7404 - val_masked_recall: 0.6630 - val_masked_f1: 0.6967\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0851 - masked_accuracy: 0.7977 - masked_precision: 0.6705 - masked_recall: 0.6827 - masked_f1: 0.6721 - val_loss: 0.0798 - val_masked_accuracy: 0.8296 - val_masked_precision: 0.7039 - val_masked_recall: 0.7520 - val_masked_f1: 0.7256\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0900 - masked_accuracy: 0.7732 - masked_precision: 0.6303 - masked_recall: 0.6775 - masked_f1: 0.6472 - val_loss: 0.0831 - val_masked_accuracy: 0.8147 - val_masked_precision: 0.6936 - val_masked_recall: 0.6924 - val_masked_f1: 0.6921\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0906 - masked_accuracy: 0.7696 - masked_precision: 0.6421 - masked_recall: 0.6024 - masked_f1: 0.6160 - val_loss: 0.0806 - val_masked_accuracy: 0.8074 - val_masked_precision: 0.7285 - val_masked_recall: 0.5836 - val_masked_f1: 0.6463\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0859 - masked_accuracy: 0.8124 - masked_precision: 0.6763 - masked_recall: 0.7347 - masked_f1: 0.6979\n",
      "[0.08589621633291245, 0.8124181628227234, 0.6763243675231934, 0.7346821427345276, 0.6978660225868225]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.2013 - masked_accuracy: 0.6024 - masked_precision: 0.3771 - masked_recall: 0.4666 - masked_f1: 0.4125 - val_loss: 0.1216 - val_masked_accuracy: 0.7204 - val_masked_precision: 0.5450 - val_masked_recall: 0.5739 - val_masked_f1: 0.5550\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1274 - masked_accuracy: 0.6903 - masked_precision: 0.4963 - masked_recall: 0.4708 - masked_f1: 0.4769 - val_loss: 0.1021 - val_masked_accuracy: 0.7681 - val_masked_precision: 0.6361 - val_masked_recall: 0.5777 - val_masked_f1: 0.6014\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.1132 - masked_accuracy: 0.7388 - masked_precision: 0.5870 - masked_recall: 0.4933 - masked_f1: 0.5317 - val_loss: 0.0956 - val_masked_accuracy: 0.8056 - val_masked_precision: 0.7155 - val_masked_recall: 0.6091 - val_masked_f1: 0.6539\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1045 - masked_accuracy: 0.7618 - masked_precision: 0.6324 - masked_recall: 0.5468 - masked_f1: 0.5793 - val_loss: 0.0852 - val_masked_accuracy: 0.8154 - val_masked_precision: 0.7041 - val_masked_recall: 0.6884 - val_masked_f1: 0.6927\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0999 - masked_accuracy: 0.7707 - masked_precision: 0.6397 - masked_recall: 0.5704 - masked_f1: 0.5973 - val_loss: 0.0859 - val_masked_accuracy: 0.8318 - val_masked_precision: 0.7277 - val_masked_recall: 0.7214 - val_masked_f1: 0.7216\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0970 - masked_accuracy: 0.7865 - masked_precision: 0.6676 - masked_recall: 0.6065 - masked_f1: 0.6303 - val_loss: 0.0794 - val_masked_accuracy: 0.8338 - val_masked_precision: 0.7181 - val_masked_recall: 0.7585 - val_masked_f1: 0.7346\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0969 - masked_accuracy: 0.7802 - masked_precision: 0.6707 - masked_recall: 0.5745 - masked_f1: 0.6113 - val_loss: 0.0744 - val_masked_accuracy: 0.8372 - val_masked_precision: 0.7433 - val_masked_recall: 0.7197 - val_masked_f1: 0.7281\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0922 - masked_accuracy: 0.7853 - masked_precision: 0.6807 - masked_recall: 0.5582 - masked_f1: 0.6082 - val_loss: 0.0777 - val_masked_accuracy: 0.8243 - val_masked_precision: 0.7613 - val_masked_recall: 0.6257 - val_masked_f1: 0.6831\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0892 - masked_accuracy: 0.7937 - masked_precision: 0.6860 - masked_recall: 0.5942 - masked_f1: 0.6330 - val_loss: 0.0739 - val_masked_accuracy: 0.8403 - val_masked_precision: 0.7661 - val_masked_recall: 0.6956 - val_masked_f1: 0.7255\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0882 - masked_accuracy: 0.8040 - masked_precision: 0.6877 - masked_recall: 0.6459 - masked_f1: 0.6637 - val_loss: 0.0741 - val_masked_accuracy: 0.8428 - val_masked_precision: 0.7586 - val_masked_recall: 0.7167 - val_masked_f1: 0.7343\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0851 - masked_accuracy: 0.8071 - masked_precision: 0.6938 - masked_recall: 0.6469 - masked_f1: 0.6657 - val_loss: 0.0722 - val_masked_accuracy: 0.8417 - val_masked_precision: 0.7555 - val_masked_recall: 0.7185 - val_masked_f1: 0.7338\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0841 - masked_accuracy: 0.8044 - masked_precision: 0.6837 - masked_recall: 0.6703 - masked_f1: 0.6722 - val_loss: 0.0726 - val_masked_accuracy: 0.8272 - val_masked_precision: 0.7852 - val_masked_recall: 0.5994 - val_masked_f1: 0.6770\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0849 - masked_accuracy: 0.8019 - masked_precision: 0.6749 - masked_recall: 0.6755 - masked_f1: 0.6700 - val_loss: 0.0730 - val_masked_accuracy: 0.8300 - val_masked_precision: 0.7891 - val_masked_recall: 0.6061 - val_masked_f1: 0.6836\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0874 - masked_accuracy: 0.7955 - masked_precision: 0.6618 - masked_recall: 0.6734 - masked_f1: 0.6629 - val_loss: 0.0747 - val_masked_accuracy: 0.8447 - val_masked_precision: 0.7396 - val_masked_recall: 0.7683 - val_masked_f1: 0.7501\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0839 - masked_accuracy: 0.8063 - masked_precision: 0.6946 - masked_recall: 0.6489 - masked_f1: 0.6664 - val_loss: 0.0729 - val_masked_accuracy: 0.8413 - val_masked_precision: 0.7538 - val_masked_recall: 0.7254 - val_masked_f1: 0.7355\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0826 - masked_accuracy: 0.8019 - masked_precision: 0.6689 - masked_recall: 0.6876 - masked_f1: 0.6744 - val_loss: 0.0724 - val_masked_accuracy: 0.8499 - val_masked_precision: 0.7390 - val_masked_recall: 0.7957 - val_masked_f1: 0.7624\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0831 - masked_accuracy: 0.8039 - masked_precision: 0.6861 - masked_recall: 0.6430 - masked_f1: 0.6607 - val_loss: 0.0780 - val_masked_accuracy: 0.8220 - val_masked_precision: 0.7663 - val_masked_recall: 0.6115 - val_masked_f1: 0.6759\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0859 - masked_accuracy: 0.7935 - masked_precision: 0.6733 - masked_recall: 0.6260 - masked_f1: 0.6434 - val_loss: 0.0713 - val_masked_accuracy: 0.8451 - val_masked_precision: 0.7516 - val_masked_recall: 0.7436 - val_masked_f1: 0.7444\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0819 - masked_accuracy: 0.8071 - masked_precision: 0.6926 - masked_recall: 0.6558 - masked_f1: 0.6689 - val_loss: 0.0705 - val_masked_accuracy: 0.8465 - val_masked_precision: 0.7820 - val_masked_recall: 0.6901 - val_masked_f1: 0.7302\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0815 - masked_accuracy: 0.8057 - masked_precision: 0.6866 - masked_recall: 0.6560 - masked_f1: 0.6650 - val_loss: 0.0693 - val_masked_accuracy: 0.8495 - val_masked_precision: 0.7405 - val_masked_recall: 0.7907 - val_masked_f1: 0.7611\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0813 - masked_accuracy: 0.8041 - masked_precision: 0.6978 - masked_recall: 0.6387 - masked_f1: 0.6629 - val_loss: 0.0697 - val_masked_accuracy: 0.8527 - val_masked_precision: 0.7627 - val_masked_recall: 0.7622 - val_masked_f1: 0.7579\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0816 - masked_accuracy: 0.8081 - masked_precision: 0.6959 - masked_recall: 0.6562 - masked_f1: 0.6716 - val_loss: 0.0762 - val_masked_accuracy: 0.8426 - val_masked_precision: 0.7135 - val_masked_recall: 0.8177 - val_masked_f1: 0.7586\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.0829 - masked_accuracy: 0.8057 - masked_precision: 0.6996 - masked_recall: 0.6494 - masked_f1: 0.6677 - val_loss: 0.0759 - val_masked_accuracy: 0.8030 - val_masked_precision: 0.7793 - val_masked_recall: 0.5048 - val_masked_f1: 0.6081\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.0833 - masked_accuracy: 0.8064 - masked_precision: 0.6966 - masked_recall: 0.6488 - masked_f1: 0.6667 - val_loss: 0.0687 - val_masked_accuracy: 0.8455 - val_masked_precision: 0.7562 - val_masked_recall: 0.7413 - val_masked_f1: 0.7447\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0810 - masked_accuracy: 0.8085 - masked_precision: 0.7043 - masked_recall: 0.6336 - masked_f1: 0.6639 - val_loss: 0.0698 - val_masked_accuracy: 0.8571 - val_masked_precision: 0.7676 - val_masked_recall: 0.7707 - val_masked_f1: 0.7657\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0805 - masked_accuracy: 0.8093 - masked_precision: 0.7050 - masked_recall: 0.6512 - masked_f1: 0.6739 - val_loss: 0.0688 - val_masked_accuracy: 0.8499 - val_masked_precision: 0.7761 - val_masked_recall: 0.7213 - val_masked_f1: 0.7445\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0795 - masked_accuracy: 0.8109 - masked_precision: 0.7076 - masked_recall: 0.6417 - masked_f1: 0.6692 - val_loss: 0.0727 - val_masked_accuracy: 0.8324 - val_masked_precision: 0.7712 - val_masked_recall: 0.6527 - val_masked_f1: 0.7026\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0826 - masked_accuracy: 0.7988 - masked_precision: 0.6881 - masked_recall: 0.6301 - masked_f1: 0.6513 - val_loss: 0.0745 - val_masked_accuracy: 0.8296 - val_masked_precision: 0.8010 - val_masked_recall: 0.5991 - val_masked_f1: 0.6805\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0829 - masked_accuracy: 0.8061 - masked_precision: 0.6909 - masked_recall: 0.6523 - masked_f1: 0.6667 - val_loss: 0.0727 - val_masked_accuracy: 0.8429 - val_masked_precision: 0.7535 - val_masked_recall: 0.7341 - val_masked_f1: 0.7393\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0830 - masked_accuracy: 0.8000 - masked_precision: 0.6649 - masked_recall: 0.7031 - masked_f1: 0.6785 - val_loss: 0.0744 - val_masked_accuracy: 0.8420 - val_masked_precision: 0.7432 - val_masked_recall: 0.7507 - val_masked_f1: 0.7421\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0783 - masked_accuracy: 0.8244 - masked_precision: 0.7129 - masked_recall: 0.7393 - masked_f1: 0.7172\n",
      "[0.07828866690397263, 0.8243548274040222, 0.7129454612731934, 0.7392815947532654, 0.7171580791473389]\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.2025 - masked_accuracy: 0.6150 - masked_precision: 0.3965 - masked_recall: 0.4995 - masked_f1: 0.4373 - val_loss: 0.1340 - val_masked_accuracy: 0.6987 - val_masked_precision: 0.5582 - val_masked_recall: 0.5622 - val_masked_f1: 0.5582\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1265 - masked_accuracy: 0.6839 - masked_precision: 0.4689 - masked_recall: 0.4377 - masked_f1: 0.4484 - val_loss: 0.1173 - val_masked_accuracy: 0.7275 - val_masked_precision: 0.7059 - val_masked_recall: 0.3421 - val_masked_f1: 0.4599\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1106 - masked_accuracy: 0.7305 - masked_precision: 0.5702 - masked_recall: 0.4413 - masked_f1: 0.4940 - val_loss: 0.1114 - val_masked_accuracy: 0.7296 - val_masked_precision: 0.6942 - val_masked_recall: 0.3732 - val_masked_f1: 0.4835\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1033 - masked_accuracy: 0.7511 - masked_precision: 0.6175 - masked_recall: 0.4758 - masked_f1: 0.5324 - val_loss: 0.1067 - val_masked_accuracy: 0.7881 - val_masked_precision: 0.6983 - val_masked_recall: 0.6674 - val_masked_f1: 0.6805\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1003 - masked_accuracy: 0.7619 - masked_precision: 0.6279 - masked_recall: 0.5138 - masked_f1: 0.5607 - val_loss: 0.0965 - val_masked_accuracy: 0.7789 - val_masked_precision: 0.7664 - val_masked_recall: 0.5063 - val_masked_f1: 0.6081\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0969 - masked_accuracy: 0.7740 - masked_precision: 0.6448 - masked_recall: 0.5535 - masked_f1: 0.5903 - val_loss: 0.0966 - val_masked_accuracy: 0.7895 - val_masked_precision: 0.7240 - val_masked_recall: 0.6189 - val_masked_f1: 0.6662\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0927 - masked_accuracy: 0.7858 - masked_precision: 0.6676 - masked_recall: 0.5588 - masked_f1: 0.6030 - val_loss: 0.0971 - val_masked_accuracy: 0.7790 - val_masked_precision: 0.7580 - val_masked_recall: 0.5186 - val_masked_f1: 0.6140\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 3s 45ms/step - loss: 0.0927 - masked_accuracy: 0.7801 - masked_precision: 0.6637 - masked_recall: 0.5550 - masked_f1: 0.5987 - val_loss: 0.0950 - val_masked_accuracy: 0.7887 - val_masked_precision: 0.7338 - val_masked_recall: 0.5956 - val_masked_f1: 0.6560\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0907 - masked_accuracy: 0.7869 - masked_precision: 0.6728 - masked_recall: 0.5716 - masked_f1: 0.6115 - val_loss: 0.0867 - val_masked_accuracy: 0.8209 - val_masked_precision: 0.7052 - val_masked_recall: 0.8141 - val_masked_f1: 0.7541\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0858 - masked_accuracy: 0.8007 - masked_precision: 0.6885 - masked_recall: 0.6172 - masked_f1: 0.6481 - val_loss: 0.0865 - val_masked_accuracy: 0.8290 - val_masked_precision: 0.7644 - val_masked_recall: 0.7204 - val_masked_f1: 0.7404\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0831 - masked_accuracy: 0.8043 - masked_precision: 0.6878 - masked_recall: 0.6384 - masked_f1: 0.6579 - val_loss: 0.0823 - val_masked_accuracy: 0.8313 - val_masked_precision: 0.7443 - val_masked_recall: 0.7641 - val_masked_f1: 0.7528\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0840 - masked_accuracy: 0.8013 - masked_precision: 0.6810 - masked_recall: 0.6380 - masked_f1: 0.6542 - val_loss: 0.0888 - val_masked_accuracy: 0.8245 - val_masked_precision: 0.7349 - val_masked_recall: 0.7575 - val_masked_f1: 0.7447\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0860 - masked_accuracy: 0.7925 - masked_precision: 0.6505 - masked_recall: 0.6660 - masked_f1: 0.6536 - val_loss: 0.0832 - val_masked_accuracy: 0.8211 - val_masked_precision: 0.7841 - val_masked_recall: 0.6543 - val_masked_f1: 0.7126\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.0917 - masked_accuracy: 0.7736 - masked_precision: 0.6315 - masked_recall: 0.6316 - masked_f1: 0.6236 - val_loss: 0.0889 - val_masked_accuracy: 0.8025 - val_masked_precision: 0.7673 - val_masked_recall: 0.6030 - val_masked_f1: 0.6742\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0873 - masked_accuracy: 0.7857 - masked_precision: 0.6573 - masked_recall: 0.6147 - masked_f1: 0.6314 - val_loss: 0.0880 - val_masked_accuracy: 0.8021 - val_masked_precision: 0.7878 - val_masked_recall: 0.5760 - val_masked_f1: 0.6643\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.0856 - masked_accuracy: 0.7898 - masked_precision: 0.6602 - masked_recall: 0.6215 - masked_f1: 0.6371 - val_loss: 0.0853 - val_masked_accuracy: 0.8105 - val_masked_precision: 0.7741 - val_masked_recall: 0.6279 - val_masked_f1: 0.6925\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0770 - masked_accuracy: 0.8365 - masked_precision: 0.7238 - masked_recall: 0.7382 - masked_f1: 0.7287\n",
      "[0.0770297423005104, 0.836537778377533, 0.72384113073349, 0.7381520867347717, 0.7286522388458252]\n",
      "0.8240759174029032 0.014317335126507279 0.7318395535151164 0.031129706339572138 0.6774539073308309 0.0667893267861601 0.6973702748616536 0.03667826843420083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracyresultlist=[]\n",
    "precisionresultlist=[]\n",
    "recallresultlist=[]\n",
    "flist=[]\n",
    "for train_index, test_index in kfold.split(X, Y):\n",
    "    # split data into train/test sets\n",
    "    x_train_tfidf = X.iloc[train_index]\n",
    "    y_train_tfidf = Y.iloc[train_index]\n",
    "    x_test_tfidf = X.iloc[test_index]\n",
    "    y_test_tfidf = Y.iloc[test_index]\n",
    "    trainX, validateX, trainyp, validatey = train_test_split(x_train_tfidf, y_train_tfidf, test_size=0.2, random_state=1989)\n",
    "    trainyp=trainyp.reset_index(drop=True)\n",
    "    trainX=trainX.reset_index(drop=True)\n",
    "    validatey=validatey.reset_index(drop=True)\n",
    "    validateX=validateX.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    trainy=trainyp.fillna(-1)\n",
    "    validatey=validatey.fillna(-1)\n",
    "    Testy=pd.DataFrame(y_test_tfidf).fillna(-1)\n",
    "\n",
    "    trainy=trainy.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    validatey=validatey.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    Testy=Testy.replace(['Not defined','Susceptible-dose dependent',0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    #print(trainy)\n",
    "    train_labels = np.array(trainy).astype(np.float32)\n",
    "    val_labels = np.array(validatey).astype(np.float32)\n",
    "    test_labels = np.array(Testy).astype(np.float32)\n",
    "    train_features = np.array(trainX).astype(np.float32)\n",
    "    val_features = np.array(validateX).astype(np.float32)\n",
    "    test_features = np.array(x_test_tfidf).astype(np.float32)\n",
    "    \n",
    "    #weight2=weight[:,1:3]\n",
    "    model = make_model(train_features)\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss= masked_loss_function,\n",
    "      metrics=METRICS)\n",
    "    #model.summary()\n",
    "    baseline_history = model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(val_features, val_labels))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    results = model.evaluate(test_features, test_labels, batch_size=BATCH_SIZE, verbose=1)\n",
    "    print (results)\n",
    "    accuracyresultlist.append(results[1])\n",
    "    precisionresultlist.append(results[2])\n",
    "    recallresultlist.append(results[3])\n",
    "    flist.append(results[4])\n",
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8240759174029032 0.014317335126507279 0.7318395535151164 0.031129706339572138 0.6774539073308309 0.0667893267861601 0.6973702748616536 0.03667826843420083\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Loss','Accuracy'], 0,['loss','masked_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEGCAYAAACzYDhlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABgTElEQVR4nO3dd1zWVfvA8c9hgywBQcWBW1Fx76050hyVDbPSTEvbe/erp/X0tJdllg3L0rQyrdx7b9wDRWQqArL3fZ/fHwcQBGTdCz3v14sX3Ov7PaBw3ed8r3NdQkqJpmmappmTnbUHoGmapl37dLDRNE3TzE4HG03TNM3sdLDRNE3TzE4HG03TNM3sHKw9AFvl5+cng4KCrD0MTdO0WmXfvn0JUsp6V96vg005goKC2Lt3r7WHoWmaVqsIIc6Vdb9eRtM0TdPMTgcbTdM0zex0sNE0TdPMTgcbTdM0zex0sNE0TdPMTgcbTdM0zex0sNE0TdPMTgcbTbsWpcRA6K+gW4hoNkJv6tS0a9HWj2HPN2DIhW5TrD0aTdMzG027JoVvUJ9XvgAXT1p3LJqGDjaadm2asQHuXwOOrrDsMb2cplmdXkbTtGuRiyc07gm3zwePBiCEtUekXef0zOYKQoixQoi5KSkp1h6KplXPmv+D/T+pr4P6g28LNbNJjrTuuLTrmg42V5BSLpdSPuDl5WXtoWha1eVmws45EH+s5P3r34KvB0JqrHXGpV33dLDRtGtJxBYw5EDLG0re32kS5OfC7zPAaLDO2DSzkLXkepwONpp2LQlbA45u0LRfyfv9WsLo9+HcVtjykXXGpplEZm4+q4+e54XfD9HrnbUMeG9DUcDZH3mJ0/HpGIy2F4B0goCmXSukhNNrIGgAOLqUfrzzXXBmPWz8LzQbAE16W36MtYTRKPlmSzg/bI+gpb87PYN8GNYugOCGnlYd15cbT/PJ2jBy8424OzswsLUfXZvURRQkgLz0x2FOnE/Dzcme4AaedAj0ol9LP4YHB1h13KCDjaZdO3IzoG4QtB1d9uNCwE0fw6UIyMu05Mhqnad+C2VpaCy9mvlwMS2HD9ecItdgJLihJ5m5+czZFE6vZj50aeKNm5Pp/4zmG4wciEpm3fF4NpyIZ8493WjmV4e29T24p3dThrX1p3uQD04OJRenPr2zC4eikzkam8qRmBQW7YniUmYuw4MDkFJy3w97aFzXjQ6BKhC18vcodQxzEbVlvc/SunfvLnVbaO2aJKVOha7AxpPxxCZnM6lnY4QQXMrIxSglvu7O7I+8xMSvtmOU4GAnCGnkRc9mvtzVswlNfN1qdN7oS5l8sOokG09dJDkzDwc7Qc9mPrw0uh0dAquetGQwStJz8vFydSQjJ5/7f9zD0ZhU0nLyAXCyt+PZkW2YMbA5uflGjsWl0ra+By6O9tX+HoQQ+6SU3Uvdr4NN2XSw0Wqd3AxwqlO55xqNsO1jqOMPXe8x77hqgdx8Ix+sPomXqyMPD2lZ4fPTsvPYe+4Su88msftsEoeik/l9Vl9CGnmz/XQC607E06uZDz2CfKhbx6nMY0gpOXMxnXXH42ns48bojg1Izsxl+MebGdDKj2FtAxjQ2g9PF0eTfq9GoyQyKZMjsSkcjklhUKt69G3px+HoFMZ+sZVP7ujMhC6B1T6+DjZVpIONVqvkZcF7LWDIS9D3kYqfbzTCzzdD5C54YCP4tzX7EG1VREIGjy08wKHoFKb2DeK1scFF10AqKyvXgJODHfZ2gu+2nuXdlSfIzTcC0La+R9HsxMXRnm2nE1hz7ALrT8QTmaSWM+/s0Zh3bw0BVBCq6vlNISUrjx1nEujatC7+HmVc86uk8oKNvmaj2Zx/DsWxIzyBJ29oja+7s7WHUztEbIW8jMoHDTs7uPlr+KofLJkGM9aXnVRgToUp2HbVX7KpqaUHYnj5z8M42Nsx5+5ujOpQv1rHcXW6/D1M69+Myb2bcDAqhd1nE9l1NoktYQk4F1wb+WxdGKFRyfRr6ccDA5sztK0/Db1di15vjUAD4OXqyKgODcx2fD2zKYee2VhPTHIW/d5dT103R/5vbDATOgda7Rew1vj3Odg/H56PqFrQCFsDCyZCzwdUanQFPll7igupOdzQzp++LfxK/JGtkuN/wz9Pw+j3IHg8RO9VWXLu9cEj4PLnoAHg5mOW60wRCRkM+2gTXZt488mdXQgs9gff1IrPVqKSMvFzd67+z87G6ZmNZvO2n0mge1MfAr1dWfXEQF744xBPLjrInwdieXtCBxr71Oziq6kZjRI7OxsJgqfXqHTmqs5OWg2HPo/Azq+g10xV2qYYKSUfrj7FoDb16BHkQ3JmHstCY/h1dyQujnb0a+HHuM4NGd+5kmv8GYmw4lk48jsEdID6HdX9eZmQcRHOH4GMeJBqCYrp61SwCV0AK18Cd3/wqA/uAepzv8fVfalxkJ2isvEq+BmcT8mmvpcLQX51+HVGb7o28cbB3rwZWcXfLNna/2NL0Zs6NZvwz6E47v52F19uPA1Am/oeLJnZl/+Ma8++iCQ+WG0bZfKTMnIB9Ud49GdbeHJRKJtPXbTuJrrEM5AUDi2HV+/1w/4Ppq8tFWjyDEaeXnyQLzacZt3xeABeH9ee/f83nJ/u78mdPZpwKj6NbacTAPUz+XLjaUKjkjGW9fM4/jfM7gnHlsGQV9S1Ip/m6rFmA+HBzfDMSXg1AZ4Jgwe3gH+wety3FXS6AwKCwZAHMXthzzz1NcCBn+HLXvBVX8hJL/PbNBol324JZ+B7G9h4Un0/PZv5mD3QaIpeRiuHXkaznHXHL/DgT/vo3Nib+ff3LLVvISY5C0d7gb+HCxEJGWTlGWjXwLKb647FpvLRmlPsO5fE5ueGYCcEb/1znH8OxZKanU+ApzPjOwdyV88mBPlVMiPMVDIS4fBiaDsGvBvX7FiRO6FRDzLzJQ8t2M/Gkxd5anhrHh3assylTCklOflGXBztiUjIYOiHGzFKqOfhzNA2/gxt58+AVn7q33TPPLXUN+FLCGhfs3Gqk6vPQkDCadXD599noO9jMOLNEk9NSM/hmcUH2XjyIsODA3jv1pBys8S0mtHZaFWkg41lbA1LYNqPe2hb34Ofp/eqMM1z5k/7WHv8Ag8Oas6jQ1vVaD9AZZyOT+fjtaf451AcHi4OPDiwOdP6NysKiNl5BtafiOeP/TFsPBnP7MldGdm+PkkZueQbjPh7Wviie03E7IdvhpAz4AXuODGQQ9HJvH1zRyb1bFLpQ1zKyGXjqXjWHY9n06l4BuVuZcaAIDrdOJ2EtCxy8vIJ9PEw3/fw18NwcCHM3Ar+7QDYdjqBJxaFkpKVx6tj2nF376b6GqAZ6WBTRTrYmF92noGB722grpsTCx/oXal3mpcycnn73+Ms2RdNc786vHNLR3o39zXL+MIvpnPDR5twdbRnWv9mTO/fHC+38oNhYnoOHi6OODnY8fGaU3y+Poz+repxa9dARgTXN88F4bxsOLYUWo1Q1zZqQkr4YwbyyO983uQz2vQczsj21cvOIu0Cxr+fwu7k3xiaDcb+3qV8seE0H6w+Rdv6Hgxr58+wdgGEBHqZdhkrIxG+6Abtb4GbVA24X3ZF8t22s3w+qYvFZ8TXIx1sqkgHG8s4EpOCv6dzlfP6t4Yl8NKfh4lMymT2XV0ZE2KalM3Y5Cz2nbvE2E4NAfh55zlu7FC/yinY4RfT+X1/NEsPxBKTnEUdJ3vGdW7IOzd3NO276tNr4edbYfISdbG/Bk6cT8VLZNNg4XCVljxzC7jWrdpBpFRLeiueU+0OhrykEhDsHYhMzGTl0TjWHY9n77lLGIwSL1dHQv9vOEIIlh6IISUrjyC/OgT5uhHo7Vq9QBR/gii7QE4nZDGkrX+JpT7N/HSwqSIdbMznxPlUdpxJ5L5+zWp0nKxcA99uCef+AWpZ61JGbrXX4ePTsvlywxl+2RWJo71g50vD8DDBzm2jUbLrbBJ/HojGYIQPb+8EwE87Iujd3JdWATVcUlrxAuz7viDlufqpu7vCE5k+fy+dG3vz00gH+G4EtBmtOn1WJThG74Vvh0GjHjD+S6jXusynJWfmsjksgcT0nKL/B3d9s5PtZxKLnuNgJ+jfyo8f7usJwKqj53FxtK8wEC07GMvLfxymoXMWyx4bhLN7FQOmViM62FSRDjbmEX4xndu/3om9Hax+chBerqYpxZGdZ+DGT7fQyt+dN8Z3oL5X5WZKyZm5zNkUzo/bI8g1GJnYtRGPDmtJo7rmS0+9mJZDn/+uI98o6Rjoxc1dAhnXuSF+1dnA+nk3le579+/VHs+qo+d59NcDNKrryvxpPdX3vvMrcHCGbvdVHGykVM3aCi/6n1oNLYdVebOmlJKL6TlEJGQSkZBBRGIGHi6OzBqssuT6/ncdsSnZADjaCxrXdWNMSAOeHtEGUAHz9/3R/LY3mv6NnfgxfSb2HW+p1P4hzXR0sKkiHWxMLyopk9u/3kFuvpFFD/ahpb+7yY6dbzAyb+tZPlpzCid7O56/sS139WxS4T6YswkZjPh4E2M6NuDxG1rTzEKZZBfTclh2MJY/D0RzJCYVezvB7Lu6Vm0He9JZ+KwzjPof9J5ZrXH8siuSV5YeJqSRN99N7YFPWTPDq22oTI2F5Y+r1gWzdpQ7kzGF+NRsIhIvB6KIxAw6BHrx0OCW5BuMtH11JQYpeXhwS564oRUOq56HPd/CjA3QsLPZxqWVpINNFelgY1rnU7K5/esdpGTl8euM3mbrCxKRkMFLfx5m+5lEegTV5et7upf4A5qZm8+P289xOj69aEkrPi27RrWgaurUhTT+PBDDzEEt8HJ1ZOPJeFKz8xndof7Vr1mE/gpLZ8Kj+0vtkamM3Hwj42dvo76nM7Mndy27VP7RpbDzS7j3r5LLdFKqvS2rXgZDLtzwmqpCYKXSM/kGI/sjk/FydaRN/YKlyaxk+KIHeDeB+9eoEj2a2ekKAppV7TqbyKXMXH66v5dZG1AF+dVhwfReLN4Xzb+H44qW6bLzDPyyK5IvN54mIT2XIW3qkZNvwNnB3qqBBqB1gAfPj7pc02zRnihWHDnP/7xdmdo3iDt6Ni47JbzzJAjqX+W9NQajJM+gLpgvmN4LDxcHHMsLak7uELULVr8CYz5U9xmNsHASnFqpOoKO+7xawc6UHOzt6Nnsimw8V28Y8Rb8+QAcmA/dplpjaFoBPbMph57ZmEbxmlBJGbllL9OYWWJ6Dr3eUddI+jT35ZmRrenWtIZpwmZkNEo2nIzn2y1n2RGeSB0ne54c3prpA5rX+NjZeQaeWBhKvtHI3Hu6V67czqqXYccXcMcCaHeTum/zB+DiBd3vt+0Zg5Tww03g21wFRc3s9MxGs7i07DwemL+Ph4e0pH8rP6sEGlAVCCZ0CeSWLoH0belnlTFUhZ2dYFi7AIa1C+BITArztp4t+tmlZedx6kI63eRR2D0XRr0Lng0rddyUrDwemL+XXWeTePWm4MrXdRv2mqoqvWgy3PUbtB4JA5+p7rdnWULA5MXgdH3WI7MlOthoZpGVa+D+H/ayP/ISWXkGq44lpJE3H9zmbdUxVFeHQC8+vqNz0e3Fe6N54+9jfF73N0bnrECO+7JSv8Txqdnc+91uzlxM59M7O1e+cCaAgxNM/A7+nAnZqVX+HqyuMNAkhEF+9uXin5pF6WCjmVxOvoEHftrL3nNJfHpnF4YHB1h7SNeMO3o0xk5AyNo9bM1vy8uf7ua+fs2Y1i+o3M2iUkpmzN9LZFIm86b0YGDrelU/sW8LmL6mhqO3IqMBFtymrkE9sBHs9Z8+S7PhxVatNsozGHnklwNsCUvgf7eGFO3E10yjjrMDU4MFTWUM/l1vooGXC2uPXSgKNClZeaVeI4TgP+M7sPCB3tULNNcCO3sY/h+4cBj2fGPt0VyXdHjXTMpOCLxdHXlzfHtu617DCsRa2U6vBaDdgFtY7NeKjJx8AC6kZjPo/Q0MD67PjAHNSM7M43BMCg8PaUnnxt5WHLCNaDcOWt4A69+G9jerfjiaxehgY+N+2RXJ/1aeoJW/O8ENPWnf0JMRwfVtrjy60ShJzsrDp44T700M0VV1zcmxjiq86dsSULMdAHs7wT29m7JwdxTLD8YiBLSt78n9/ZvpumCgkgVufA++7KMy7CbOs/aIris69bkctpD6LKVk2EebyM030sDLheNxaaTn5LP+6UE0r+fOP4fiWHPsPO0behHc0JPgBp5WCUJSSl5fdpT1J+NZ/kh/vN1sKxBeb9Ky81i0J4ozFzN4cXTbCts2XHc2vQ/ZyTD8TdtO266ldOpzLSSE4Ou7u5GRa6BzY2+MRknUpUwaF9TtSkjPYWd4EktDY4teE+jtyrqnB+HiaM/p+DSc7O1p7ONao5mGlJKsPAMpWXnYC4G/pwtGo2TJ/mhSs9RSzV+hscwY0Mxktc60cmQlg6ObyhArh4eLo0n25FyzBj1r7RFcl3SwuYIQYiwwtmXLltYeCkCJqsB2doKmvpdrd03pG8SUvkEkpudwPC6NY3EpxKVkFy2ZvLviBGuPx+Ph7EC7Bp4EN/SkSxPvorTXTacuciE1m9SsPFKy8kjNyqN5PXem9A0CYPzsbcRcyiQlK488g5oB39q1ER/e3gkh4JU/j5BrMGIn4L5+Qbw0up1ePjO3ze/DwV/h6ZNgrwN7jYRvguRI6HqPtUdyXdDB5gpSyuXA8u7du8+w5jiycg28svQI0wc0q7Dhk6+7M/1bOdO/VckNi08Nb8OwdgEci03lWFwqv+2N4mhsSlGweWP5Uc5czADUcraniyPD2vkXvT4k0IvgBp54uzni5ao+Wge4FzxfsOHZwbg7O+Dh7FD5DYJazYStgfohOtCYwu65cHodNB+k6qdpZqWDjY1acSSO3/dHc3v3RtU+RnBDzxJ1yIxGWSI1du693XGyt8PT1bHMgPHmhA5XPX6gd/X7p2jVkBwJCSeh670WP3VSRi6hUZfIM0jshcDOTmUe2tuJgtvqazshsBMUfW1f7H71mRL3e7k6Wi95YdS7MLsnrHwR7lxgnTFcR3SwsVGL90bT1NetdHHBGrCzEyUSCFrUM12Jf80Cwgo2VdawI2dlpGXnsftsEtvPJLL9TCLH48xXOcC3jhMNvF1o4OVKQy8XGni70sBL3W7g5UJ9L5fyC4XWhHdjGPQcrH0dTq1SZXg0s9HBxgZFJWWyIzyRp4e31tdAtMtOrwWvJuBn+p4x2XkG9p+7xLYzCWw/k8ih6BQMRomTgx3dm9bl2ZFt6BHkQx1ne4xGMEiJwSgxFn42SgxSYpRqBm0ovF3wufC5ha81GiX5RsmljFxiU7KJS8kiMjGTneGJpGXnlxibEFDP3ZkG3gXByMuVht4qCBV+7e/hgn11lnJ7P6xaNfz7LDQbWKNup9rV6WBjgxbvi0YIuLVb9ZfQtGtQ/6cgI75qbZrLkWcwcig6hR1nEth2OpF9kZfIzTdibyfo1MiLWYNa0LelL12b1LX4Mld6Tj5xyVnEFQSh2GT1OS4lm1MX0th06iKZuSXr7dnbCQI8nGkf6MUjQ1rSqbKbWB2c4KaPIP442OuUfXPS+2zKYc19Nt9uCedYXCof3d7ZKufXrj1Go+T4+VR2FCyL7QpPJKPgD3ZwA0/6tvClX0s/ejTzwd3Ztt+DSilJzconNiWrZDBKzmb9yXiSM/O4oV0ATw1vbdbeSVrZdKfOKrKFTZ2aVuTEv+BUR2VOVYKUkvCEDLafSWTHmQR2nEnkUqZKDmlerw59W/jSt4UfvZv7Wq31gzmkZefx/bYIvtkSTlp2PmNCGvDkDa1o6e9R8YsPLYaw1XDLXJPMHq9XelNnLXEsNpXWAe5XbwesXX/WvQEeAaWCTVaugbMJGZy5mE74RfX5zMV0ziZkFC01NfRyYVi7APq28KVPC18aeF271yU8XBx5bFgrpvQJ4pst4Xy/7SwrDscxoXMgj9/QqsQ+tVIyE+Hwb9B2DLSfYLExXy/0zKYc1pjZpGbn0eOttUzpqzZIarZJSsnhmBTyjbJo/5GniyNODuZ5gyCToxCfdOBs15fYWu8Ozly8HFxikrOKnieESkdvUc+d5vXq0DrAgz7NfWnq63bdJpokpufw9eZw5u+IIM8gua1bIx4Z2pJGdctopmbIh28GQ0YiPLIbnCsxG9JK0TObWuDvg3Hk5BsZ3bGBtYdSdVJe80sP8anZLNkfzW97oohIzCz1uKujfVHw8XJ1xLPY1+q2Q4nbxZ/n4mhPdp6BiMQMzsRnEF4wQwlPyKBr/FJet4MZO7w5LY/i5mRPi3ru9Aiqyx31GhcFl2Z+dXTBzSv4ujvz0uh2TO/fjC83nuGXXZH8vj+aST2b8PCQlgR4ulx+sr0DjPkI5g2Hjf+FgI4QvhG6TYWmfaz1LVwz9MymHNaY2dz85TbSs/NZ/eTA2vVOdM882DUHHtqp+oZcQ/INRjadusjCPVGsPxGPwSjp1cyH27o3xreOE6nZqtRPSmbB58LSP9l5pGTlF5UCSs/Jv+p5nBzsyDMYKf7rGOjtSvN6dXgp9S0a54Rx8NYttPD3IMDTuXb9/7AhsclZfL7+NIv3RhVVyZ45uAV+7s7qCfk58OM4iNqpbts7gyEHQu6E4QVLmdpV6ZmNjTsdn8aByGReGt22dv0hidwF/zxV8PVOCOpn3fGYSGRiJr/tjWLxvigupObg5+7MjAHNub17I5pXYzNsvsFIanZ+UQ26lCs+UrPycC2YsRTOUtycHNSM8dNz0H4U/Vpdp43PTKihtyv/vaUjswa14NN1YXy37Sy/7I5keq/6zPLYjOueLyEtTrVvGPEWBA2ALR/C9s/h5L8w+EXoOcPmywUZjZKM3Hwycgyk5+STkZNfdDsjJ5/0nHwyc/NJL7h9+T71/PnTepp8lqyDjY3459B57O0EE7pUoTe8Lbh4/PLXx5fV6mCTnWdg9bELLNoTybbTidgJGNzGnzfGN2ZoW/8a7WJ3sLfDp45T1TO/hIDHDkBuerXPrZXWxNeND2/vxMP9/Dny54f03b0IV5FKtGdX6t75BXXaDFM/+7xsuOE16DwZVj4Pq16EAz+pvjjNBlj1eziXmMEP2yM4GptaLGCo4JGVZ6j4AAXqONlTx9kBd2cH6jg74OZkT67BaPJgo5fRymHpZTSDUXI8LpUOgV4WO6dJrHpZLaM1HwTnD8OTR2vdtZsT51NZtCeKPw/EkJyZR6O6rtzRvTETuze6pjO3rmuZSWrpd9ccyE4hvfFgvjLczOzweni5OvLgoObcX2cbzlveg+lrwLOhmmWe/BdWvqDq1HW4Vc1+PC3b+nzfuUt8uyWcVUfVG9QuTeri6VIYKBxwd74cPNycHKjjbF8USNwLgknhbVdHe5MX0dXLaDbO3k7UvkADkBAGvi0geAKcWgmx+yGwm7VHVaH0nHz+PhjLwj1RhEYl42Rvx8gO9bmzR2P6NPe1nSrWv9wBLYZBrwesPZJrQ9oF2PGFeoOUlwFtb4KBz+DesAvPAjfGpPDRmlO8t/Ikm+vkMp9L2H8zHPspf4FfS5UW3WIobP0Ytn6iaqoNeg56zbpqj6GaMhglq4+e55st4eyPTMbTxYGZg1owpW9QySQHG6ZnNuWw5MzmlaWHaeDlysNDbKOHTpV81kWVvB/7CWx8F3o+oIKPDZJSsj8ymUV7Ivn7UByZuQZaB7hzZ48m3Nwl0OZabZMSDR+3Vxem+z1u7dHUbslRsP0z2D8fDLlqVtL/KQgILvPp+85d4uM1p0g+s5sfnd7D0V6wrffX9Ow7FN/CZIKks6pi9KkVql7dje9BiyEmHXZGTj6L90bx3bYIIpMyaezjyv39mnFb98ZF7cBtjZ7Z2KikjFwW7Yni3j5B1h5K1UkJjXpCk17gWhdu/J+1R1Sm2OQs/j0cx6I9UYTFp+PmZM+4Tg25o0djOjf2tt2EjNNr1eeW5q/yfM1KPKNmIQcXAhI6TYL+T1b4hqhb07r8PL0Xx2LbsXR3G8YcfJj+2+5jxMYPaNG8FWNCGjCyfSA+dy1Us5sVz8NPE6DdOBj5jqooXQMXUrP5YXsEv+yKJCUrj65NvHnxxraMaF+/egVHbYCe2ZTDUjOb77ed5T/Lj7HyiQG0rV/L6zgZDRC1C7wa1/iXrSYMRsnB6GTWH49n3Yn4ovL4XZp4c2ePxowJaWjz9b8AWDgZYg/UyutgVhd/HLZ8BEeWgJ0jdJsCfR+r9v9LmRLD+T1L+dkwjH8Pn+dsQgb2doK+LXwZ3bEBI9t44xP6tcpcEwIGPA19HwUH5yqd53hcKt9uOcuygzEYjJKR7eszfUBzujWtW61xW4OujVZFlgo2N366BQc7wfJH+5v9XCZnyFf7agr/EKbHwwetYdDzMORFiw4lLTuPLWEJrDsez8aT8SRm5GJvJ+jetC7D2vkzrF1A7erfk58L7zWHDrfAuM+sPRrzyM9VWXbCruBDFPvaDhBXPFaJgBsbCls+gOPLwbEO9JgGfR4Bj/omG7aM2kNs2D5+yRvMP4fiiEjMLAo8E1tKboz+DKewf8CnuVpaq6D/kJSSzWEJfLslnC1hCbg62nN790ZM69/s6uV1bJReRrNBR2JSOB6Xyhvj21t7KNWz/TO1/+CpY6oPiLs/NOmjftEtEGwiEjJYdyKe9ScusPtsEnkGVT5mSJt6DG0XwKBW9fBys+39EOXKSYN2YyF4nLVHYlpSqv1YoT/D0aVVT+kuMwgVC065aeDsBQOfg96zwM10zQeLhrDnGwIPLeLZoa/yzNNPcex8Gv8ciuPfw3E8viKTp+zu5oHAfszKnIvngonQZgyMegfqBpU4Tk6+gWWhsczbepYT59Pw93Dm2ZFtmNyrCd5uNnb90AR0sLEiF0c7bukayLhOlk2dNJnE06oHSPGGU+3Gqr0IiWdMniiQZzCy79wl1p+IZ+3xC4RfzACglb870/o344Z2AXRp7H1tFDGt4ws3f2XtUZhOSgwc/BVCf4GkM2rW0f5mqN9BBSBpVB8U+1rKy4+Vut94xWsK7vMMhK73gIsZMzvHz1bnW/8mIjOJ9iPeon1DL54d2Yajsan8eziOfw678m3iG0x3WMHjp/7EIawneb0fx3XIUyTn2bNgVyQ/bI/gYloObet78MFtnRjbqQHODtdWBY7i9DJaOXSLgUr4drhak5769+X7kqPgkw5ww+vqQmwNXcrIZdOpi6w7Ec+mk/GkZufjZG9Hr+Y+DGvrz9C2ATTxLaOoYm2XeEYtw9TmazV52WpfyoGfIXyDCgZN+6kNksHjwbkWLWteyWiEVS/Brq9UKZvxX5SoKiCl5GhsKv8cjmPPwcNMSf+WsfY7uWBfn+/yRrAirwtNW7ZnxoDmDGjlZ7tJKtWgl9FszJGYFOyEqN3NnRLD1LvT4rwbQ8MucGZDtYJNVq6BE+dT2RmexPoTF9h37hJGCX7uzozqUJ+hbQPo38qvdlzgr67UWPi8q1rv7/WgtUdTNVJCXCgcWACHF0N2Mng2UhfMO9+lAui1wM4ORv1XzUBjQ4GSwUIItW+uQ6AXcmQbjsaO4Nety+l+6iNetJvPi87zIbsdRI4C19Fqb5ot1BU0GtX3ZgbX8G+sbftw9UmOx6Wx7YWhtTOVMSMRsi6Bb6vSj90+HzwqrlydmJ7DsbhUjsamciw2lWNxqYRfTMdYMNlu39CTR4a0ZGi7AEICvWxno6W5FaY8B9WipJGMBDi0SAWZ+KOqgGW7m6DL3dBskG38ITU1IWDgs5f/QKedVzN917pXPK0g8NxxN3C32p9zaiWcXKGueW79GOrUg9Yjoc1oaD5YNcqzBmM+ZKVCHT+TH1oHGyu4kJrNplMXmTW4Re0MNKCWRPo+Vnbpde8mJW4ajZKoS5kciy0ILHGpHI1N4UJqTtFzGnq5ENzQi9EdGxDcwJPOjb2p71U7dkabXNga8GgI/mVvOLQZhnw4vUYtk51aqf5QNewKYz5UmyZda0+6bo3Y2amA88sdYMiDu38Hz6u82fJpppIXes+CrGT15uLkCji2XP0sHVxUgG5zI7QedfVjmUpWsvqddvMBYZ5/Nx1srOCP/TEYJUzsZr29KDXmXg9GvFnq7px8A2EX0sndPge7uFDecXqMY3GpRSX27e0ELeu507eFH8ENPGnf0JN2DTxtb/e+tRjyVA+V9hNs93pN/AmVTXZwEWTEq3flvWaqazHl7Mi/5tnZqeuUCyfDdyPgnqWVS5Bx9YaOE9WHIQ/ObVeB5+S/ELZKPadhVzXjaXMjBLSv+f8LQz6kxkBKlKrxdvGkqqxgzAdXH1X1+oVzJRN/TEAHGwuTUrJ4bxQ9gurSzK/25dAXSTsPzh5IRzeWH4pj08mLHI1N4XR8OvlGyZMOJ3jEfgV1/O/hlq5NCG7gSXBDT1oHeFi+wdeZ9bD0IbhvhXpXacuidkNOqu1VDTAaVLXj/fMhZh/YOUCrkWqZrNVwmy+5bxEthsDU5bDgNvhupJrhNOhU+dfbO6qCts0HqetBF0+ooHNyBWx4Gza8BV5NoM0oFXia9i+7Hltetip1lBKpEnYKg0rh16kxBVl8V/BtBQ1C1KZsQ67Jg43ORiuHubLRIhMzGfXpZl4f257be9Timc2vk5CXIniz8Ty+23YWP3dnOgR6FgWVzk4xNFp4A4z9VHU6tKbZvVUrhNEfqF4ktiwnTSVXNB8MLjaSPJKbAb9PV3/4/IPVDCbkDjW71Uq7eAp+uhm8AmHaKtPMUNMuqJnOyRXq/0d+Fjh7Qsthatk6uSCgpERB+oWSrxV2KiXcu8nl6h7eTVT6+fo31LEn/Wqyum66gkAVmTP1OT0nHwc7Uatb+Bo/787BnAbcnDCTaf2a8cqYdiUv4EupinT6NId7/rDeQGMPwNzBKjPuhtetN47aKu28uhZx/hCMKii0aqvLe7YkJUb9nApbE5jyZ5abCWc3qcBzaqVql+DduFggaVoyqHg0VC2vrzR/AkTvgcmLoWlfkw1Ppz7bAKNRIgS1Pm03NSMTt8RwtuUH89LotswY0Lz0PgEh1O73HbPVxUdXb2sMFXZ8CU4el9Ow0y7YbmvftAsQukAVi7TEReGKXDgGv9wOmYlw5y9q6UarHK+CJohGg5oVthymlhxNwclN/Vu0ufHyxtfqpCuP/URlETYqFRfM4hrYal17LA2N4cZPtxCflm3toVTbhdRsnpqzFAcM9OnRmwcGtih/Q1rwBFUFNyfVomMsIqX6pe89S+0oP7hQlexPPGOd8VQkbDWs+w9kJlh7JHB6nbruYMhT17p0oKme/By11+ivh2Hbp6Y/vhBVCzQJp2HNayp7rm6QxQINXGfBRgjRXAgxTwixxBrnX7w3msxcA/Xcq1YJ1lacjk/jli+345ISDkC3bj2v/oLArnDb96VSoS1GCLV0NvRldbvFUHVhe9N71hlPRU6vUfuTAjpYdxz7flQXub0aw4x10LCzdcdTmzm5waRF0P4WWPN/sPoV9SbIGuKPw/c3qvTq1BiLn96swUYI4S2EWCKEOCGEOC6EKGNTRqWO850QIl4IcaSMx0YJIU4KIU4LIV642nGklOFSyvurM4aaikrKZEd4IhO7NaqVpSn2nUti4pwd5OQbeXTSOBj1P6jXpnIvTjyj1pktKTdDZaEV/8V294ce98Ph31SHUVtiyIczG9Vyi7X+fxiNsPZ1WP6YSlCYthK8GllnLNcSBye49VvoMV1t4vz7CcuPIe4Q/DBGJQvc969VWoCYe2bzKbBSStkW6AQcL/6gEMJfCOFxxX1ltav8ARh15Z1CCHtgNnAjEAxMEkIECyE6CiH+vuLD3zTfUvUs2ReNEHBrt9r3y7vm2AXu+mYXdd2c+GNWX9q0C4HeM8HZo+IXR+1RpVfCVpt/oMWF/qIygmL2l7y/3xNq05ytzW6id0NOCrQaYZ3z52XD79PUbvZuU+GuRbaTDXctsLNX2ZBjP1V14UBV4Ijabf5zx+yDH8eCg6sKNJV9k2hiZgs2QggvYCAwD0BKmSulTL7iaYOApUII54LXzAA+v/JYUsrNQFIZp+kJnC6YseQCC4HxUsrDUsqbrviIr+S4xwoh5qakpFTyO62Y0ShZsi+afi38CPQ2be66uf2yK5IHf9pL2/oeLJnZRxW9jNypUi0rI7AruPmptgOWYjTCzq9UvanAriUfc6+n0p9P/quyeGxFQphKRW0+2PLnzkiA+ePg6J+qBfVNn+h9M+YghArkLYaq27u/hXnD1ZJl7AHznTc7FdwDVKCxYst2c85smgEXge+FEAeEEN8KIUrsYpRSLgZWAYuEEJOBacBtVThHIFD8r150wX1lEkL4CiHmAF2EEGU2XJFSLpdSPuDlZboS5UYpeWp4a2YNtt4/dFVJKflozSle+vMwg1rX49cHel/uvb7wLtj8fuUOZGcPbUer1rn5ORU/3xTCVqky9r0fKntJqv+T8Oh+s/Q6qbZuU+C5cPOWxi9LQhh8e4MqJnnbD9DvcZ3abCl9HlLXFKN2q/T8hZPhwlHTHT+94P11iyEwazvUbWq6Y1eDOYONA9AV+EpK2QXIAEpdU5FSvgdkA18B46SUVeymVHlSykQp5UwpZQsp5X/NdZ4rOdjbcWu3RvRrafriduaQbzDy4h+H+WxdGLd1a8Tce7vj5lSQrp2ZpFJh/coowFmeduNVU6vwjWYZbyk7ZqtKw4XLFVdyravSn6W0/LWkshT+gXG0cC24iG0q0OSkqTYRV1bw1szLqY564/PEIRj8IpzdDOveMM2xT6+FTzvBsb/U7bL22ViYOYNNNBAtpdxVcHsJKviUIIQYAHQA/gReq+I5YoDiV7oaFdxnM9Ky8/hmczhJGbnWHkqlZOUaePCnfSzcE8UjQ1ry3sQQHIs3I0s8rT77ta78QZsNVN0Tjy8z7WDLkpmkxtjrgasvBUkJP9+qUlKtKWo3fNVPZYBZ0qHf4KcJqq7Z9LXQuILMQs18XLxg8Avw+EEYXbBikBSuSiwlna368U6ugF8ngU8L1T/IRpgt2EgpzwNRQojCq1HDgGPFnyOE6ALMBcYD9wG+Qoi3qnCaPUArIUQzIYQTcCdggb9olff3oTje/vc4kUk28A66AkkZudz17U7Wn4znzQkdeGZkm9KZc4VZXL5l5XGUw8FJXXAeUZV/2mpy84HHD6md7lcjhKpbdfRPlRJqDfk5sOxRVUqkwy2WOaeUsPF/8McMaNQT7l9t+/XirhduPpe3CcTshyO/wxfdYfnjqtZZZRz7CxbdrQp2TllmllYB1WXubLRHgQVCiENAZ+CdKx53A26XUp6RUhqBe4FzVx5ECPErsANoI4SIFkLcDyClzAceQV33OQ78JqU04aJnzS3eG0Urf3c6NbLwWnwVRSVlMnHOdo7GpvLV5G7c07uc9d2EU2DnqEpiVEXTPuYvOZ+boTYhOjhVrohg30fByR02vmvecZVn68eq2OJNH1cus6+m8nPVu+WN76jukvf8aVvXrbTLOk6Ex0Kh232qR9BnXWDVy1d/zcWTsPg+lRhz7182929r1oU8KWUoUO4WVSnltitu5wHflPG8SVc5xr/Av9Ufpfmcjk9nf2QyL41ua9N7a47GpjD1+z3k5BlYML0XPYKu8p+0x/1qWaw6a8B7v1Pv5nvPqv5gr2brx6pKwMO7Ktd8ys1HdcLc8oG6bhLQ3jzjKkv8cdj8AXS8DVpbIN056xIsugcitqjrA4Oe14kAts6zAYz5APo9phJyjPmXH8tOKZ1MUq8NjJ8N7cbaZMvt66qCgKUt2ReNvZ1gQpdyE+SsbvvpBO74eicOdoIls/pePdCAmua3HFa9k53ZAFs/UanJppabCXvmqaWxqnQ57POwqp6780vTj+lqUmPU8tUoC8yqLkXAvBEqZf3muer6gA40tYd3Exj3+eX/K+e2w0fBKpkg65K63leYOt15kk0GGtDBxqwupGYztK0//h622XFy2cFYpny/m0BvV/54qC+tAypYyjHkw55vq19brN04SD+vKs2a2qGFkJWk0p2rws1H9R0Z/YHpx3Q1LW+Ah3aZf009ei98M0ylwd67FDrdYd7zaeZT+AbBPUD1ENryIXzcQVV82DnHumOrBB1szOjjOzrz1eRSCXg24dst4Tz26wG6NKnLbzP70MCrEtc4ks/BP0+rd8jV0Xok2DuZPiutcBNng87VK5XeuKe6xmOOGdeVkqPUHwajoXqVeqvi2F+qRImzu8o4C+pv3vNpluHbQu2JmrlVbRDtfLea+dg4HWzMJDU7D1B7bGyJlJK3/znGW/8c58YO9Zk/rSderpXcLV6YiVaVPTbFuXiqHfLHl5m2GGHEZpW40Ofh6i8PxR1UZXXiDpluXFeSEv5+Ui1/pMWZ5xy5GSrD7rd74bcpUL8jTF9X/X8zzXbV7wh3/AQTZpfdsdPG2NZfwmtEUkYuPd9eyy+7Iq09lFJWHjnPN1vOcm+fpnxxV9eqNXBLrEba85Xa36yqCWddqv4xrtRsENz9h2ppUF3eTdUenU3/M9mwSjm8WFV2HvZ/pi1wmZOu0mQX3QPvtYDFU9W6fu+HYMpym0p/1a5f1t9Weg36KzSG7DwjXZt6W3soJUgp+XpzOE193XhtbHvs7ao4C0gIAzffmqVUdr5LfZiSENVPWijk6q1mRhvfUbOcqvSOr4yMBFjxPAR2N01r6pw0VQLo6J9qt3h+NtTxhy6TVdBt2leVCtI0G6GDjRks3htNx0Av2ta3raq5eyIuERqVzJvjqxFoQO3M9zXRcoypuneufFFlkw0ps9Rd1fSeCTtnq303k36t+fGKW/WSChDjv6h+EMhOVW2Ajy5VAcaQA+71oeu9KsA06a0DjGazKhVshBCPA98DacC3QBfgBSmlhevG277w/esIvLCVAWOnWHsopczdHE5dN0cmdqtmL4tJv6ogUVPH/1bXFB7aUbNy52kXVHZc13trPiZQ+xb6PAob3lLXbhqEmOa4oKr9Nu4F/u2q9rqs5MsB5sw6MOSqnvLd71MBpnEv8ycaaJoJVHZmM01K+akQYiRQF7gH+AnQweYKWZu/4BXHo3h1MsE7bRM6HZ/O2uMXeGxYK1ydqvnu18XLNFWJA7uBNKhEgXrPVv84e+epigG9TLhJtNeD6mJ6YbfM7FRIjYW0WPU5NU7tkUm/AA7OalnR1efy8qKbT7HbvuDopoJB076Vz5TLugQn/lXZZGfWgzFPlbTpMV0FmEY9dIDRap3KBpvCNZfRwE9SyqPClrfEW1GT4B54bF8P9rmA7WSIzNsajrODHff2qWaZ8YTTELpAVRCo6cVtzwaqLtexZTCwmsEmL0vNalqPAr9qJCwYjap6dVEQiSkIJAWBZcPb6nZuWunXuvmBR31VDSEzsSDZoZzsOmGnmlZ5N4U6hQHJt2RAKgxQ8cdUgAnfqAKMV2MV/IInqACtA4xWi1U22OwTQqxG9ah5saC7pgU2JdQ+Hk06w3ZUOZLGPaw9HAAupuXw+/4YJnZrhF9hT5qqit4DWz8y3cX9dmNhzatqd3vdoKq//tBv6g99n0pUbU6NhV1fQ0pUQWCJVanHhisqcQt78GiggqG9E3jWhy7PgWfDyx8eDdSMpjijQZUPyUy83IIhK0nt6t7zLXg3UtUCspLU/4vCACXL+BXybqLK+QRPUI3f9Hs67RpR2WBzP6qQZriUMlMI4Yuq0qxdKSBYfb5wxGaCzfwdEeQZjEzvX4PqvolhYOdQvcBQlsJgc3y5KohZVYFdVYvnijYqRu9Tzd4yE1Xfdc9AdZ3Ds6H62rPB5a/r1Lt8gX3Lh2o/TNO+0Kjc8n6Knf3lJbRC+Tmw7TPVV2f6utKFNo1GyE5WQSczUX141FcbU3WA0a5BlQ0244H1UsrCXskGoDlgxh1wtZRXE3DyMG3HvRrIzM3np53nGN4ugOb1alAzKSEM6jYzXbtgn2Zq13OzQdV7ff2O6uNqjvyuqhy7B8DMLVW7ON/zAdj+BWz8rypnU1VbPoKEkzB5SdkVne3sLgcoK7bq1TRLqewi8GvFAg1SymSq3ujs+mBnBw9shJFvW3skgErDTs7M48FBzWt2oIQw0+9C73pv9VrVbv8CLhwr/3EpYcN/Yck0aNgFZqyvehaYs4eqtnt6rWpwVhVZyapbaMfbVA0rTdMqHWzKep7eo1Mev5al1/WtIN9g5Nut4XRt4k23pjXYiCklZFysWeWAshiNavZxel3lX3PhGKx+GU6W01UiLwuW3Aeb3oXOk1Vfj+ruoO8xQ13A31jFDuKu3uoNhyUqOmtaLVHZgLFXCPERMLvg9sPAPvMM6Rpw8RTs+0G9M/aob7VhrDp6gaikLF4eHVyzAwkBz54ufUG9puzs1AZKjwaVrwCw80uV3dV9WunHUuNg4SSIDYXhb0Dfx2p2/cPZHW76RI2vsgoTHqqTIadp17DKzmweBXKBRQUfOaiAo5UlM1HtRI87aLUhSCmZu/kMQb5uDA8OqPkBhTDPbK3dWIjYqrK4KpJ+UWWhdZ5UumRO7AH4Zoha7pv0K/R73DQX2oPHVT7RIzkSvuyrkgs0TSuhUsFGSpkhpXxBStm94ONFKWWGuQdXaxXPSLOSXWeTOBidwvQBzatXmqa4I3/AHw+qDCtTazdWbfAsb1msuL3zVImWK3vWHF0K392osuWmrYI2N5p2jJlJsOwxOLej/OcUVnQGda1G07QSrrqMJoT4REr5hBBiOWXsWpNSjjPbyGozFy+VlWbFjLRvNofjU8eJid1MUF04YosqmWJvhk2qDTqrn9WxZdDl7oqf3+HWy4kKUqrWyhveUptE71wA7v6mH6ODC5xcAZfOqirKZTn0m0omGPU/tVdG07QSKrpm81PBZwu3MbwGBLS/esaUGYVdSGPdiXieuKFV1VoIlKcwE80c+z+EULOb8I0FDcWuMt7BL1zug5OXBX89AkeWQMidMPZTcDRTR1QnN+j/hCqmGbENgvqVfDwjAVa+oMrImKKis6Zdg666jCal3CeEsAcekFJuuvLDQmOsnQLaq13lhnyLn/rbLWcLStMEmeaACWGmq/Zclhteg1nbyg80UkLkLvVZCFWA84ebVKAZ9hrcPMd8gaZQ92lqv05ZmWmJp9XsZ9znuuqyppWjwms2UkoD0FQIYTuFvmqDwS/C08fB3rIZ4vGp2fx5IIbbujfCp44J/smyUyH9vHmzqxycVRApry1z+Ab4boQq3Bl3CL4ZquqI3fEzDHjKMjvuHV2h/5NqSfHslpKPNekNjx+s+l4eTbuOVPYvYTiwTQixDChKDJBSfmSWUV0LLBxkCv24I4I8o5Hp/Wu4ibNQZgL4tYF6Zv5DGvoLrHsTHt2nlq2K2zFbNQYzGuG7keBaF6atNH2Ds4p0m6oyzgpL9uSkwaFF0O2+WtGWV9OsqbKpz2eAvwue71HwUYPaJ9eJpQ/B9s8tdrqMnHx+3hnJyOD6BPnVMc1BfZrDI7uh7WjTHK88Hg1UteUz60veH39CXXgPCIYlU8E/WFUEsHSgATW7GfVfVWMNVHD85xk4f9jyY9G0Wqayb7+PSSkXF79DCKHzOyty4YiqMFydQpPV8NveKFKy8nigpqVprCGov5qxHF8G7W66fP+OL1SZ/vCN0GGi6nTp6Gq1YQJqT8+ur+HgQlVDrWFn645H02qBys5syuoEZlvdwWxRQAeLpT/nG4zM23qW7k3r0rVJXdMd+J+n4c+Zpjteeewdoc1oOLkS8gsqFaTEqpRiaYQhr8Ct31o/0ABE7YGDv6pK0cNetfZoNK1WqGifzY2ohmmBQojPij3kCVg+zaq2CWivGo6lx5tn/0cxK46cJ/pSFv93Uw1L01wpcqcqwW8J7capn9fZzarMz693AgLGzYauldiDYyld71XVIbrcXXZFZ03TSqloGS0W2AuMo2QttDTgSXMN6poR0F59vnDUrMFGlaYJp7lfHW5oZ4LSNIWMRkg8A80Hm+6YV9N8sFpyTI6E3+5Vf8jvX6kqN9sSRxeYMLvi52maVuSqwUZKeRA4KIT4peC5TaSUJy0ysmtBQAeoH6I2K5rRzvAkDsek8M7NHbGraWma4lKjIT/L9NWey+Pooloh//u0ajomDaqhmaZptV5lr9mMAkKBlQBCiM4FadDa1dTxU027Wt1g1tPM3XwGP3cnbukaaNoDJ5xSn03dx6YsRgOseAFWPKdKz2TEg7Onui6iaVqtV9lg8zrQE0gGkFKGAjXoMXydkaXKypnMqQtpbDh5kXv7BJmmNE1xDi7QYij4tTbtca+UmwGL7oFdX6keMlE7IT8b+jykWyRr2jWissEmr3inzgLm+wt6Ldn9DXzYxmxla77ZHI6Lox339K5Gx8uKBPWHe/40b3JD2gX4YQycWgE3vg9jPlDFOQE63m6+82qaZlGV3WdzVAhxF2AvhGgFPAZsN9+wriHOHpB+AZLOQL02Jj30hdRslobGMKlnE+qaojTNlYxG1eDMXOKPw4LbVP+fO3+53Brg3r/UbMfc9c40TbOYqjRPa49qmvYrkAo8YaYx1W7p8apbYyF/8/W2+WF7BAaj5P7+ZlrR/KwTrHrZPMc+swHmjQBDHty3omQPGldv8NLXajTtWlLZ5mmZUsqXpZQ9CpqnvSylzDb34KxBCDFWCDE3JeXKVcNKMBrg+xthyf2XM9DqtQFhb/LNnek5+fy88xyjOtSnqa+JStMUl5OuUpBdvU1/7P0/wYKJKvNs+lq9A1/TrgMVbeq8asbZtdg8TUq5HFjevXv3qjcmsbNX1Z5/vx+2f6aqBDs4qwvsJg42i/ZEkZadzwMDW5j0uEUST6vPpmwtYDSqRmdbPlSJB7f9CC6epju+pmk2q6JrNn2AKNTS2S5ApwZVpMOtcGwpbHgHWo9SZec732XSrKo8g5Hvtp6lZzMfOjf2NtlxSygMNqZKe87Lhr8egiO/Q9cpMOZDVaJG07TrQkXLaPWBl4AOwKfAcCBBN0+7CiFgzMcqMeDPmeqaRL/HTFqM89/DccQkZ/HAADMW3EwIA4Sq+lxTGYkwf7wKNDe8rrpq6kCjadeVijp1GqSUK6WUU4DewGlgoxDiEYuMrrZyr6feuceFwrZP1H056ar/SQ0VlqZpUa8OQ9uaMSW5YWfo+0jNC18mnoF5N6hKyRO/V0uLeu+Mpl13KkwQEEI4CyFuAX4GHgY+A/4098BqvfY3Q/tbYOP/VObVfwNVSfoa2nEmkaOxqcwY0Ny0pWmu1OZGGPFWzY5xbgd8e4Nqjz1lOXS4xTRj0zSt1qkoQWA+agntX+A/UkrT5+9ey0Z/oNoIr34FXLxMkiTw9eZw/NydmdDFjKnBUkJKtCoVU919NoeXwNJZ4N0EJi82zXKcpmm1VkV/Se4GWgGPA9uFEKkFH2lCiFTzD6+Wq+Orrk9cOKLqfNUw2Jw8n8amUxeZ2rep6UvTFJcaA590gH3fV/21UsLmD1RGXmB3uH+NDjSaplVY9dmM28evE23HQMgdqglYZkKNduXP3RyOm5M9d5ujNE1xCWHqc1WrPRvy4O8n4MDP0PE2GD9bpX5rmnbd08HEEm78n8pOy8uCxLBqHeJ8SjbLDsZwe/fGeLuZoTRNcUVpz1UowJmVDD/fqgLNwOfglm90oNE0rYgONpbgWvfyxfbqLE0B328/a97SNMUlnAInd9UtszKSI+G7UXBuG4z/Eoa+rDPONE0rQQcbS+k2BTrfDbu+huh9FT+/mLTsPH7ZGcnojg1o7ONmpgEWkxCmltAqEzCi98E3wyA1Fu7+A7pMNv/4NE2rdXSwsaTes8DVF5bOVDvqK2nRnijScvJ5YKCFLrT3mgkDnqr4eUf+gB9Gq70496+G5oPMPzZN02olHWwsadO7aud8winY8HalXlJYmqZ3cx9CGnmbd3yF2oyC4PHlPy4lbHofltynes/MWA/+bS0zNk3TaiUdbCwpoAOkxUGXu2H75xC5q8KX/H0oltiUbMvNajIS1bjyssp+PD8H/nxQFdQMuQOmLFPtrzVN065CBxtLCmgPSAi5U5XXXzoLcjPLfXqewcgna8NoW9+Dwa3NWJqmuLMb4bsRlzPSistIgB/HwaFFMPQVuPlrnXGmaVql6GBjSYWN1C6dhfFfqO6d698s9+m/7Y3iXGImz41qY97SNMUlFAQZnytaF8SfgG+GqnpvE7+Hgc/qjDNN0ypNBxtLqtsMHN1UJYHmg6DHDNj5FURsK/XUrFwDn64No0dQXYa0sdCsBtQ+IK/G4FQs6+30Opg3XC2tTf1X1zjTNK3KdLCxJDs7uGvR5XYDN7wOdZuqPi856SWe+sP2COLTcnhuVFuEJWcQhWnPhfZ8CwtuUzXOZqyHRt0sNxZN064ZOthYWrOB4NVIfe3sDhO+gkvnYO3rRU9Jyczjq42nGdrWnx5BPpYbm5TqWo1fazDkw4rn4Z+nodVwmLYSvBtbbiyapl1TdLCxtJQYtbEzI1HdbtpX7b/Z8w2Eq350X28+Q1pOPs+ObGPZsUmpKjSH3A6/3gm75kDvh+HOX1S5HU3TtGrSwcbSLp2FFc+pZmKFhr6qLsj/9QgXL17ku21nGdepIe0aeFp2bHZ2ata17FE4sx5u+hhGvQN2ZqwwrWnadUEHG0srzEiLL9ZuwMkNbp4DqdFELHyKfIPkqeFVKIJpKgcWwFd9ITka7v4duk+z/Bg0Tbsm6WBjaW4+qinZlb1tGvckpcuD9Ehcxitt42jqW8ey4zq8RM1octJh+hpoMcSy59c07Zqmg401BLQvs5HaG+kTOC0DuSf+A1Wy3xKkVK2rf79fXZfxD9alZzRNMzkdbKzBP1ilGBvyiu46GpvC74cS2d7xLewzLsCql80/jrxs+GMGbHwHOt0FLp460GiaZhY62FhDv8fhuXBVlLPAB6tO4uXqyPgxY6H/ExD6M5xaZb4xpF+EH8fC4cUw7DUY8yEkR4FvK/OdU9O065YONtbg5qP22BTYfTaJDScvMmtwC7xcHWHQ8+DfHpY9BplJpj//hWPw7VA4fxhun6/aCVw6C0jw08FG0zTTc7D2AK5bG98Fr8bIznfx3soTBHg6M6VPkHrMwRkmfAnfDoOVL8Atcyt3TCkhOxnS4ws+LpT8nFHwdcJpcPGC+/6FwK7qtfXaweOHwNXbDN+spmnXOx1srOX43+ARwHqXG9h77hJv39wBV6di+1kadoYBz6geOK1HQsMuFQSRgtuG3NLnsnME9wBwr6cy4Rr3gv5PXq5kAGqPTd2mZv+2Ne1q8vLyiI6OJju78s0FNetwcXGhUaNGODo6VvxkdLCxnoD2yLObeX/VSYJ83bi9exmlYAY8DSf/gSVl7XcRUKfe5SDi1xrc/QtuBxR7zB9c61ZcofnAzyCN0PVek3x7mlYd0dHReHh4EBQUZNmagFqVSClJTEwkOjqaZs2aVeo1OthYS0B7xKGFnM+O5c1JA3G0L+PymYMT3PUbHP1TBQx3f6hTEFDcfMHehP98e+ap1GcdbDQrys7O1oGmFhBC4Ovry8WLFyv9Gh1srCTPLxhHYKRfImM6Nij/iZ4Noc/D5h1MYQHOkNvNex5NqwQdaGqHqv476Ww0K1ka50WKdOPeTu6Wa4xWnvR4yEnVac+appmNDjZWkJmbz/+2JPNAg98JvsEGlq0Sw9Rnv5ZXf56mXeMSExPp3LkznTt3pn79+gQGBhbdzs0tI/mmmL179/LYY49V6XxBQUF07NiRkJAQRowYwfnz52syfADmzJnD/Pnzy3182bJlvPvuuzU+T1XpZTQr+H5bBAkZuXx9b3fbWDJIjQVhp5IMNO065uvrS2hoKACvv/467u7uPPPMM0WP5+fn4+BQ9p/N7t2707179yqfc8OGDfj5+fHSSy/xzjvv8NlnnxU9JqVESomdXeXnBTNnzrzq4+PGjWPcuHFVHmdN6WBjYZcycpmz8Qw3tAugW8pa+GYO3L/aumX8Q26HduPU/h5NsxH/WX6UY7GpJj1mcENPXhvbvkqvmTp1Ki4uLhw4cIB+/fpx55138vjjj5OdnY2rqyvff/89bdq0YePGjXzwwQf8/fffvP7660RGRhIeHk5kZCRPPPFEhbOegQMH8tlnnxEREcHIkSPp1asX+/bt499//+W3337jt99+Iycnh5tvvpn//Oc/AMyfP58PPvgAIQQhISH89NNPJYLkZ599xpw5c3BwcCA4OJiFCxfyww8/sHfvXr744gsiIiKYNm0aCQkJ1KtXj++//54mTZowdepUPD092bt3L+fPn+e9995j4sSJ1f65gw42Fjdn0xnScwsao8WdgJi9kHTW+ktYji7WPb+m2bDo6Gi2b9+Ovb09qampbNmyBQcHB9auXctLL73E77//Xuo1J06cYMOGDaSlpdGmTRtmzZp11T0pf//9Nx07dgQgLCyMH3/8kd69e7N69WrCwsLYvXs3UkrGjRvH5s2b8fX15a233mL79u34+fmRlFS62si7777L2bNncXZ2Jjk5udTjjz76KFOmTGHKlCl89913PPbYYyxduhSAuLg4tm7dyokTJxg3bpwONrXJ+ZRsftgewc1dAmlT3wOMBe+w4o9aN9j89TA07Q+dJ1lvDJp2harOQMzptttuw95erT6kpKQwZcoUwsLCEEKQl5dX5mvGjBmDs7Mzzs7O+Pv7c+HCBRo1alTqeUOGDMHe3p6QkBDeeustkpOTadq0Kb179wZg9erVrF69mi5dugCQnp5OWFgYBw8e5LbbbsPPzw8AH5/SLeRDQkKYPHkyEyZMYMKECaUe37FjB3/88QcA99xzD88991zRYxMmTMDOzo7g4GAuXLhQhZ9W2XSCgAV9ui4Mo5Q8eUPBtZF6bdW1kjLaDVhMfg6E/gJJZ6w3Bk2zcXXqXO4v9eqrrzJkyBCOHDnC8uXLy6124Ox8eVna3t6e/Pz8Mp+3YcMGQkNDmT9/Pt7e3qXOJ6XkxRdfJDQ0lNDQUE6fPs39999fqXH/888/PPzww+zfv58ePXqUO4aKxi+lrPTryqODjYWEX0znt71RTO7VlMY+bupOR1fwbWndYJN0VlUO0MkBmlYpKSkpBAYGAvDDDz+Y/XwjR47ku+++Iz09HYCYmBji4+MZOnQoixcvJjExEaDUMprRaCQqKoohQ4bwv//9j5SUlKJjFOrbty8LFy4EYMGCBQwYMMBs34deRrOQD9ecwtnBjoeHXLFc1noUGA3WGRRAwin12VenPWtaZTz33HNMmTKFt956izFjxpj9fCNGjOD48eP06dMHAHd3d37++Wfat2/Pyy+/zKBBg7C3t6dLly4lgp/BYODuu+8mJSUFKSWPPfZY0cyp0Oeff859993H+++/X5QgYC7CFNOja1H37t3l3r17TXKsIzEp3PT5Vh4b2pKnRrQxyTFNZsuHsO4NeCFKNU/TNCs6fvw47dq1s/YwtEoq699LCLFPSlkqB1wvo1nAe6tO4u3myPSBzct/kjVnN/U76kCjaZpZ6WBjZtvPJLD51EUeHtwST5cy0h7TL8L7LWH/j5YfHKjK0jO3WufcmqZdN3SwMSMpJe+tPEkDLxfu6VNOr5g6fiojzJpJApqmaWamg40ZrTl2gdCoZJ64oRUujuVUCBAC/INVq2ZLy0iAL/vAyZWWP7emadcVHWzMxGCUvL/qJM3r1eHWrqU3cpUQ0F7NbCydrJFwCuKPWbdUjqZp14XrKtgIIZoLIeYJIZaY+1x/HoghLD6dZ0a0waGsxmjFBbSHnBRIiTb3sEpKKKj2rNOeNU0zM7MHGyGEvRDigBDi7xoc4zshRLwQ4kgZj40SQpwUQpwWQrxwteNIKcOllJXbelsDOfkGPl5zio6BXtzYoX7FL2jSB/o8oqoJWFJiGNg7g3cTy55X02zUkCFDWLVqVYn7PvnkE2bNmlXuawYPHkxZ2yQGDx5MmzZt6NSpE/369ePkyZM1Hl9F7QGq0+bAUizx1+1x4HhZDwgh/IUQHlfcV9bb7B+AUWW83h6YDdwIBAOThBDBQoiOQoi/r/jwr+k3Ulm/7IokJjmL50e1rVwLgYBgGPk2eAWaf3DFJZwG3xZ6GU3TCkyaNKloR32hhQsXMmlS9eoGLliwgIMHDzJlyhSeffbZUo8bDFXb8jBu3DheeKH899Tdu3cv0aLAlpi1goAQohEwBngbeKqMpwwCZgohRkspc4QQM4BbUMGjiJRysxAiqIzX9wROSynDC863EBgvpfwvcFM1xzwWGNuyZfWWltJz8vli/Wn6tvClfyu/yr8wLxsy4i07y/BrBfVsbJOpphVzx9c7St13U0gD7ukTRFauganf7y71+MRujbite2OSMnKZ9fO+Eo8terDPVc83ceJEXnnlFXJzc3FyciIiIoLY2FgGDBjArFmz2LNnD1lZWUycOLGozH9lDBw4kE8++QRQFQAefPBB1q5dy+zZs4mIiOCzzz4jNzeXXr168eWXX2Jvb8/KlSt56aWXMBgM+Pn5sW7duhLtARYvXsx//vMf7O3t8fLyYvPmzSXaHCQlJTFt2jTCw8Nxc3Nj7ty5hISEVKv9gSmYe2bzCfAcYCzrQSnlYmAVsEgIMRmYBtxWheMHAlHFbkcX3FcmIYSvEGIO0EUI8WI5Y1oupXzAy8urCsO4bN6WsyRm5PLcqLZVe+GSabCgKt+6CYx4E4ZX/hdG0651Pj4+9OzZkxUrVgBqVnP77bcjhODtt99m7969HDp0iE2bNnHo0KFKH3f58uVF7QMyMjLo1asXBw8exNfXl0WLFrFt2zZCQ0Oxt7dnwYIFXLx4kRkzZvD7779z8OBBFi9eXOqYb7zxBqtWreLgwYMsW7as1OOvvfYaXbp04dChQ7zzzjvce+/lrsAnTpxg1apV7N69m//85z/lVq42JbPNbIQQNwHxUsp9QojB5T1PSvlewYzkK6CFlDK9vOfWlJQyEbh6G7saMBolK4+eZ1T7+nRu7F21FwcEw6mVaoZjid4yRqNKu7aFTqGaVo6rzURcneyv+rhPHacKZzJlKVxKGz9+PAsXLmTevHkA/Pbbb8ydO5f8/Hzi4uI4duwYISEhVz3W5MmTcXV1JSgoiM8//xxQFaBvvfVWANatW8e+ffvo0aMHAFlZWfj7+7Nz504GDhxIs2bN1PdSRvuAfv36MXXqVG6//XZuueWWUo9v3bq1qM/O0KFDSUxMJDVVNaOrbPsDUzLnMlo/YJwQYjTgAngKIX6WUt5d/ElCiAFAB+BP4DXgkSqcIwZoXOx2o4L7rMLOTvDXw/1Iy67Gu4SA9iANkHASGnQy/eCudGoFLJ0F01aBv65FpWmFxo8fz5NPPsn+/fvJzMykW7dunD17lg8++IA9e/ZQt25dpk6dWm5rgeIWLFhQqlW0i4tLUW8cKSVTpkzhv//9b4nnLF++vMJjz5kzh127dvHPP//QrVs39u3bV+FrClW2/YEpmW0ZTUr5opSykZQyCLgTWF9GoOkCzAXGA/cBvkKIt6pwmj1AKyFEMyGEU8F5Ss8nLcjJwQ5f92q0Vw7ooD5bqpJAQhhkp4BHA8ucT9NqCXd3d4YMGcK0adOKEgNSU1OpU6cOXl5eXLhwoWiZraaGDRvGkiVLiI+PB1SbgHPnztG7d282b97M2bNni+6/0pkzZ+jVqxdvvPEG9erVIyoqqsTjAwYMYMGCBQBs3LgRPz8/PD2tVwPR2i0G3IDbpZRnAIQQ9wJTr3ySEOJXYDDgJ4SIBl6TUs6TUuYLIR5BXfexB76TUtbOui8+zcHBxXLBJjEM6viDq7dlzqdptcikSZO4+eabizLTOnXqRJcuXWjbti2NGzemX79+JjlPcHAwb731FiNGjMBoNOLo6Mjs2bPp3bs3c+fO5ZZbbsFoNOLv78+aNWtKvPbZZ58lLCwMKSXDhg2jU6dObNq0qejx119/nWnTphESEoKbmxs//mil+osFdIuBcpiyxUClHVyossMadjH/ueaNADsHuO9f859L0ypJtxioXarSYsDaMxutuE53Wu5cCWHQbqzlzqdp2nXtuipXY/OyklVRzOwU857HkA9d74XWI817Hk3TtAI62NiSuIPw6x0Qs9+857F3UPtr2pq/pa2maRroYGNbAtqrz+ZOEsi6BDlm286kaZpWig42tqSOH7jXN3+w2foxvNfMuq2oNU27ruhgY2sC2sOFUsWtTSvhNNRtpgtwappmMTrY2JqA9nDxhLqIby6JYaoIp6ZpJSQmJtK5c2c6d+5M/fr1CQwMLLqdm5t71ddWp7x/UFAQHTt2JCQkhEGDBnHu3LmaDL+U4u0PgoKCSEhIMOnxq0KnPtuaHtOh82Tz9bYx5EPSWZ0coGll8PX1JTQ0FFCbIt3d3XnmmWeKHs/Pz8fBoew/m927dy9VmqYyNmzYgJ+fH6+99hpvvfUW33zzTbXGbut0sLE1dZua9/iXzoIxD3z1zEazcStegPOHTXvM+h3hxvKbj5Vl6tSpuLi4cODAAfr168edd97J448/TnZ2Nq6urnz//fe0adOmRHn/6pTx79OnT1EvmosXLzJz5kwiIyMB1cCtX79+pKen8+ijj7J3716EELz22mvceuutNWp/YCk62Nii/T+pZIE2N1b83KrybQkDn4Og/qY/tqZdo6Kjo9m+fTv29vakpqayZcsWHBwcWLt2LS+99FJRdeXiTpw4wYYNG0hLS6NNmzbMmjULR0fHcs+xcuVKJkyYAMDjjz/Ok08+Sf/+/YmMjGTkyJEcP36cN998Ey8vLw4fVkH40qVLALz99tv4+PhgMBgYNmwYhw4dqrAitaXpYGOLdn6pmqiZMtgknYX8HPBvC0NfNt1xNc1cqjgDMafbbrutqFJzSkoKU6ZMISwsDCFEub1gKlvGf8iQISQlJeHu7s6bb74JwNq1azl27FjRc1JTU0lPT2ft2rUlOonWrVsXqF77A0vTCQK2KKC9adOfE8/AD2Ng8RSd7qxp1VCnTp2ir1999VWGDBnCkSNHWL58ebmtBipbxn/Dhg2cO3eOzp0789prrwFgNBrZuXMnoaGhhIaGEhMTg7u7e5mvL2x/sG7dOg4dOsSYMWMq1f7A0nSwsUUB7SElSpWvqamLp+D70ZCfDbd+q9OdNa2GUlJSCAxUDYF/+OEHkxzTwcGBTz75hPnz55OUlMSIESOKmq0BRUkLw4cPZ/bs2UX3X7p0yWztD0xNBxtbVNjbJv7Y1Z9Xkfjj8MNo1ZRtyt/q4qimaTXy3HPP8eKLL9KlSxeTNh1r0KABkyZNYvbs2Xz22Wfs3buXkJAQgoODmTNnDgCvvPIKly5dokOHDnTq1IkNGzaUaH9w1113maz9ganpFgPlsEqLgUKpsfBROxj3uSqYWV2Lp8K5HTBlOdRrbbLhaZq56BYDtYtuMVDbeTSA5yPAtW7NjjN+NqTHg08zkwxL0zStuvQymi0SovqBJmYfLLgNctLAqY4ONJqm2QQdbGxV2BpYfB8YjZV/TdRumD8BEk6ZvyeOpmlaFehgY6tSY+HoH5BcyVpJ57bDTzdDnXow9V/wKp3Pr2maZi062Niqwoy0yuy3idgGP98Kng1h6j/gFWjesWmaplWRDja2yr8tICoXbDwbQJM+KtB4NjD70DRN06pKBxtb5VQHfJpfvbfNhaMgpXrePX+Au7/lxqdp16AhQ4awatWqEvd98sknzJo1q9zXFC/jf+X9bdq0oVOnTvTo0aNoY6apTJ06lSVLllx1DLZEBxtb1rhn+Tv+T/wLcwfDji8sOiRNu5ZNmjSpRO0xgIULFzJp0qRqHW/BggUcPHiQhx56iGeffdYUQ6y19D4bW3bznLLvP/YXLJkGDTpBl3ssOyZNs6Tvy+i71H4C9JwBuZkqzf9Kne+CLpMhIxF+u2JT9H3/XPV0EydO5JVXXiE3NxcnJyciIiKIjY1lwIABNSrj36dPH95//30AMjIyePTRRzly5Ah5eXm8/vrrjB8/HoPBwPPPP8/KlSuxs7NjxowZPProo7zxxhssX76crKws+vbty9dff40QotLnthV6ZlPbHPldpUQHdoN7/gRXb2uPSNOuGT4+PvTs2bOovtjChQu5/fbbEULw9ttvs3fvXg4dOsSmTZs4dOhQpY9bvH3A22+/zdChQ9m9ezcbNmzg2WefJSMjg7lz5xIREUFoaCiHDh1i8uTJADzyyCPs2bOHI0eOkJWVxd9//23y79sS9MzGlmUmqXduPR+ATneoagBLH4YmveGuReDsYe0Rapp5XW0m4uR29cfr+FY4kylL4VLa+PHjWbhwIfPmzQOqV8Z/8uTJ5Obmkp6eXnTNZvXq1SxbtowPPvgAgOzsbCIjI1m7di0zZ84s6gTq4+MDqKrQ7733HpmZmSQlJdG+fXvGjh1b5e/L2vTMxpa5eKtimrH71W13f5UIMHmxDjSaZibjx49n3bp17N+/n8zMTLp161btMv4LFiwgPDycKVOm8OijjwIgpeT3338vah8QGRlZbj247OxsHnroIZYsWcLhw4eZMWOGTbYPqAwdbGyZnR34t4PDi+HQb+q+pn1VppqmaWbh7u7OkCFDmDZtWlFiQE3K+AshePPNN9m5cycnTpxg5MiRfP755xQWQT5w4ACg2gd8/fXXRZWkk5KSigKLn58f6enpRdlntZEONrYuoD1kJsLRP1Was6ZpZjdp0iQOHjxYFGxqWsbf1dWVp59+mvfff59XX32VvLw8QkJCaN++Pa+++ioA06dPp0mTJoSEhNCpUyd++eUXvL29mTFjBh06dGDkyJH06NHD5N+rpegWA+WwaouB4mIPwLFlMPgFcHCu+PmaVovpFgO1i24xcC1p2EV9aJqm1WJ6GU3TNE0zOx1sNE2zKXppv3ao6r+TDjaaptkMFxcXEhMTdcCxcVJKEhMTcXFxqfRr9DUbTdNsRqNGjYiOjubixYvWHopWARcXFxo1qnzfLB1sNE2zGY6OjjRrpluZX4v0MpqmaZpmdjrYaJqmaWang42maZpmdrqCQDmEEBeBc9V8uR+QYMLhmIOtj9HWxwe2P0ZbHx/Y/hhtfXxge2NsKqWsd+WdOtiYgRBib1nlGmyJrY/R1scHtj9GWx8f2P4YbX18UDvGCHoZTdM0TbMAHWw0TdM0s9PBxjzmWnsAlWDrY7T18YHtj9HWxwe2P0ZbHx/UjjHqazaapmma+emZjaZpmmZ2OthomqZpZqeDjQkJIUYJIU4KIU4LIV6w9niuJIRoLITYIIQ4JoQ4KoR43NpjKosQwl4IcUAI8be1x1IWIYS3EGKJEOKEEOK4EKKPtcd0JSHEkwX/xkeEEL8KISpfntd8Y/pOCBEvhDhS7D4fIcQaIURYwee6Nja+9wv+nQ8JIf4UQnhba3wF4yk1xmKPPS2EkEIIP2uMrSI62JiIEMIemA3cCAQDk4QQwdYdVSn5wNNSymCgN/CwDY4R4HHguLUHcRWfAiullG2BTtjYWIUQgcBjQHcpZQfAHrjTuqMC4Adg1BX3vQCsk1K2AtYV3LaWHyg9vjVAByllCHAKeNHSg7rCD5QeI0KIxsAIINLSA6osHWxMpydwWkoZLqXMBRYC4608phKklHFSyv0FX6eh/kgGWndUJQkhGgFjgG+tPZayCCG8gIHAPAApZa6UMtmqgyqbA+AqhHAA3IBYK48HKeVmIOmKu8cDPxZ8/SMwwZJjKq6s8UkpV0sp8wtu7gQqX1PfDMr5GQJ8DDwH2GzGlw42phMIRBW7HY2N/SEvTggRBHQBdll5KFf6BPVLY7TyOMrTDLgIfF+w1PetEKKOtQdVnJQyBvgA9S43DkiRUq627qjKFSCljCv4+jwQYM3BVGAasMLag7iSEGI8ECOlPGjtsVyNDjbXISGEO/A78ISUMtXa4ykkhLgJiJdS7rP2WK7CAegKfCWl7AJkYN2ln1IKrnuMRwXGhkAdIcTd1h1VxaTah2GT78yFEC+jlqEXWHssxQkh3ICXgP+z9lgqooON6cQAjYvdblRwn00RQjiiAs0CKeUf1h7PFfoB44QQEahlyKFCiJ+tO6RSooFoKWXhjHAJKvjYkhuAs1LKi1LKPOAPoK+Vx1SeC0KIBgAFn+OtPJ5ShBBTgZuAydL2Nia2QL2pOFjwe9MI2C+EqG/VUZVBBxvT2QO0EkI0E0I4oS7ILrPymEoQQgjUtYbjUsqPrD2eK0kpX5RSNpJSBqF+fuullDb1jlxKeR6IEkK0KbhrGHDMikMqSyTQWwjhVvBvPgwbS2IoZhkwpeDrKcBfVhxLKUKIUahl3XFSykxrj+dKUsrDUkp/KWVQwe9NNNC14P+pTdHBxkQKLiI+AqxC/WL/JqU8at1RldIPuAc1Ywgt+Bht7UHVQo8CC4QQh4DOwDvWHU5JBbOuJcB+4DDq99zqJU2EEL8CO4A2QohoIcT9wLvAcCFEGGpG9q6Nje8LwANYU/D7Msda47vKGGsFXa5G0zRNMzs9s9E0TdPMTgcbTdM0zex0sNE0TdPMTgcbTdM0zex0sNE0TdPMTgcbTbMSIYShWAp6qCkrhQshgsqqDKxp1uJg7QFo2nUsS0rZ2dqD0DRL0DMbTbMxQogIIcR7QojDQojdQoiWBfcHCSHWF/RWWSeEaFJwf0BBr5WDBR+FpWnshRDfFPS1WS2EcLXaN6Vd93Sw0TTrcb1iGe2OYo+lSCk7onawf1Jw3+fAjwW9VRYAnxXc/xmwSUrZCVWnrbByRStgtpSyPZAM3GrW70bTrkJXENA0KxFCpEsp3cu4PwIYKqUMLyicel5K6SuESAAaSCnzCu6Pk1L6CSEuAo2klDnFjhEErCloSoYQ4nnAUUr5lgW+NU0rRc9sNM02yXK+roqcYl8b0NdoNSvSwUbTbNMdxT7vKPh6O5fbO08GthR8vQ6YBao9eUE3UU2zKfqdjqZZj6sQIrTY7ZVSysL057oFVaVzgEkF9z2K6hD6LKpb6H0F9z8OzC2oAGxABZ44NM2G6Gs2mmZjCq7ZdJdSJlh7LJpmKnoZTdM0TTM7PbPRNE3TzE7PbDRN0zSz08FG0zRNMzsdbDRN0zSz08FG0zRNMzsdbDRN0zSz+3/q1Pw68azZxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Precision','Recall'], 0,['masked_precision','masked_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_metric(baseline_history, ['AUC','F1'], 0,['auc','masked_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, Dropout, MaxPooling1D, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1D_model(train_data_reshaped):\n",
    "    n_timesteps = train_data_reshaped.shape[1] #13\n",
    "    n_features  = train_data_reshaped.shape[2] #1 \n",
    "    model = Sequential(name=\"model_conv1D\")\n",
    "    model.add(Input(shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=7, activation='relu', name=\"Conv1D_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', name=\"Conv1D_2\"))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_2\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu', name=\"Dense_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='relu', name=\"Dense_1_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu',name=\"Dense_2\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='sigmoid',name=\"Dense_3\"))\n",
    "   # model.add(Dense(n_labels, name=\"Dense_2\"))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 785ms/step - loss: 0.1301 - masked_accuracy: 0.6978 - masked_precision: 0.5256 - masked_recall: 0.4361 - masked_f1: 0.4687 - val_loss: 0.1183 - val_masked_accuracy: 0.7401 - val_masked_precision: 0.6703 - val_masked_recall: 0.3878 - val_masked_f1: 0.4862\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0988 - masked_accuracy: 0.7672 - masked_precision: 0.6495 - masked_recall: 0.5263 - masked_f1: 0.5772 - val_loss: 0.0907 - val_masked_accuracy: 0.8244 - val_masked_precision: 0.7865 - val_masked_recall: 0.6194 - val_masked_f1: 0.6908\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0814 - masked_accuracy: 0.8178 - masked_precision: 0.7307 - masked_recall: 0.6450 - masked_f1: 0.6826 - val_loss: 0.0838 - val_masked_accuracy: 0.8404 - val_masked_precision: 0.8079 - val_masked_recall: 0.6538 - val_masked_f1: 0.7206\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0695 - masked_accuracy: 0.8522 - masked_precision: 0.7765 - masked_recall: 0.7393 - masked_f1: 0.7550 - val_loss: 0.0772 - val_masked_accuracy: 0.8597 - val_masked_precision: 0.8361 - val_masked_recall: 0.6948 - val_masked_f1: 0.7575\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0633 - masked_accuracy: 0.8660 - masked_precision: 0.7957 - masked_recall: 0.7528 - masked_f1: 0.7710 - val_loss: 0.0726 - val_masked_accuracy: 0.8653 - val_masked_precision: 0.8102 - val_masked_recall: 0.7550 - val_masked_f1: 0.7793\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.0554 - masked_accuracy: 0.8855 - masked_precision: 0.8241 - masked_recall: 0.8018 - masked_f1: 0.8099 - val_loss: 0.0693 - val_masked_accuracy: 0.8729 - val_masked_precision: 0.8211 - val_masked_recall: 0.7740 - val_masked_f1: 0.7951\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 45s 802ms/step - loss: 0.0501 - masked_accuracy: 0.8966 - masked_precision: 0.8436 - masked_recall: 0.8161 - masked_f1: 0.8274 - val_loss: 0.0686 - val_masked_accuracy: 0.8677 - val_masked_precision: 0.7747 - val_masked_recall: 0.8252 - val_masked_f1: 0.7976\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0426 - masked_accuracy: 0.9175 - masked_precision: 0.8788 - masked_recall: 0.8475 - masked_f1: 0.8610 - val_loss: 0.0735 - val_masked_accuracy: 0.8690 - val_masked_precision: 0.8613 - val_masked_recall: 0.7058 - val_masked_f1: 0.7714\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0405 - masked_accuracy: 0.9185 - masked_precision: 0.8704 - masked_recall: 0.8626 - masked_f1: 0.8651 - val_loss: 0.0679 - val_masked_accuracy: 0.8757 - val_masked_precision: 0.8500 - val_masked_recall: 0.7384 - val_masked_f1: 0.7852\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0361 - masked_accuracy: 0.9278 - masked_precision: 0.8924 - masked_recall: 0.8710 - masked_f1: 0.8801 - val_loss: 0.0695 - val_masked_accuracy: 0.8860 - val_masked_precision: 0.8489 - val_masked_recall: 0.7790 - val_masked_f1: 0.8097\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0340 - masked_accuracy: 0.9354 - masked_precision: 0.9008 - masked_recall: 0.8871 - masked_f1: 0.8928 - val_loss: 0.0692 - val_masked_accuracy: 0.8788 - val_masked_precision: 0.8489 - val_masked_recall: 0.7569 - val_masked_f1: 0.7963\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0308 - masked_accuracy: 0.9430 - masked_precision: 0.9112 - masked_recall: 0.9036 - masked_f1: 0.9066 - val_loss: 0.0701 - val_masked_accuracy: 0.8832 - val_masked_precision: 0.8453 - val_masked_recall: 0.7766 - val_masked_f1: 0.8070\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0262 - masked_accuracy: 0.9494 - masked_precision: 0.9224 - masked_recall: 0.9137 - masked_f1: 0.9169 - val_loss: 0.0704 - val_masked_accuracy: 0.8898 - val_masked_precision: 0.8706 - val_masked_recall: 0.7672 - val_masked_f1: 0.8120\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0254 - masked_accuracy: 0.9533 - masked_precision: 0.9302 - masked_recall: 0.9170 - masked_f1: 0.9227 - val_loss: 0.0741 - val_masked_accuracy: 0.8815 - val_masked_precision: 0.8519 - val_masked_recall: 0.7629 - val_masked_f1: 0.8006\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 45s 805ms/step - loss: 0.0226 - masked_accuracy: 0.9555 - masked_precision: 0.9335 - masked_recall: 0.9218 - masked_f1: 0.9268 - val_loss: 0.0722 - val_masked_accuracy: 0.8849 - val_masked_precision: 0.8590 - val_masked_recall: 0.7651 - val_masked_f1: 0.8060\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0214 - masked_accuracy: 0.9620 - masked_precision: 0.9404 - masked_recall: 0.9360 - masked_f1: 0.9376 - val_loss: 0.0820 - val_masked_accuracy: 0.8891 - val_masked_precision: 0.8599 - val_masked_recall: 0.7775 - val_masked_f1: 0.8137\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 45s 799ms/step - loss: 0.0208 - masked_accuracy: 0.9632 - masked_precision: 0.9394 - masked_recall: 0.9399 - masked_f1: 0.9389 - val_loss: 0.0818 - val_masked_accuracy: 0.8847 - val_masked_precision: 0.8533 - val_masked_recall: 0.7658 - val_masked_f1: 0.8044\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 45s 802ms/step - loss: 0.0180 - masked_accuracy: 0.9682 - masked_precision: 0.9503 - masked_recall: 0.9468 - masked_f1: 0.9480 - val_loss: 0.0837 - val_masked_accuracy: 0.8870 - val_masked_precision: 0.8765 - val_masked_recall: 0.7543 - val_masked_f1: 0.8065\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "18/18 [==============================] - 2s 124ms/step - loss: 0.0672 - masked_accuracy: 0.8804 - masked_precision: 0.8163 - masked_recall: 0.7696 - masked_f1: 0.7900\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 795ms/step - loss: 0.1278 - masked_accuracy: 0.6902 - masked_precision: 0.5084 - masked_recall: 0.4208 - masked_f1: 0.4495 - val_loss: 0.0995 - val_masked_accuracy: 0.7866 - val_masked_precision: 0.6712 - val_masked_recall: 0.5621 - val_masked_f1: 0.6092\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0964 - masked_accuracy: 0.7801 - masked_precision: 0.6734 - masked_recall: 0.5440 - masked_f1: 0.5968 - val_loss: 0.0824 - val_masked_accuracy: 0.8209 - val_masked_precision: 0.6939 - val_masked_recall: 0.7052 - val_masked_f1: 0.6971\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0786 - masked_accuracy: 0.8300 - masked_precision: 0.7408 - masked_recall: 0.6823 - masked_f1: 0.7077 - val_loss: 0.0696 - val_masked_accuracy: 0.8569 - val_masked_precision: 0.7730 - val_masked_recall: 0.7300 - val_masked_f1: 0.7491\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0685 - masked_accuracy: 0.8578 - masked_precision: 0.7791 - masked_recall: 0.7473 - masked_f1: 0.7589 - val_loss: 0.0680 - val_masked_accuracy: 0.8618 - val_masked_precision: 0.7578 - val_masked_recall: 0.7858 - val_masked_f1: 0.7699\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0615 - masked_accuracy: 0.8770 - masked_precision: 0.8117 - masked_recall: 0.7744 - masked_f1: 0.7899 - val_loss: 0.0637 - val_masked_accuracy: 0.8687 - val_masked_precision: 0.7784 - val_masked_recall: 0.7792 - val_masked_f1: 0.7764\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0538 - masked_accuracy: 0.8949 - masked_precision: 0.8326 - masked_recall: 0.8225 - masked_f1: 0.8257 - val_loss: 0.0625 - val_masked_accuracy: 0.8785 - val_masked_precision: 0.7964 - val_masked_recall: 0.7964 - val_masked_f1: 0.7930\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0485 - masked_accuracy: 0.9038 - masked_precision: 0.8458 - masked_recall: 0.8327 - masked_f1: 0.8375 - val_loss: 0.0600 - val_masked_accuracy: 0.8867 - val_masked_precision: 0.8284 - val_masked_recall: 0.7821 - val_masked_f1: 0.8017\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0434 - masked_accuracy: 0.9125 - masked_precision: 0.8616 - masked_recall: 0.8495 - masked_f1: 0.8538 - val_loss: 0.0605 - val_masked_accuracy: 0.8910 - val_masked_precision: 0.8373 - val_masked_recall: 0.7860 - val_masked_f1: 0.8085\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0392 - masked_accuracy: 0.9240 - masked_precision: 0.8808 - masked_recall: 0.8643 - masked_f1: 0.8709 - val_loss: 0.0610 - val_masked_accuracy: 0.8883 - val_masked_precision: 0.8157 - val_masked_recall: 0.8052 - val_masked_f1: 0.8070\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0342 - masked_accuracy: 0.9324 - masked_precision: 0.8904 - masked_recall: 0.8855 - masked_f1: 0.8871 - val_loss: 0.0628 - val_masked_accuracy: 0.8848 - val_masked_precision: 0.8332 - val_masked_recall: 0.7714 - val_masked_f1: 0.7980\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0302 - masked_accuracy: 0.9428 - masked_precision: 0.9093 - masked_recall: 0.9035 - masked_f1: 0.9050 - val_loss: 0.0635 - val_masked_accuracy: 0.8884 - val_masked_precision: 0.8301 - val_masked_recall: 0.7887 - val_masked_f1: 0.8058\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0292 - masked_accuracy: 0.9454 - masked_precision: 0.9180 - masked_recall: 0.8993 - masked_f1: 0.9075 - val_loss: 0.0691 - val_masked_accuracy: 0.8887 - val_masked_precision: 0.8195 - val_masked_recall: 0.7993 - val_masked_f1: 0.8064\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0277 - masked_accuracy: 0.9494 - masked_precision: 0.9179 - masked_recall: 0.9136 - masked_f1: 0.9150 - val_loss: 0.0657 - val_masked_accuracy: 0.8910 - val_masked_precision: 0.8353 - val_masked_recall: 0.7894 - val_masked_f1: 0.8103\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0684 - masked_accuracy: 0.8770 - masked_precision: 0.8410 - masked_recall: 0.7657 - masked_f1: 0.7999\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 788ms/step - loss: 0.1302 - masked_accuracy: 0.6967 - masked_precision: 0.5067 - masked_recall: 0.4357 - masked_f1: 0.4620 - val_loss: 0.1122 - val_masked_accuracy: 0.7667 - val_masked_precision: 0.6963 - val_masked_recall: 0.5414 - val_masked_f1: 0.6047\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0957 - masked_accuracy: 0.7769 - masked_precision: 0.6582 - masked_recall: 0.5425 - masked_f1: 0.5879 - val_loss: 0.0837 - val_masked_accuracy: 0.8204 - val_masked_precision: 0.7228 - val_masked_recall: 0.7419 - val_masked_f1: 0.7298\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0795 - masked_accuracy: 0.8236 - masked_precision: 0.7249 - masked_recall: 0.6715 - masked_f1: 0.6941 - val_loss: 0.0795 - val_masked_accuracy: 0.8361 - val_masked_precision: 0.7248 - val_masked_recall: 0.8214 - val_masked_f1: 0.7670\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0684 - masked_accuracy: 0.8551 - masked_precision: 0.7735 - masked_recall: 0.7411 - masked_f1: 0.7539 - val_loss: 0.0726 - val_masked_accuracy: 0.8467 - val_masked_precision: 0.8184 - val_masked_recall: 0.6903 - val_masked_f1: 0.7464\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0607 - masked_accuracy: 0.8743 - masked_precision: 0.8094 - masked_recall: 0.7621 - masked_f1: 0.7823 - val_loss: 0.0688 - val_masked_accuracy: 0.8570 - val_masked_precision: 0.7797 - val_masked_recall: 0.7961 - val_masked_f1: 0.7840\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0540 - masked_accuracy: 0.8905 - masked_precision: 0.8311 - masked_recall: 0.7968 - masked_f1: 0.8111 - val_loss: 0.0659 - val_masked_accuracy: 0.8728 - val_masked_precision: 0.8167 - val_masked_recall: 0.7979 - val_masked_f1: 0.8050\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0483 - masked_accuracy: 0.9025 - masked_precision: 0.8525 - masked_recall: 0.8199 - masked_f1: 0.8342 - val_loss: 0.0673 - val_masked_accuracy: 0.8651 - val_masked_precision: 0.7914 - val_masked_recall: 0.8132 - val_masked_f1: 0.7984\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 45s 804ms/step - loss: 0.0436 - masked_accuracy: 0.9127 - masked_precision: 0.8659 - masked_recall: 0.8407 - masked_f1: 0.8518 - val_loss: 0.0686 - val_masked_accuracy: 0.8676 - val_masked_precision: 0.7972 - val_masked_recall: 0.8165 - val_masked_f1: 0.8037\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.0403 - masked_accuracy: 0.9198 - masked_precision: 0.8742 - masked_recall: 0.8592 - masked_f1: 0.8648 - val_loss: 0.0657 - val_masked_accuracy: 0.8641 - val_masked_precision: 0.8021 - val_masked_recall: 0.7930 - val_masked_f1: 0.7950\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 45s 797ms/step - loss: 0.0354 - masked_accuracy: 0.9325 - masked_precision: 0.9024 - masked_recall: 0.8707 - masked_f1: 0.8851 - val_loss: 0.0678 - val_masked_accuracy: 0.8711 - val_masked_precision: 0.7772 - val_masked_recall: 0.8665 - val_masked_f1: 0.8162\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 45s 795ms/step - loss: 0.0325 - masked_accuracy: 0.9388 - masked_precision: 0.9082 - masked_recall: 0.8894 - masked_f1: 0.8975 - val_loss: 0.0671 - val_masked_accuracy: 0.8781 - val_masked_precision: 0.8319 - val_masked_recall: 0.7991 - val_masked_f1: 0.8128\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.0288 - masked_accuracy: 0.9453 - masked_precision: 0.9116 - masked_recall: 0.9063 - masked_f1: 0.9082 - val_loss: 0.0712 - val_masked_accuracy: 0.8760 - val_masked_precision: 0.8543 - val_masked_recall: 0.7585 - val_masked_f1: 0.8017\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 45s 801ms/step - loss: 0.0263 - masked_accuracy: 0.9492 - masked_precision: 0.9194 - masked_recall: 0.9080 - masked_f1: 0.9128 - val_loss: 0.0763 - val_masked_accuracy: 0.8727 - val_masked_precision: 0.8491 - val_masked_recall: 0.7542 - val_masked_f1: 0.7964\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0247 - masked_accuracy: 0.9539 - masked_precision: 0.9280 - masked_recall: 0.9160 - masked_f1: 0.9209 - val_loss: 0.0727 - val_masked_accuracy: 0.8792 - val_masked_precision: 0.8371 - val_masked_recall: 0.7955 - val_masked_f1: 0.8141\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0241 - masked_accuracy: 0.9562 - masked_precision: 0.9371 - masked_recall: 0.9170 - masked_f1: 0.9264 - val_loss: 0.0740 - val_masked_accuracy: 0.8752 - val_masked_precision: 0.7936 - val_masked_recall: 0.8518 - val_masked_f1: 0.8198\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0217 - masked_accuracy: 0.9585 - masked_precision: 0.9298 - masked_recall: 0.9341 - masked_f1: 0.9311 - val_loss: 0.0840 - val_masked_accuracy: 0.8793 - val_masked_precision: 0.8438 - val_masked_recall: 0.7859 - val_masked_f1: 0.8115\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0206 - masked_accuracy: 0.9608 - masked_precision: 0.9359 - masked_recall: 0.9334 - masked_f1: 0.9337 - val_loss: 0.0771 - val_masked_accuracy: 0.8835 - val_masked_precision: 0.8554 - val_masked_recall: 0.7853 - val_masked_f1: 0.8165\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0186 - masked_accuracy: 0.9660 - masked_precision: 0.9455 - masked_recall: 0.9424 - masked_f1: 0.9434 - val_loss: 0.0814 - val_masked_accuracy: 0.8763 - val_masked_precision: 0.8340 - val_masked_recall: 0.7875 - val_masked_f1: 0.8081\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0183 - masked_accuracy: 0.9681 - masked_precision: 0.9484 - masked_recall: 0.9449 - masked_f1: 0.9461 - val_loss: 0.0828 - val_masked_accuracy: 0.8755 - val_masked_precision: 0.8388 - val_masked_recall: 0.7772 - val_masked_f1: 0.8050\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 45s 811ms/step - loss: 0.0172 - masked_accuracy: 0.9683 - masked_precision: 0.9494 - masked_recall: 0.9462 - masked_f1: 0.9473 - val_loss: 0.0842 - val_masked_accuracy: 0.8725 - val_masked_precision: 0.8320 - val_masked_recall: 0.7712 - val_masked_f1: 0.7987\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0163 - masked_accuracy: 0.9694 - masked_precision: 0.9524 - masked_recall: 0.9478 - masked_f1: 0.9496 - val_loss: 0.0812 - val_masked_accuracy: 0.8757 - val_masked_precision: 0.8465 - val_masked_recall: 0.7660 - val_masked_f1: 0.8026\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0165 - masked_accuracy: 0.9707 - masked_precision: 0.9543 - masked_recall: 0.9482 - masked_f1: 0.9507 - val_loss: 0.0786 - val_masked_accuracy: 0.8750 - val_masked_precision: 0.8442 - val_masked_recall: 0.7648 - val_masked_f1: 0.8009\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0831 - masked_accuracy: 0.8758 - masked_precision: 0.8293 - masked_recall: 0.7490 - masked_f1: 0.78 - 2s 110ms/step - loss: 0.0826 - masked_accuracy: 0.8757 - masked_precision: 0.8224 - masked_recall: 0.7602 - masked_f1: 0.7860\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1276 - masked_accuracy: 0.7014 - masked_precision: 0.5203 - masked_recall: 0.4485 - masked_f1: 0.4743 - val_loss: 0.1156 - val_masked_accuracy: 0.7613 - val_masked_precision: 0.6696 - val_masked_recall: 0.4700 - val_masked_f1: 0.5476\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1007 - masked_accuracy: 0.7656 - masked_precision: 0.6405 - masked_recall: 0.5335 - masked_f1: 0.5775 - val_loss: 0.0890 - val_masked_accuracy: 0.7924 - val_masked_precision: 0.6656 - val_masked_recall: 0.6585 - val_masked_f1: 0.6596\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0820 - masked_accuracy: 0.8176 - masked_precision: 0.7118 - masked_recall: 0.6682 - masked_f1: 0.6866 - val_loss: 0.0781 - val_masked_accuracy: 0.8459 - val_masked_precision: 0.7514 - val_masked_recall: 0.7432 - val_masked_f1: 0.7440\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0697 - masked_accuracy: 0.8576 - masked_precision: 0.7710 - masked_recall: 0.7507 - masked_f1: 0.7581 - val_loss: 0.0714 - val_masked_accuracy: 0.8453 - val_masked_precision: 0.7310 - val_masked_recall: 0.7908 - val_masked_f1: 0.7554\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0611 - masked_accuracy: 0.8745 - masked_precision: 0.8040 - masked_recall: 0.7702 - masked_f1: 0.7847 - val_loss: 0.0716 - val_masked_accuracy: 0.8542 - val_masked_precision: 0.8594 - val_masked_recall: 0.6364 - val_masked_f1: 0.7241\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0539 - masked_accuracy: 0.8903 - masked_precision: 0.8345 - masked_recall: 0.7956 - masked_f1: 0.8119 - val_loss: 0.0652 - val_masked_accuracy: 0.8577 - val_masked_precision: 0.7685 - val_masked_recall: 0.7709 - val_masked_f1: 0.7664\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0479 - masked_accuracy: 0.9031 - masked_precision: 0.8514 - masked_recall: 0.8264 - masked_f1: 0.8365 - val_loss: 0.0663 - val_masked_accuracy: 0.8576 - val_masked_precision: 0.7505 - val_masked_recall: 0.7998 - val_masked_f1: 0.7714\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0433 - masked_accuracy: 0.9154 - masked_precision: 0.8695 - masked_recall: 0.8500 - masked_f1: 0.8582 - val_loss: 0.0668 - val_masked_accuracy: 0.8557 - val_masked_precision: 0.7480 - val_masked_recall: 0.7991 - val_masked_f1: 0.7694\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0389 - masked_accuracy: 0.9227 - masked_precision: 0.8810 - masked_recall: 0.8592 - masked_f1: 0.8691 - val_loss: 0.0657 - val_masked_accuracy: 0.8625 - val_masked_precision: 0.7751 - val_masked_recall: 0.7745 - val_masked_f1: 0.7708\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0357 - masked_accuracy: 0.9314 - masked_precision: 0.8923 - masked_recall: 0.8802 - masked_f1: 0.8849 - val_loss: 0.0678 - val_masked_accuracy: 0.8644 - val_masked_precision: 0.7666 - val_masked_recall: 0.7997 - val_masked_f1: 0.7806\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0305 - masked_accuracy: 0.9390 - masked_precision: 0.9058 - masked_recall: 0.8942 - masked_f1: 0.8988 - val_loss: 0.0725 - val_masked_accuracy: 0.8681 - val_masked_precision: 0.8076 - val_masked_recall: 0.7495 - val_masked_f1: 0.7746\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0289 - masked_accuracy: 0.9474 - masked_precision: 0.9176 - masked_recall: 0.9094 - masked_f1: 0.9125 - val_loss: 0.0679 - val_masked_accuracy: 0.8704 - val_masked_precision: 0.7892 - val_masked_recall: 0.7837 - val_masked_f1: 0.7836\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0272 - masked_accuracy: 0.9493 - masked_precision: 0.9193 - masked_recall: 0.9112 - masked_f1: 0.9144 - val_loss: 0.0713 - val_masked_accuracy: 0.8624 - val_masked_precision: 0.7674 - val_masked_recall: 0.7857 - val_masked_f1: 0.7734\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0266 - masked_accuracy: 0.9494 - masked_precision: 0.9178 - masked_recall: 0.9173 - masked_f1: 0.9165 - val_loss: 0.0745 - val_masked_accuracy: 0.8759 - val_masked_precision: 0.8100 - val_masked_recall: 0.7803 - val_masked_f1: 0.7926\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0232 - masked_accuracy: 0.9582 - masked_precision: 0.9353 - masked_recall: 0.9248 - masked_f1: 0.9293 - val_loss: 0.0749 - val_masked_accuracy: 0.8663 - val_masked_precision: 0.7756 - val_masked_recall: 0.7919 - val_masked_f1: 0.7815\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0230 - masked_accuracy: 0.9579 - masked_precision: 0.9362 - masked_recall: 0.9270 - masked_f1: 0.9311 - val_loss: 0.0733 - val_masked_accuracy: 0.8654 - val_masked_precision: 0.7737 - val_masked_recall: 0.7930 - val_masked_f1: 0.7802\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0220 - masked_accuracy: 0.9603 - masked_precision: 0.9339 - masked_recall: 0.9347 - masked_f1: 0.9336 - val_loss: 0.0713 - val_masked_accuracy: 0.8711 - val_masked_precision: 0.7879 - val_masked_recall: 0.7914 - val_masked_f1: 0.7864\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0179 - masked_accuracy: 0.9671 - masked_precision: 0.9451 - masked_recall: 0.9467 - masked_f1: 0.9454 - val_loss: 0.0796 - val_masked_accuracy: 0.8737 - val_masked_precision: 0.7814 - val_masked_recall: 0.8085 - val_masked_f1: 0.7920\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0172 - masked_accuracy: 0.9700 - masked_precision: 0.9527 - masked_recall: 0.9474 - masked_f1: 0.9497 - val_loss: 0.0859 - val_masked_accuracy: 0.8715 - val_masked_precision: 0.7951 - val_masked_recall: 0.7804 - val_masked_f1: 0.7857\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.0742 - masked_accuracy: 0.8838 - masked_precision: 0.8417 - masked_recall: 0.7763 - masked_f1: 0.8044\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1333 - masked_accuracy: 0.6818 - masked_precision: 0.4928 - masked_recall: 0.3871 - masked_f1: 0.4256 - val_loss: 0.1004 - val_masked_accuracy: 0.7592 - val_masked_precision: 0.6814 - val_masked_recall: 0.4858 - val_masked_f1: 0.5649\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0988 - masked_accuracy: 0.7701 - masked_precision: 0.6430 - masked_recall: 0.5430 - masked_f1: 0.5855 - val_loss: 0.0836 - val_masked_accuracy: 0.8116 - val_masked_precision: 0.7326 - val_masked_recall: 0.6579 - val_masked_f1: 0.6893\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0821 - masked_accuracy: 0.8173 - masked_precision: 0.7117 - masked_recall: 0.6712 - masked_f1: 0.6874 - val_loss: 0.0743 - val_masked_accuracy: 0.8366 - val_masked_precision: 0.8024 - val_masked_recall: 0.6548 - val_masked_f1: 0.7191\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0751 - masked_accuracy: 0.8416 - masked_precision: 0.7516 - masked_recall: 0.7148 - masked_f1: 0.7279 - val_loss: 0.0692 - val_masked_accuracy: 0.8464 - val_masked_precision: 0.8047 - val_masked_recall: 0.6928 - val_masked_f1: 0.7401\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0668 - masked_accuracy: 0.8622 - masked_precision: 0.7875 - masked_recall: 0.7457 - masked_f1: 0.7628 - val_loss: 0.0658 - val_masked_accuracy: 0.8701 - val_masked_precision: 0.8238 - val_masked_recall: 0.7605 - val_masked_f1: 0.7893\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0580 - masked_accuracy: 0.8799 - masked_precision: 0.8141 - masked_recall: 0.7845 - masked_f1: 0.7960 - val_loss: 0.0633 - val_masked_accuracy: 0.8684 - val_masked_precision: 0.8183 - val_masked_recall: 0.7638 - val_masked_f1: 0.7880\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0539 - masked_accuracy: 0.8914 - masked_precision: 0.8390 - masked_recall: 0.7947 - masked_f1: 0.8133 - val_loss: 0.0637 - val_masked_accuracy: 0.8664 - val_masked_precision: 0.8009 - val_masked_recall: 0.7835 - val_masked_f1: 0.7902\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0467 - masked_accuracy: 0.9063 - masked_precision: 0.8592 - masked_recall: 0.8269 - masked_f1: 0.8411 - val_loss: 0.0620 - val_masked_accuracy: 0.8784 - val_masked_precision: 0.8313 - val_masked_recall: 0.7844 - val_masked_f1: 0.8047\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0425 - masked_accuracy: 0.9186 - masked_precision: 0.8674 - masked_recall: 0.8596 - masked_f1: 0.8614 - val_loss: 0.0642 - val_masked_accuracy: 0.8647 - val_masked_precision: 0.8532 - val_masked_recall: 0.6996 - val_masked_f1: 0.7656\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0383 - masked_accuracy: 0.9245 - masked_precision: 0.8831 - masked_recall: 0.8634 - masked_f1: 0.8721 - val_loss: 0.0628 - val_masked_accuracy: 0.8768 - val_masked_precision: 0.8320 - val_masked_recall: 0.7749 - val_masked_f1: 0.8002\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0335 - masked_accuracy: 0.9345 - masked_precision: 0.8961 - masked_recall: 0.8862 - masked_f1: 0.8905 - val_loss: 0.0654 - val_masked_accuracy: 0.8772 - val_masked_precision: 0.8389 - val_masked_recall: 0.7619 - val_masked_f1: 0.7972\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 45s 813ms/step - loss: 0.0313 - masked_accuracy: 0.9411 - masked_precision: 0.9106 - masked_recall: 0.8916 - masked_f1: 0.9002 - val_loss: 0.0701 - val_masked_accuracy: 0.8729 - val_masked_precision: 0.8510 - val_masked_recall: 0.7308 - val_masked_f1: 0.7842\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0286 - masked_accuracy: 0.9486 - masked_precision: 0.9244 - masked_recall: 0.9049 - masked_f1: 0.9138 - val_loss: 0.0672 - val_masked_accuracy: 0.8777 - val_masked_precision: 0.8127 - val_masked_recall: 0.8116 - val_masked_f1: 0.8096\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.0597 - masked_accuracy: 0.8827 - masked_precision: 0.7902 - masked_recall: 0.8233 - masked_f1: 0.8045\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 46s 807ms/step - loss: 0.1385 - masked_accuracy: 0.6586 - masked_precision: 0.4503 - masked_recall: 0.4062 - masked_f1: 0.4150 - val_loss: 0.1221 - val_masked_accuracy: 0.7574 - val_masked_precision: 0.6762 - val_masked_recall: 0.4009 - val_masked_f1: 0.4976\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.1046 - masked_accuracy: 0.7517 - masked_precision: 0.6195 - masked_recall: 0.4682 - masked_f1: 0.5291 - val_loss: 0.0991 - val_masked_accuracy: 0.7952 - val_masked_precision: 0.7013 - val_masked_recall: 0.5693 - val_masked_f1: 0.6257\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0863 - masked_accuracy: 0.8080 - masked_precision: 0.7030 - masked_recall: 0.6344 - masked_f1: 0.6631 - val_loss: 0.0883 - val_masked_accuracy: 0.8326 - val_masked_precision: 0.7317 - val_masked_recall: 0.7169 - val_masked_f1: 0.7220\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0761 - masked_accuracy: 0.8368 - masked_precision: 0.7422 - masked_recall: 0.7082 - masked_f1: 0.7214 - val_loss: 0.0792 - val_masked_accuracy: 0.8571 - val_masked_precision: 0.7687 - val_masked_recall: 0.7586 - val_masked_f1: 0.7612\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0677 - masked_accuracy: 0.8583 - masked_precision: 0.7750 - masked_recall: 0.7479 - masked_f1: 0.7586 - val_loss: 0.0757 - val_masked_accuracy: 0.8508 - val_masked_precision: 0.7913 - val_masked_recall: 0.7056 - val_masked_f1: 0.7428\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0598 - masked_accuracy: 0.8792 - masked_precision: 0.8032 - masked_recall: 0.7822 - masked_f1: 0.7904 - val_loss: 0.0716 - val_masked_accuracy: 0.8639 - val_masked_precision: 0.8362 - val_masked_recall: 0.6988 - val_masked_f1: 0.7575\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0530 - masked_accuracy: 0.8901 - masked_precision: 0.8300 - masked_recall: 0.7999 - masked_f1: 0.8118 - val_loss: 0.0692 - val_masked_accuracy: 0.8700 - val_masked_precision: 0.8196 - val_masked_recall: 0.7357 - val_masked_f1: 0.7730\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0458 - masked_accuracy: 0.9108 - masked_precision: 0.8581 - masked_recall: 0.8376 - masked_f1: 0.8459 - val_loss: 0.0700 - val_masked_accuracy: 0.8701 - val_masked_precision: 0.7784 - val_masked_recall: 0.8013 - val_masked_f1: 0.7874\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0413 - masked_accuracy: 0.9192 - masked_precision: 0.8711 - masked_recall: 0.8563 - masked_f1: 0.8621 - val_loss: 0.0674 - val_masked_accuracy: 0.8775 - val_masked_precision: 0.8217 - val_masked_recall: 0.7655 - val_masked_f1: 0.7895\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0382 - masked_accuracy: 0.9260 - masked_precision: 0.8849 - masked_recall: 0.8688 - masked_f1: 0.8752 - val_loss: 0.0678 - val_masked_accuracy: 0.8804 - val_masked_precision: 0.8309 - val_masked_recall: 0.7701 - val_masked_f1: 0.7949\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 45s 797ms/step - loss: 0.0339 - masked_accuracy: 0.9344 - masked_precision: 0.9006 - masked_recall: 0.8769 - masked_f1: 0.8875 - val_loss: 0.0702 - val_masked_accuracy: 0.8735 - val_masked_precision: 0.7814 - val_masked_recall: 0.8174 - val_masked_f1: 0.7955\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0303 - masked_accuracy: 0.9428 - masked_precision: 0.9115 - masked_recall: 0.8979 - masked_f1: 0.9035 - val_loss: 0.0718 - val_masked_accuracy: 0.8743 - val_masked_precision: 0.8133 - val_masked_recall: 0.7629 - val_masked_f1: 0.7836\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 45s 798ms/step - loss: 0.0285 - masked_accuracy: 0.9465 - masked_precision: 0.9168 - masked_recall: 0.9038 - masked_f1: 0.9093 - val_loss: 0.0738 - val_masked_accuracy: 0.8760 - val_masked_precision: 0.8173 - val_masked_recall: 0.7672 - val_masked_f1: 0.7880\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 45s 798ms/step - loss: 0.0273 - masked_accuracy: 0.9490 - masked_precision: 0.9209 - masked_recall: 0.9075 - masked_f1: 0.9135 - val_loss: 0.0741 - val_masked_accuracy: 0.8818 - val_masked_precision: 0.8057 - val_masked_recall: 0.8089 - val_masked_f1: 0.8042\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0248 - masked_accuracy: 0.9529 - masked_precision: 0.9225 - masked_recall: 0.9172 - masked_f1: 0.9192 - val_loss: 0.0793 - val_masked_accuracy: 0.8838 - val_masked_precision: 0.8415 - val_masked_recall: 0.7620 - val_masked_f1: 0.7970\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0221 - masked_accuracy: 0.9602 - masked_precision: 0.9359 - masked_recall: 0.9326 - masked_f1: 0.9336 - val_loss: 0.0789 - val_masked_accuracy: 0.8760 - val_masked_precision: 0.8017 - val_masked_recall: 0.7923 - val_masked_f1: 0.7937\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0212 - masked_accuracy: 0.9614 - masked_precision: 0.9393 - masked_recall: 0.9293 - masked_f1: 0.9336 - val_loss: 0.0741 - val_masked_accuracy: 0.8782 - val_masked_precision: 0.8193 - val_masked_recall: 0.7713 - val_masked_f1: 0.7914\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0203 - masked_accuracy: 0.9621 - masked_precision: 0.9453 - masked_recall: 0.9287 - masked_f1: 0.9363 - val_loss: 0.0788 - val_masked_accuracy: 0.8740 - val_masked_precision: 0.7952 - val_masked_recall: 0.7912 - val_masked_f1: 0.7899\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 45s 797ms/step - loss: 0.0191 - masked_accuracy: 0.9647 - masked_precision: 0.9375 - masked_recall: 0.9449 - masked_f1: 0.9407 - val_loss: 0.0849 - val_masked_accuracy: 0.8802 - val_masked_precision: 0.8187 - val_masked_recall: 0.7778 - val_masked_f1: 0.7952\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0182 - masked_accuracy: 0.9673 - masked_precision: 0.9507 - masked_recall: 0.9406 - masked_f1: 0.9449 - val_loss: 0.0878 - val_masked_accuracy: 0.8816 - val_masked_precision: 0.8310 - val_masked_recall: 0.7680 - val_masked_f1: 0.7952\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.0738 - masked_accuracy: 0.8831 - masked_precision: 0.8648 - masked_recall: 0.7724 - masked_f1: 0.8129\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 788ms/step - loss: 0.1390 - masked_accuracy: 0.6590 - masked_precision: 0.4584 - masked_recall: 0.3965 - masked_f1: 0.4180 - val_loss: 0.1115 - val_masked_accuracy: 0.7517 - val_masked_precision: 0.6220 - val_masked_recall: 0.4202 - val_masked_f1: 0.4989\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0998 - masked_accuracy: 0.7697 - masked_precision: 0.6501 - masked_recall: 0.5545 - masked_f1: 0.5931 - val_loss: 0.0845 - val_masked_accuracy: 0.8194 - val_masked_precision: 0.7694 - val_masked_recall: 0.5629 - val_masked_f1: 0.6461\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0824 - masked_accuracy: 0.8172 - masked_precision: 0.7299 - masked_recall: 0.6539 - masked_f1: 0.6860 - val_loss: 0.0747 - val_masked_accuracy: 0.8361 - val_masked_precision: 0.7195 - val_masked_recall: 0.7268 - val_masked_f1: 0.7201\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0715 - masked_accuracy: 0.8492 - masked_precision: 0.7643 - masked_recall: 0.7450 - masked_f1: 0.7517 - val_loss: 0.0709 - val_masked_accuracy: 0.8608 - val_masked_precision: 0.7875 - val_masked_recall: 0.7287 - val_masked_f1: 0.7535\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0636 - masked_accuracy: 0.8680 - masked_precision: 0.7933 - masked_recall: 0.7759 - masked_f1: 0.7820 - val_loss: 0.0666 - val_masked_accuracy: 0.8688 - val_masked_precision: 0.7927 - val_masked_recall: 0.7534 - val_masked_f1: 0.7701\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0564 - masked_accuracy: 0.8841 - masked_precision: 0.8198 - masked_recall: 0.8017 - masked_f1: 0.8086 - val_loss: 0.0651 - val_masked_accuracy: 0.8711 - val_masked_precision: 0.8079 - val_masked_recall: 0.7399 - val_masked_f1: 0.7700\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0519 - masked_accuracy: 0.8934 - masked_precision: 0.8365 - masked_recall: 0.8105 - masked_f1: 0.8212 - val_loss: 0.0659 - val_masked_accuracy: 0.8675 - val_masked_precision: 0.7651 - val_masked_recall: 0.7965 - val_masked_f1: 0.7785\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0468 - masked_accuracy: 0.9097 - masked_precision: 0.8627 - masked_recall: 0.8433 - masked_f1: 0.8508 - val_loss: 0.0608 - val_masked_accuracy: 0.8704 - val_masked_precision: 0.7655 - val_masked_recall: 0.8093 - val_masked_f1: 0.7851\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0416 - masked_accuracy: 0.9174 - masked_precision: 0.8724 - masked_recall: 0.8578 - masked_f1: 0.8633 - val_loss: 0.0644 - val_masked_accuracy: 0.8786 - val_masked_precision: 0.8338 - val_masked_recall: 0.7341 - val_masked_f1: 0.7790\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 45s 801ms/step - loss: 0.0368 - masked_accuracy: 0.9314 - masked_precision: 0.8927 - masked_recall: 0.8841 - masked_f1: 0.8872 - val_loss: 0.0664 - val_masked_accuracy: 0.8800 - val_masked_precision: 0.8083 - val_masked_recall: 0.7722 - val_masked_f1: 0.7878\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0351 - masked_accuracy: 0.9337 - masked_precision: 0.8945 - masked_recall: 0.8876 - masked_f1: 0.8892 - val_loss: 0.0676 - val_masked_accuracy: 0.8825 - val_masked_precision: 0.8346 - val_masked_recall: 0.7483 - val_masked_f1: 0.7873\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0313 - masked_accuracy: 0.9403 - masked_precision: 0.9090 - masked_recall: 0.9011 - masked_f1: 0.9037 - val_loss: 0.0631 - val_masked_accuracy: 0.8829 - val_masked_precision: 0.8048 - val_masked_recall: 0.7933 - val_masked_f1: 0.7970\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0284 - masked_accuracy: 0.9457 - masked_precision: 0.9140 - masked_recall: 0.9108 - masked_f1: 0.9115 - val_loss: 0.0662 - val_masked_accuracy: 0.8790 - val_masked_precision: 0.7910 - val_masked_recall: 0.8015 - val_masked_f1: 0.7942\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0253 - masked_accuracy: 0.9532 - masked_precision: 0.9208 - masked_recall: 0.9287 - masked_f1: 0.9237 - val_loss: 0.0687 - val_masked_accuracy: 0.8895 - val_masked_precision: 0.8121 - val_masked_recall: 0.8075 - val_masked_f1: 0.8082\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0240 - masked_accuracy: 0.9533 - masked_precision: 0.9286 - masked_recall: 0.9201 - masked_f1: 0.9235 - val_loss: 0.0663 - val_masked_accuracy: 0.8874 - val_masked_precision: 0.8084 - val_masked_recall: 0.8074 - val_masked_f1: 0.8062\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0240 - masked_accuracy: 0.9560 - masked_precision: 0.9306 - masked_recall: 0.9306 - masked_f1: 0.9296 - val_loss: 0.0633 - val_masked_accuracy: 0.8892 - val_masked_precision: 0.8223 - val_masked_recall: 0.7940 - val_masked_f1: 0.8061\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 45s 804ms/step - loss: 0.0198 - masked_accuracy: 0.9637 - masked_precision: 0.9445 - masked_recall: 0.9385 - masked_f1: 0.9411 - val_loss: 0.0727 - val_masked_accuracy: 0.8864 - val_masked_precision: 0.8119 - val_masked_recall: 0.7978 - val_masked_f1: 0.8028\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0203 - masked_accuracy: 0.9638 - masked_precision: 0.9446 - masked_recall: 0.9394 - masked_f1: 0.9414 - val_loss: 0.0771 - val_masked_accuracy: 0.8892 - val_masked_precision: 0.8188 - val_masked_recall: 0.8019 - val_masked_f1: 0.8078\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0174 - masked_accuracy: 0.9692 - masked_precision: 0.9528 - masked_recall: 0.9475 - masked_f1: 0.9498 - val_loss: 0.0692 - val_masked_accuracy: 0.8879 - val_masked_precision: 0.8076 - val_masked_recall: 0.8118 - val_masked_f1: 0.8069\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.0698 - masked_accuracy: 0.8957 - masked_precision: 0.8455 - masked_recall: 0.8084 - masked_f1: 0.8243\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 777ms/step - loss: 0.1522 - masked_accuracy: 0.6684 - masked_precision: 0.4711 - masked_recall: 0.4683 - masked_f1: 0.4586 - val_loss: 0.1154 - val_masked_accuracy: 0.7431 - val_masked_precision: 0.6904 - val_masked_recall: 0.4103 - val_masked_f1: 0.5094\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1107 - masked_accuracy: 0.7351 - masked_precision: 0.5875 - masked_recall: 0.4523 - masked_f1: 0.5058 - val_loss: 0.0934 - val_masked_accuracy: 0.7970 - val_masked_precision: 0.7403 - val_masked_recall: 0.6005 - val_masked_f1: 0.6583\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0906 - masked_accuracy: 0.7967 - masked_precision: 0.6904 - masked_recall: 0.5883 - masked_f1: 0.6314 - val_loss: 0.0815 - val_masked_accuracy: 0.8181 - val_masked_precision: 0.7053 - val_masked_recall: 0.7772 - val_masked_f1: 0.7351\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0797 - masked_accuracy: 0.8279 - masked_precision: 0.7213 - masked_recall: 0.6977 - masked_f1: 0.7051 - val_loss: 0.0797 - val_masked_accuracy: 0.8251 - val_masked_precision: 0.7089 - val_masked_recall: 0.7989 - val_masked_f1: 0.7476\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0696 - masked_accuracy: 0.8509 - masked_precision: 0.7643 - masked_recall: 0.7321 - masked_f1: 0.7451 - val_loss: 0.0688 - val_masked_accuracy: 0.8494 - val_masked_precision: 0.7827 - val_masked_recall: 0.7534 - val_masked_f1: 0.7646\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0642 - masked_accuracy: 0.8679 - masked_precision: 0.7948 - masked_recall: 0.7638 - masked_f1: 0.7763 - val_loss: 0.0680 - val_masked_accuracy: 0.8539 - val_masked_precision: 0.8113 - val_masked_recall: 0.7319 - val_masked_f1: 0.7656\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0585 - masked_accuracy: 0.8818 - masked_precision: 0.8118 - masked_recall: 0.7936 - masked_f1: 0.8007 - val_loss: 0.0659 - val_masked_accuracy: 0.8570 - val_masked_precision: 0.8095 - val_masked_recall: 0.7529 - val_masked_f1: 0.7771\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0529 - masked_accuracy: 0.8900 - masked_precision: 0.8321 - masked_recall: 0.7953 - masked_f1: 0.8113 - val_loss: 0.0637 - val_masked_accuracy: 0.8625 - val_masked_precision: 0.8055 - val_masked_recall: 0.7738 - val_masked_f1: 0.7870\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0478 - masked_accuracy: 0.9072 - masked_precision: 0.8551 - masked_recall: 0.8315 - masked_f1: 0.8416 - val_loss: 0.0638 - val_masked_accuracy: 0.8648 - val_masked_precision: 0.7923 - val_masked_recall: 0.8067 - val_masked_f1: 0.7971\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0422 - masked_accuracy: 0.9167 - masked_precision: 0.8715 - masked_recall: 0.8460 - masked_f1: 0.8573 - val_loss: 0.0683 - val_masked_accuracy: 0.8671 - val_masked_precision: 0.7794 - val_masked_recall: 0.8359 - val_masked_f1: 0.8049\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0406 - masked_accuracy: 0.9214 - masked_precision: 0.8870 - masked_recall: 0.8526 - masked_f1: 0.8675 - val_loss: 0.0651 - val_masked_accuracy: 0.8696 - val_masked_precision: 0.8242 - val_masked_recall: 0.7715 - val_masked_f1: 0.7950\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0384 - masked_accuracy: 0.9236 - masked_precision: 0.8815 - masked_recall: 0.8670 - masked_f1: 0.8726 - val_loss: 0.0679 - val_masked_accuracy: 0.8662 - val_masked_precision: 0.7762 - val_masked_recall: 0.8428 - val_masked_f1: 0.8051\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0341 - masked_accuracy: 0.9368 - masked_precision: 0.9004 - masked_recall: 0.8876 - masked_f1: 0.8927 - val_loss: 0.0663 - val_masked_accuracy: 0.8737 - val_masked_precision: 0.8274 - val_masked_recall: 0.7883 - val_masked_f1: 0.8042\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0319 - masked_accuracy: 0.9379 - masked_precision: 0.9039 - masked_recall: 0.8898 - masked_f1: 0.8959 - val_loss: 0.0684 - val_masked_accuracy: 0.8732 - val_masked_precision: 0.8485 - val_masked_recall: 0.7521 - val_masked_f1: 0.7946\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0276 - masked_accuracy: 0.9475 - masked_precision: 0.9208 - masked_recall: 0.9061 - masked_f1: 0.9126 - val_loss: 0.0703 - val_masked_accuracy: 0.8754 - val_masked_precision: 0.8376 - val_masked_recall: 0.7716 - val_masked_f1: 0.8009\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 45s 802ms/step - loss: 0.0271 - masked_accuracy: 0.9491 - masked_precision: 0.9214 - masked_recall: 0.9112 - masked_f1: 0.9154 - val_loss: 0.0753 - val_masked_accuracy: 0.8719 - val_masked_precision: 0.8263 - val_masked_recall: 0.7792 - val_masked_f1: 0.7992\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 45s 805ms/step - loss: 0.0238 - masked_accuracy: 0.9559 - masked_precision: 0.9293 - masked_recall: 0.9246 - masked_f1: 0.9263 - val_loss: 0.0654 - val_masked_accuracy: 0.8792 - val_masked_precision: 0.8296 - val_masked_recall: 0.8010 - val_masked_f1: 0.8123\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 45s 795ms/step - loss: 0.0228 - masked_accuracy: 0.9575 - masked_precision: 0.9319 - masked_recall: 0.9252 - masked_f1: 0.9278 - val_loss: 0.0715 - val_masked_accuracy: 0.8721 - val_masked_precision: 0.8042 - val_masked_recall: 0.8124 - val_masked_f1: 0.8057\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 45s 798ms/step - loss: 0.0202 - masked_accuracy: 0.9639 - masked_precision: 0.9413 - masked_recall: 0.9367 - masked_f1: 0.9385 - val_loss: 0.0744 - val_masked_accuracy: 0.8757 - val_masked_precision: 0.7988 - val_masked_recall: 0.8330 - val_masked_f1: 0.8124\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0213 - masked_accuracy: 0.9595 - masked_precision: 0.9357 - masked_recall: 0.9311 - masked_f1: 0.9328 - val_loss: 0.0738 - val_masked_accuracy: 0.8697 - val_masked_precision: 0.8241 - val_masked_recall: 0.7756 - val_masked_f1: 0.7954\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.0188 - masked_accuracy: 0.9675 - masked_precision: 0.9477 - masked_recall: 0.9458 - masked_f1: 0.9462 - val_loss: 0.0808 - val_masked_accuracy: 0.8640 - val_masked_precision: 0.8230 - val_masked_recall: 0.7541 - val_masked_f1: 0.7850\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 45s 799ms/step - loss: 0.0175 - masked_accuracy: 0.9686 - masked_precision: 0.9489 - masked_recall: 0.9481 - masked_f1: 0.9480 - val_loss: 0.0817 - val_masked_accuracy: 0.8704 - val_masked_precision: 0.8129 - val_masked_recall: 0.7907 - val_masked_f1: 0.7990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.0660 - masked_accuracy: 0.8783 - masked_precision: 0.8136 - masked_recall: 0.7900 - masked_f1: 0.7984\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 798ms/step - loss: 0.1360 - masked_accuracy: 0.6825 - masked_precision: 0.4976 - masked_recall: 0.4443 - masked_f1: 0.4593 - val_loss: 0.1126 - val_masked_accuracy: 0.7395 - val_masked_precision: 0.6028 - val_masked_recall: 0.4590 - val_masked_f1: 0.5149\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.1010 - masked_accuracy: 0.7509 - masked_precision: 0.6228 - masked_recall: 0.4885 - masked_f1: 0.5411 - val_loss: 0.0902 - val_masked_accuracy: 0.7739 - val_masked_precision: 0.6388 - val_masked_recall: 0.6021 - val_masked_f1: 0.6152\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 45s 805ms/step - loss: 0.0834 - masked_accuracy: 0.8065 - masked_precision: 0.7047 - masked_recall: 0.6399 - masked_f1: 0.6663 - val_loss: 0.0778 - val_masked_accuracy: 0.8336 - val_masked_precision: 0.7307 - val_masked_recall: 0.7199 - val_masked_f1: 0.7229\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0723 - masked_accuracy: 0.8408 - masked_precision: 0.7600 - masked_recall: 0.7103 - masked_f1: 0.7313 - val_loss: 0.0743 - val_masked_accuracy: 0.8466 - val_masked_precision: 0.7711 - val_masked_recall: 0.7009 - val_masked_f1: 0.7315\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0641 - masked_accuracy: 0.8619 - masked_precision: 0.7831 - masked_recall: 0.7559 - masked_f1: 0.7670 - val_loss: 0.0723 - val_masked_accuracy: 0.8441 - val_masked_precision: 0.7684 - val_masked_recall: 0.6982 - val_masked_f1: 0.7291\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0574 - masked_accuracy: 0.8835 - masked_precision: 0.8278 - masked_recall: 0.7854 - masked_f1: 0.8043 - val_loss: 0.0684 - val_masked_accuracy: 0.8608 - val_masked_precision: 0.7817 - val_masked_recall: 0.7524 - val_masked_f1: 0.7649\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0520 - masked_accuracy: 0.8909 - masked_precision: 0.8328 - masked_recall: 0.8023 - masked_f1: 0.8160 - val_loss: 0.0686 - val_masked_accuracy: 0.8680 - val_masked_precision: 0.8168 - val_masked_recall: 0.7277 - val_masked_f1: 0.7679\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0463 - masked_accuracy: 0.9083 - masked_precision: 0.8635 - masked_recall: 0.8344 - masked_f1: 0.8475 - val_loss: 0.0669 - val_masked_accuracy: 0.8648 - val_masked_precision: 0.7940 - val_masked_recall: 0.7448 - val_masked_f1: 0.7668\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.0417 - masked_accuracy: 0.9152 - masked_precision: 0.8703 - masked_recall: 0.8463 - masked_f1: 0.8565 - val_loss: 0.0670 - val_masked_accuracy: 0.8695 - val_masked_precision: 0.7959 - val_masked_recall: 0.7705 - val_masked_f1: 0.7811\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0381 - masked_accuracy: 0.9233 - masked_precision: 0.8875 - masked_recall: 0.8594 - masked_f1: 0.8717 - val_loss: 0.0712 - val_masked_accuracy: 0.8754 - val_masked_precision: 0.8262 - val_masked_recall: 0.7430 - val_masked_f1: 0.7811\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0376 - masked_accuracy: 0.9249 - masked_precision: 0.8867 - masked_recall: 0.8706 - masked_f1: 0.8765 - val_loss: 0.0753 - val_masked_accuracy: 0.8697 - val_masked_precision: 0.8112 - val_masked_recall: 0.7375 - val_masked_f1: 0.7705\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 43s 775ms/step - loss: 0.0331 - masked_accuracy: 0.9351 - masked_precision: 0.9022 - masked_recall: 0.8892 - masked_f1: 0.8942 - val_loss: 0.0791 - val_masked_accuracy: 0.8684 - val_masked_precision: 0.8199 - val_masked_recall: 0.7232 - val_masked_f1: 0.7675\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0307 - masked_accuracy: 0.9421 - masked_precision: 0.9140 - masked_recall: 0.8941 - masked_f1: 0.9030 - val_loss: 0.0758 - val_masked_accuracy: 0.8748 - val_masked_precision: 0.8073 - val_masked_recall: 0.7661 - val_masked_f1: 0.7847\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0281 - masked_accuracy: 0.9467 - masked_precision: 0.9193 - masked_recall: 0.9069 - masked_f1: 0.9119 - val_loss: 0.0761 - val_masked_accuracy: 0.8682 - val_masked_precision: 0.8038 - val_masked_recall: 0.7490 - val_masked_f1: 0.7737\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.0258 - masked_accuracy: 0.9513 - masked_precision: 0.9209 - masked_recall: 0.9175 - masked_f1: 0.9185 - val_loss: 0.0767 - val_masked_accuracy: 0.8711 - val_masked_precision: 0.8005 - val_masked_recall: 0.7665 - val_masked_f1: 0.7812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.0732 - masked_accuracy: 0.8686 - masked_precision: 0.7894 - masked_recall: 0.7736 - masked_f1: 0.7787\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1367 - masked_accuracy: 0.6663 - masked_precision: 0.4846 - masked_recall: 0.4245 - masked_f1: 0.4452 - val_loss: 0.1143 - val_masked_accuracy: 0.7684 - val_masked_precision: 0.6224 - val_masked_recall: 0.5114 - val_masked_f1: 0.5599\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 43s 775ms/step - loss: 0.1016 - masked_accuracy: 0.7663 - masked_precision: 0.6608 - masked_recall: 0.5293 - masked_f1: 0.5842 - val_loss: 0.0886 - val_masked_accuracy: 0.8120 - val_masked_precision: 0.6731 - val_masked_recall: 0.6819 - val_masked_f1: 0.6765\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0843 - masked_accuracy: 0.8139 - masked_precision: 0.7286 - masked_recall: 0.6536 - masked_f1: 0.6865 - val_loss: 0.0747 - val_masked_accuracy: 0.8518 - val_masked_precision: 0.7670 - val_masked_recall: 0.6990 - val_masked_f1: 0.7297\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.0729 - masked_accuracy: 0.8495 - masked_precision: 0.7759 - masked_recall: 0.7392 - masked_f1: 0.7549 - val_loss: 0.0689 - val_masked_accuracy: 0.8558 - val_masked_precision: 0.7488 - val_masked_recall: 0.7507 - val_masked_f1: 0.7478\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.0653 - masked_accuracy: 0.8657 - masked_precision: 0.7952 - masked_recall: 0.7702 - masked_f1: 0.7801 - val_loss: 0.0667 - val_masked_accuracy: 0.8648 - val_masked_precision: 0.7950 - val_masked_recall: 0.7222 - val_masked_f1: 0.7538\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.0585 - masked_accuracy: 0.8814 - masked_precision: 0.8255 - masked_recall: 0.7858 - masked_f1: 0.8031 - val_loss: 0.0645 - val_masked_accuracy: 0.8698 - val_masked_precision: 0.7838 - val_masked_recall: 0.7626 - val_masked_f1: 0.7710\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0514 - masked_accuracy: 0.8980 - masked_precision: 0.8482 - masked_recall: 0.8213 - masked_f1: 0.8332 - val_loss: 0.0615 - val_masked_accuracy: 0.8794 - val_masked_precision: 0.7949 - val_masked_recall: 0.7889 - val_masked_f1: 0.7907\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0476 - masked_accuracy: 0.9049 - masked_precision: 0.8577 - masked_recall: 0.8356 - masked_f1: 0.8436 - val_loss: 0.0634 - val_masked_accuracy: 0.8655 - val_masked_precision: 0.7877 - val_masked_recall: 0.7401 - val_masked_f1: 0.7605\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0417 - masked_accuracy: 0.9186 - masked_precision: 0.8815 - masked_recall: 0.8587 - masked_f1: 0.8685 - val_loss: 0.0622 - val_masked_accuracy: 0.8812 - val_masked_precision: 0.7778 - val_masked_recall: 0.8285 - val_masked_f1: 0.8010\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0380 - masked_accuracy: 0.9245 - masked_precision: 0.8917 - masked_recall: 0.8687 - masked_f1: 0.8790 - val_loss: 0.0628 - val_masked_accuracy: 0.8782 - val_masked_precision: 0.7940 - val_masked_recall: 0.7872 - val_masked_f1: 0.7879\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0355 - masked_accuracy: 0.9314 - masked_precision: 0.8949 - masked_recall: 0.8863 - masked_f1: 0.8890 - val_loss: 0.0653 - val_masked_accuracy: 0.8822 - val_masked_precision: 0.7963 - val_masked_recall: 0.8045 - val_masked_f1: 0.7988\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0317 - masked_accuracy: 0.9405 - masked_precision: 0.9104 - masked_recall: 0.9023 - masked_f1: 0.9055 - val_loss: 0.0661 - val_masked_accuracy: 0.8805 - val_masked_precision: 0.8055 - val_masked_recall: 0.7721 - val_masked_f1: 0.7873\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0293 - masked_accuracy: 0.9444 - masked_precision: 0.9218 - masked_recall: 0.9000 - masked_f1: 0.9098 - val_loss: 0.0695 - val_masked_accuracy: 0.8860 - val_masked_precision: 0.8052 - val_masked_recall: 0.8002 - val_masked_f1: 0.8009\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.0274 - masked_accuracy: 0.9487 - masked_precision: 0.9233 - masked_recall: 0.9139 - masked_f1: 0.9175 - val_loss: 0.0643 - val_masked_accuracy: 0.8874 - val_masked_precision: 0.8073 - val_masked_recall: 0.8044 - val_masked_f1: 0.8038\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0244 - masked_accuracy: 0.9528 - masked_precision: 0.9315 - masked_recall: 0.9175 - masked_f1: 0.9237 - val_loss: 0.0685 - val_masked_accuracy: 0.8855 - val_masked_precision: 0.8037 - val_masked_recall: 0.8035 - val_masked_f1: 0.8016\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0222 - masked_accuracy: 0.9599 - masked_precision: 0.9376 - masked_recall: 0.9369 - masked_f1: 0.9365 - val_loss: 0.0701 - val_masked_accuracy: 0.8855 - val_masked_precision: 0.8037 - val_masked_recall: 0.8006 - val_masked_f1: 0.8007\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0219 - masked_accuracy: 0.9597 - masked_precision: 0.9420 - masked_recall: 0.9329 - masked_f1: 0.9367 - val_loss: 0.0735 - val_masked_accuracy: 0.8836 - val_masked_precision: 0.7879 - val_masked_recall: 0.8185 - val_masked_f1: 0.8012\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0211 - masked_accuracy: 0.9623 - masked_precision: 0.9417 - masked_recall: 0.9363 - masked_f1: 0.9385 - val_loss: 0.0755 - val_masked_accuracy: 0.8911 - val_masked_precision: 0.8374 - val_masked_recall: 0.7780 - val_masked_f1: 0.8045\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0193 - masked_accuracy: 0.9653 - masked_precision: 0.9442 - masked_recall: 0.9444 - masked_f1: 0.9439 - val_loss: 0.0757 - val_masked_accuracy: 0.8855 - val_masked_precision: 0.8133 - val_masked_recall: 0.7883 - val_masked_f1: 0.7989\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0176 - masked_accuracy: 0.9678 - masked_precision: 0.9522 - masked_recall: 0.9452 - masked_f1: 0.9481 - val_loss: 0.0742 - val_masked_accuracy: 0.8884 - val_masked_precision: 0.8158 - val_masked_recall: 0.7971 - val_masked_f1: 0.8050\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0176 - masked_accuracy: 0.9696 - masked_precision: 0.9558 - masked_recall: 0.9494 - masked_f1: 0.9521 - val_loss: 0.0762 - val_masked_accuracy: 0.8858 - val_masked_precision: 0.8038 - val_masked_recall: 0.8051 - val_masked_f1: 0.8027\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0162 - masked_accuracy: 0.9722 - masked_precision: 0.9585 - masked_recall: 0.9547 - masked_f1: 0.9562 - val_loss: 0.0825 - val_masked_accuracy: 0.8866 - val_masked_precision: 0.8327 - val_masked_recall: 0.7648 - val_masked_f1: 0.7956\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0153 - masked_accuracy: 0.9720 - masked_precision: 0.9598 - masked_recall: 0.9507 - masked_f1: 0.9550 - val_loss: 0.0789 - val_masked_accuracy: 0.8904 - val_masked_precision: 0.8044 - val_masked_recall: 0.8243 - val_masked_f1: 0.8135\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.0804 - masked_accuracy: 0.8795 - masked_precision: 0.8320 - masked_recall: 0.7429 - masked_f1: 0.7833\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 47s 824ms/step - loss: 0.1369 - masked_accuracy: 0.6825 - masked_precision: 0.4994 - masked_recall: 0.4131 - masked_f1: 0.4404 - val_loss: 0.1210 - val_masked_accuracy: 0.7437 - val_masked_precision: 0.7087 - val_masked_recall: 0.3793 - val_masked_f1: 0.4927\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.1022 - masked_accuracy: 0.7562 - masked_precision: 0.6388 - masked_recall: 0.4625 - masked_f1: 0.5323 - val_loss: 0.0922 - val_masked_accuracy: 0.8136 - val_masked_precision: 0.7806 - val_masked_recall: 0.6139 - val_masked_f1: 0.6839\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 51s 918ms/step - loss: 0.0854 - masked_accuracy: 0.8049 - masked_precision: 0.7056 - masked_recall: 0.6261 - masked_f1: 0.6597 - val_loss: 0.0848 - val_masked_accuracy: 0.8426 - val_masked_precision: 0.7897 - val_masked_recall: 0.7158 - val_masked_f1: 0.7482\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 52s 924ms/step - loss: 0.0739 - masked_accuracy: 0.8368 - masked_precision: 0.7528 - masked_recall: 0.6874 - masked_f1: 0.7155 - val_loss: 0.0766 - val_masked_accuracy: 0.8513 - val_masked_precision: 0.8275 - val_masked_recall: 0.6951 - val_masked_f1: 0.7526\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 51s 911ms/step - loss: 0.0642 - masked_accuracy: 0.8625 - masked_precision: 0.7966 - masked_recall: 0.7450 - masked_f1: 0.7660 - val_loss: 0.0740 - val_masked_accuracy: 0.8562 - val_masked_precision: 0.7698 - val_masked_recall: 0.8113 - val_masked_f1: 0.7871\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.0585 - masked_accuracy: 0.8841 - masked_precision: 0.8249 - masked_recall: 0.7886 - masked_f1: 0.8041 - val_loss: 0.0713 - val_masked_accuracy: 0.8541 - val_masked_precision: 0.7840 - val_masked_recall: 0.7815 - val_masked_f1: 0.7785\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 51s 917ms/step - loss: 0.0524 - masked_accuracy: 0.8924 - masked_precision: 0.8377 - masked_recall: 0.7938 - masked_f1: 0.8128 - val_loss: 0.0707 - val_masked_accuracy: 0.8568 - val_masked_precision: 0.7885 - val_masked_recall: 0.7839 - val_masked_f1: 0.7821\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 51s 917ms/step - loss: 0.0465 - masked_accuracy: 0.9088 - masked_precision: 0.8622 - masked_recall: 0.8330 - masked_f1: 0.8455 - val_loss: 0.0694 - val_masked_accuracy: 0.8591 - val_masked_precision: 0.8017 - val_masked_recall: 0.7664 - val_masked_f1: 0.7806\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 51s 913ms/step - loss: 0.0419 - masked_accuracy: 0.9168 - masked_precision: 0.8751 - masked_recall: 0.8529 - masked_f1: 0.8621 - val_loss: 0.0752 - val_masked_accuracy: 0.8731 - val_masked_precision: 0.8447 - val_masked_recall: 0.7599 - val_masked_f1: 0.7954\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 51s 915ms/step - loss: 0.0379 - masked_accuracy: 0.9277 - masked_precision: 0.8901 - masked_recall: 0.8662 - masked_f1: 0.8770 - val_loss: 0.0715 - val_masked_accuracy: 0.8668 - val_masked_precision: 0.8067 - val_masked_recall: 0.7873 - val_masked_f1: 0.7944\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 51s 916ms/step - loss: 0.0343 - masked_accuracy: 0.9331 - masked_precision: 0.8935 - masked_recall: 0.8863 - masked_f1: 0.8890 - val_loss: 0.0724 - val_masked_accuracy: 0.8694 - val_masked_precision: 0.8121 - val_masked_recall: 0.7912 - val_masked_f1: 0.7987\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 52s 923ms/step - loss: 0.0317 - masked_accuracy: 0.9390 - masked_precision: 0.9102 - masked_recall: 0.8885 - masked_f1: 0.8985 - val_loss: 0.0722 - val_masked_accuracy: 0.8707 - val_masked_precision: 0.8167 - val_masked_recall: 0.7885 - val_masked_f1: 0.7995\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 52s 926ms/step - loss: 0.0290 - masked_accuracy: 0.9452 - masked_precision: 0.9146 - masked_recall: 0.9060 - masked_f1: 0.9094 - val_loss: 0.0758 - val_masked_accuracy: 0.8718 - val_masked_precision: 0.8144 - val_masked_recall: 0.7955 - val_masked_f1: 0.8024\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 52s 921ms/step - loss: 0.0277 - masked_accuracy: 0.9466 - masked_precision: 0.9212 - masked_recall: 0.9053 - masked_f1: 0.9123 - val_loss: 0.0762 - val_masked_accuracy: 0.8685 - val_masked_precision: 0.8269 - val_masked_recall: 0.7660 - val_masked_f1: 0.7913\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 0.0644 - masked_accuracy: 0.8846 - masked_precision: 0.8076 - masked_recall: 0.7679 - masked_f1: 0.7849\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 50s 878ms/step - loss: 0.1309 - masked_accuracy: 0.6886 - masked_precision: 0.4997 - masked_recall: 0.5133 - masked_f1: 0.4981 - val_loss: 0.1146 - val_masked_accuracy: 0.7477 - val_masked_precision: 0.6057 - val_masked_recall: 0.4526 - val_masked_f1: 0.5129\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 49s 870ms/step - loss: 0.1001 - masked_accuracy: 0.7615 - masked_precision: 0.6267 - masked_recall: 0.5339 - masked_f1: 0.5728 - val_loss: 0.0878 - val_masked_accuracy: 0.8150 - val_masked_precision: 0.7259 - val_masked_recall: 0.6183 - val_masked_f1: 0.6649\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 49s 871ms/step - loss: 0.0846 - masked_accuracy: 0.8130 - masked_precision: 0.7057 - masked_recall: 0.6624 - masked_f1: 0.6781 - val_loss: 0.0802 - val_masked_accuracy: 0.8335 - val_masked_precision: 0.7530 - val_masked_recall: 0.6552 - val_masked_f1: 0.6965\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 49s 873ms/step - loss: 0.0724 - masked_accuracy: 0.8428 - masked_precision: 0.7460 - masked_recall: 0.7324 - masked_f1: 0.7349 - val_loss: 0.0748 - val_masked_accuracy: 0.8482 - val_masked_precision: 0.7830 - val_masked_recall: 0.6797 - val_masked_f1: 0.7251\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 49s 868ms/step - loss: 0.0623 - masked_accuracy: 0.8699 - masked_precision: 0.7940 - masked_recall: 0.7728 - masked_f1: 0.7801 - val_loss: 0.0710 - val_masked_accuracy: 0.8565 - val_masked_precision: 0.7987 - val_masked_recall: 0.7018 - val_masked_f1: 0.7418\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 49s 872ms/step - loss: 0.0568 - masked_accuracy: 0.8841 - masked_precision: 0.8176 - masked_recall: 0.7963 - masked_f1: 0.8049 - val_loss: 0.0687 - val_masked_accuracy: 0.8612 - val_masked_precision: 0.7748 - val_masked_recall: 0.7655 - val_masked_f1: 0.7645\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 48s 864ms/step - loss: 0.0503 - masked_accuracy: 0.8984 - masked_precision: 0.8398 - masked_recall: 0.8215 - masked_f1: 0.8288 - val_loss: 0.0737 - val_masked_accuracy: 0.8477 - val_masked_precision: 0.7311 - val_masked_recall: 0.7837 - val_masked_f1: 0.7517\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 49s 875ms/step - loss: 0.0437 - masked_accuracy: 0.9142 - masked_precision: 0.8656 - masked_recall: 0.8517 - masked_f1: 0.8571 - val_loss: 0.0686 - val_masked_accuracy: 0.8603 - val_masked_precision: 0.7695 - val_masked_recall: 0.7685 - val_masked_f1: 0.7638\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 49s 867ms/step - loss: 0.0399 - masked_accuracy: 0.9196 - masked_precision: 0.8727 - masked_recall: 0.8538 - masked_f1: 0.8620 - val_loss: 0.0754 - val_masked_accuracy: 0.8562 - val_masked_precision: 0.7645 - val_masked_recall: 0.7555 - val_masked_f1: 0.7546\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 48s 861ms/step - loss: 0.0361 - masked_accuracy: 0.9284 - masked_precision: 0.8843 - masked_recall: 0.8797 - masked_f1: 0.8806 - val_loss: 0.0712 - val_masked_accuracy: 0.8732 - val_masked_precision: 0.7884 - val_masked_recall: 0.7858 - val_masked_f1: 0.7830\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 0.0309 - masked_accuracy: 0.9417 - masked_precision: 0.9061 - masked_recall: 0.9010 - masked_f1: 0.9028 - val_loss: 0.0758 - val_masked_accuracy: 0.8694 - val_masked_precision: 0.8106 - val_masked_recall: 0.7374 - val_masked_f1: 0.7662\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 48s 861ms/step - loss: 0.0298 - masked_accuracy: 0.9470 - masked_precision: 0.9129 - masked_recall: 0.9121 - masked_f1: 0.9117 - val_loss: 0.0767 - val_masked_accuracy: 0.8734 - val_masked_precision: 0.7909 - val_masked_recall: 0.7853 - val_masked_f1: 0.7826\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 48s 860ms/step - loss: 0.0278 - masked_accuracy: 0.9468 - masked_precision: 0.9114 - masked_recall: 0.9115 - masked_f1: 0.9106 - val_loss: 0.0745 - val_masked_accuracy: 0.8709 - val_masked_precision: 0.7982 - val_masked_recall: 0.7650 - val_masked_f1: 0.7764\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 50s 885ms/step - loss: 0.0242 - masked_accuracy: 0.9536 - masked_precision: 0.9239 - masked_recall: 0.9218 - masked_f1: 0.9219 - val_loss: 0.0802 - val_masked_accuracy: 0.8630 - val_masked_precision: 0.7938 - val_masked_recall: 0.7403 - val_masked_f1: 0.7595\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 49s 869ms/step - loss: 0.0220 - masked_accuracy: 0.9604 - masked_precision: 0.9351 - masked_recall: 0.9336 - masked_f1: 0.9337 - val_loss: 0.0786 - val_masked_accuracy: 0.8604 - val_masked_precision: 0.7654 - val_masked_recall: 0.7747 - val_masked_f1: 0.7652\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 49s 877ms/step - loss: 0.0200 - masked_accuracy: 0.9619 - masked_precision: 0.9338 - masked_recall: 0.9350 - masked_f1: 0.9337 - val_loss: 0.0863 - val_masked_accuracy: 0.8692 - val_masked_precision: 0.8062 - val_masked_recall: 0.7492 - val_masked_f1: 0.7705\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 49s 873ms/step - loss: 0.0179 - masked_accuracy: 0.9661 - masked_precision: 0.9473 - masked_recall: 0.9395 - masked_f1: 0.9428 - val_loss: 0.0921 - val_masked_accuracy: 0.8745 - val_masked_precision: 0.7996 - val_masked_recall: 0.7750 - val_masked_f1: 0.7825\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 49s 873ms/step - loss: 0.0182 - masked_accuracy: 0.9674 - masked_precision: 0.9473 - masked_recall: 0.9467 - masked_f1: 0.9463 - val_loss: 0.0899 - val_masked_accuracy: 0.8610 - val_masked_precision: 0.7936 - val_masked_recall: 0.7315 - val_masked_f1: 0.7547\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 49s 866ms/step - loss: 0.0177 - masked_accuracy: 0.9684 - masked_precision: 0.9472 - masked_recall: 0.9498 - masked_f1: 0.9482 - val_loss: 0.0839 - val_masked_accuracy: 0.8663 - val_masked_precision: 0.7840 - val_masked_recall: 0.7691 - val_masked_f1: 0.7712\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 48s 867ms/step - loss: 0.0165 - masked_accuracy: 0.9699 - masked_precision: 0.9506 - masked_recall: 0.9513 - masked_f1: 0.9504 - val_loss: 0.0950 - val_masked_accuracy: 0.8655 - val_masked_precision: 0.7843 - val_masked_recall: 0.7651 - val_masked_f1: 0.7703\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 48s 859ms/step - loss: 0.0154 - masked_accuracy: 0.9728 - masked_precision: 0.9578 - masked_recall: 0.9527 - masked_f1: 0.9548 - val_loss: 0.0946 - val_masked_accuracy: 0.8655 - val_masked_precision: 0.7935 - val_masked_recall: 0.7600 - val_masked_f1: 0.7694\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 48s 865ms/step - loss: 0.0138 - masked_accuracy: 0.9775 - masked_precision: 0.9605 - masked_recall: 0.9633 - masked_f1: 0.9615 - val_loss: 0.0929 - val_masked_accuracy: 0.8698 - val_masked_precision: 0.7892 - val_masked_recall: 0.7801 - val_masked_f1: 0.7788\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 0.0778 - masked_accuracy: 0.8844 - masked_precision: 0.8387 - masked_recall: 0.7943 - masked_f1: 0.8128\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 48s 846ms/step - loss: 0.1477 - masked_accuracy: 0.6335 - masked_precision: 0.4297 - masked_recall: 0.4869 - masked_f1: 0.4500 - val_loss: 0.1323 - val_masked_accuracy: 0.7612 - val_masked_precision: 0.6525 - val_masked_recall: 0.4680 - val_masked_f1: 0.5426\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 47s 846ms/step - loss: 0.1121 - masked_accuracy: 0.7238 - masked_precision: 0.5689 - masked_recall: 0.4832 - masked_f1: 0.5186 - val_loss: 0.0974 - val_masked_accuracy: 0.8038 - val_masked_precision: 0.7127 - val_masked_recall: 0.5957 - val_masked_f1: 0.6464\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 47s 845ms/step - loss: 0.0917 - masked_accuracy: 0.7842 - masked_precision: 0.6751 - masked_recall: 0.5750 - masked_f1: 0.6182 - val_loss: 0.0799 - val_masked_accuracy: 0.8346 - val_masked_precision: 0.7162 - val_masked_recall: 0.7474 - val_masked_f1: 0.7294\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 48s 854ms/step - loss: 0.0795 - masked_accuracy: 0.8206 - masked_precision: 0.7172 - masked_recall: 0.7003 - masked_f1: 0.7043 - val_loss: 0.0743 - val_masked_accuracy: 0.8355 - val_masked_precision: 0.6957 - val_masked_recall: 0.8130 - val_masked_f1: 0.7482\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 48s 866ms/step - loss: 0.0699 - masked_accuracy: 0.8496 - masked_precision: 0.7560 - masked_recall: 0.7628 - masked_f1: 0.7549 - val_loss: 0.0671 - val_masked_accuracy: 0.8676 - val_masked_precision: 0.7870 - val_masked_recall: 0.7762 - val_masked_f1: 0.7800\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 48s 863ms/step - loss: 0.0608 - masked_accuracy: 0.8745 - masked_precision: 0.8044 - masked_recall: 0.7883 - masked_f1: 0.7934 - val_loss: 0.0627 - val_masked_accuracy: 0.8789 - val_masked_precision: 0.8148 - val_masked_recall: 0.7821 - val_masked_f1: 0.7962\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 48s 852ms/step - loss: 0.0533 - masked_accuracy: 0.8883 - masked_precision: 0.8280 - masked_recall: 0.8099 - masked_f1: 0.8169 - val_loss: 0.0613 - val_masked_accuracy: 0.8827 - val_masked_precision: 0.8357 - val_masked_recall: 0.7675 - val_masked_f1: 0.7984\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 47s 849ms/step - loss: 0.0493 - masked_accuracy: 0.9010 - masked_precision: 0.8479 - masked_recall: 0.8262 - masked_f1: 0.8351 - val_loss: 0.0613 - val_masked_accuracy: 0.8823 - val_masked_precision: 0.8077 - val_masked_recall: 0.8167 - val_masked_f1: 0.8098\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 48s 852ms/step - loss: 0.0438 - masked_accuracy: 0.9116 - masked_precision: 0.8646 - masked_recall: 0.8488 - masked_f1: 0.8553 - val_loss: 0.0619 - val_masked_accuracy: 0.8911 - val_masked_precision: 0.8588 - val_masked_recall: 0.7727 - val_masked_f1: 0.8116\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 48s 855ms/step - loss: 0.0402 - masked_accuracy: 0.9202 - masked_precision: 0.8772 - masked_recall: 0.8556 - masked_f1: 0.8651 - val_loss: 0.0614 - val_masked_accuracy: 0.8869 - val_masked_precision: 0.8684 - val_masked_recall: 0.7460 - val_masked_f1: 0.8007\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 47s 847ms/step - loss: 0.0373 - masked_accuracy: 0.9258 - masked_precision: 0.8861 - masked_recall: 0.8747 - masked_f1: 0.8788 - val_loss: 0.0653 - val_masked_accuracy: 0.8822 - val_masked_precision: 0.8248 - val_masked_recall: 0.7848 - val_masked_f1: 0.8016\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 48s 852ms/step - loss: 0.0334 - masked_accuracy: 0.9357 - masked_precision: 0.8996 - masked_recall: 0.8890 - masked_f1: 0.8935 - val_loss: 0.0656 - val_masked_accuracy: 0.8838 - val_masked_precision: 0.8467 - val_masked_recall: 0.7619 - val_masked_f1: 0.8001\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 48s 858ms/step - loss: 0.0309 - masked_accuracy: 0.9403 - masked_precision: 0.9097 - masked_recall: 0.8948 - masked_f1: 0.9013 - val_loss: 0.0651 - val_masked_accuracy: 0.8891 - val_masked_precision: 0.8555 - val_masked_recall: 0.7751 - val_masked_f1: 0.8102\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 47s 844ms/step - loss: 0.0290 - masked_accuracy: 0.9460 - masked_precision: 0.9202 - masked_recall: 0.9028 - masked_f1: 0.9105 - val_loss: 0.0679 - val_masked_accuracy: 0.8812 - val_masked_precision: 0.8104 - val_masked_recall: 0.8028 - val_masked_f1: 0.8032\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "18/18 [==============================] - 3s 139ms/step - loss: 0.0659 - masked_accuracy: 0.8786 - masked_precision: 0.8260 - masked_recall: 0.7558 - masked_f1: 0.7860\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 47s 834ms/step - loss: 0.1397 - masked_accuracy: 0.6742 - masked_precision: 0.4749 - masked_recall: 0.4535 - masked_f1: 0.4548 - val_loss: 0.1064 - val_masked_accuracy: 0.7717 - val_masked_precision: 0.6866 - val_masked_recall: 0.4735 - val_masked_f1: 0.5559\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 47s 833ms/step - loss: 0.1013 - masked_accuracy: 0.7670 - masked_precision: 0.6425 - masked_recall: 0.5198 - masked_f1: 0.5696 - val_loss: 0.0853 - val_masked_accuracy: 0.8293 - val_masked_precision: 0.7272 - val_masked_recall: 0.7157 - val_masked_f1: 0.7164\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 0.0823 - masked_accuracy: 0.8218 - masked_precision: 0.7188 - masked_recall: 0.6817 - masked_f1: 0.6961 - val_loss: 0.0697 - val_masked_accuracy: 0.8592 - val_masked_precision: 0.8171 - val_masked_recall: 0.7000 - val_masked_f1: 0.7504\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.0699 - masked_accuracy: 0.8539 - masked_precision: 0.7770 - masked_recall: 0.7305 - masked_f1: 0.7501 - val_loss: 0.0635 - val_masked_accuracy: 0.8711 - val_masked_precision: 0.8044 - val_masked_recall: 0.7679 - val_masked_f1: 0.7836\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 47s 837ms/step - loss: 0.0613 - masked_accuracy: 0.8742 - masked_precision: 0.8081 - masked_recall: 0.7717 - masked_f1: 0.7859 - val_loss: 0.0600 - val_masked_accuracy: 0.8720 - val_masked_precision: 0.8074 - val_masked_recall: 0.7672 - val_masked_f1: 0.7843\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 47s 835ms/step - loss: 0.0554 - masked_accuracy: 0.8909 - masked_precision: 0.8319 - masked_recall: 0.8077 - masked_f1: 0.8179 - val_loss: 0.0586 - val_masked_accuracy: 0.8784 - val_masked_precision: 0.8206 - val_masked_recall: 0.7722 - val_masked_f1: 0.7935\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 46s 829ms/step - loss: 0.0498 - masked_accuracy: 0.9023 - masked_precision: 0.8465 - masked_recall: 0.8257 - masked_f1: 0.8344 - val_loss: 0.0589 - val_masked_accuracy: 0.8753 - val_masked_precision: 0.7973 - val_masked_recall: 0.7932 - val_masked_f1: 0.7935\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 46s 830ms/step - loss: 0.0450 - masked_accuracy: 0.9157 - masked_precision: 0.8654 - masked_recall: 0.8578 - masked_f1: 0.8595 - val_loss: 0.0666 - val_masked_accuracy: 0.8679 - val_masked_precision: 0.8599 - val_masked_recall: 0.6776 - val_masked_f1: 0.7557\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 46s 830ms/step - loss: 0.0405 - masked_accuracy: 0.9239 - masked_precision: 0.8797 - masked_recall: 0.8690 - masked_f1: 0.8731 - val_loss: 0.0623 - val_masked_accuracy: 0.8734 - val_masked_precision: 0.8429 - val_masked_recall: 0.7231 - val_masked_f1: 0.7759\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 47s 847ms/step - loss: 0.0361 - masked_accuracy: 0.9331 - masked_precision: 0.8879 - masked_recall: 0.8890 - masked_f1: 0.8876 - val_loss: 0.0588 - val_masked_accuracy: 0.8811 - val_masked_precision: 0.8225 - val_masked_recall: 0.7771 - val_masked_f1: 0.7970\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 47s 840ms/step - loss: 0.0342 - masked_accuracy: 0.9352 - masked_precision: 0.8958 - masked_recall: 0.8899 - masked_f1: 0.8919 - val_loss: 0.0642 - val_masked_accuracy: 0.8846 - val_masked_precision: 0.8414 - val_masked_recall: 0.7658 - val_masked_f1: 0.7998\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 47s 832ms/step - loss: 0.0336 - masked_accuracy: 0.9367 - masked_precision: 0.9002 - masked_recall: 0.8914 - masked_f1: 0.8950 - val_loss: 0.0645 - val_masked_accuracy: 0.8808 - val_masked_precision: 0.8543 - val_masked_recall: 0.7376 - val_masked_f1: 0.7895\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 46s 824ms/step - loss: 0.0287 - masked_accuracy: 0.9463 - masked_precision: 0.9160 - masked_recall: 0.9037 - masked_f1: 0.9088 - val_loss: 0.0638 - val_masked_accuracy: 0.8799 - val_masked_precision: 0.8364 - val_masked_recall: 0.7568 - val_masked_f1: 0.7921\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 46s 828ms/step - loss: 0.0266 - masked_accuracy: 0.9519 - masked_precision: 0.9244 - masked_recall: 0.9159 - masked_f1: 0.9193 - val_loss: 0.0672 - val_masked_accuracy: 0.8842 - val_masked_precision: 0.8444 - val_masked_recall: 0.7618 - val_masked_f1: 0.7986\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 46s 821ms/step - loss: 0.0250 - masked_accuracy: 0.9560 - masked_precision: 0.9254 - masked_recall: 0.9278 - masked_f1: 0.9260 - val_loss: 0.0692 - val_masked_accuracy: 0.8876 - val_masked_precision: 0.8466 - val_masked_recall: 0.7699 - val_masked_f1: 0.8047\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 45s 809ms/step - loss: 0.0239 - masked_accuracy: 0.9543 - masked_precision: 0.9245 - masked_recall: 0.9232 - masked_f1: 0.9230 - val_loss: 0.0656 - val_masked_accuracy: 0.8854 - val_masked_precision: 0.8523 - val_masked_recall: 0.7571 - val_masked_f1: 0.7993\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.0216 - masked_accuracy: 0.9623 - masked_precision: 0.9379 - masked_recall: 0.9372 - masked_f1: 0.9371 - val_loss: 0.0692 - val_masked_accuracy: 0.8796 - val_masked_precision: 0.8465 - val_masked_recall: 0.7381 - val_masked_f1: 0.7860\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0208 - masked_accuracy: 0.9618 - masked_precision: 0.9382 - masked_recall: 0.9377 - masked_f1: 0.9374 - val_loss: 0.0720 - val_masked_accuracy: 0.8808 - val_masked_precision: 0.8627 - val_masked_recall: 0.7273 - val_masked_f1: 0.7863\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.0196 - masked_accuracy: 0.9644 - masked_precision: 0.9463 - masked_recall: 0.9360 - masked_f1: 0.9405 - val_loss: 0.0674 - val_masked_accuracy: 0.8876 - val_masked_precision: 0.8217 - val_masked_recall: 0.8107 - val_masked_f1: 0.8140\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0191 - masked_accuracy: 0.9670 - masked_precision: 0.9444 - masked_recall: 0.9445 - masked_f1: 0.9441 - val_loss: 0.0714 - val_masked_accuracy: 0.8827 - val_masked_precision: 0.8276 - val_masked_recall: 0.7805 - val_masked_f1: 0.8011\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0183 - masked_accuracy: 0.9683 - masked_precision: 0.9455 - masked_recall: 0.9514 - masked_f1: 0.9479 - val_loss: 0.0696 - val_masked_accuracy: 0.8903 - val_masked_precision: 0.8673 - val_masked_recall: 0.7583 - val_masked_f1: 0.8069\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0172 - masked_accuracy: 0.9684 - masked_precision: 0.9522 - masked_recall: 0.9429 - masked_f1: 0.9471 - val_loss: 0.0723 - val_masked_accuracy: 0.8827 - val_masked_precision: 0.8115 - val_masked_recall: 0.8076 - val_masked_f1: 0.8078\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0163 - masked_accuracy: 0.9724 - masked_precision: 0.9552 - masked_recall: 0.9556 - masked_f1: 0.9549 - val_loss: 0.0806 - val_masked_accuracy: 0.8862 - val_masked_precision: 0.8426 - val_masked_recall: 0.7779 - val_masked_f1: 0.8062\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.0147 - masked_accuracy: 0.9736 - masked_precision: 0.9587 - masked_recall: 0.9555 - masked_f1: 0.9566 - val_loss: 0.0776 - val_masked_accuracy: 0.8798 - val_masked_precision: 0.8398 - val_masked_recall: 0.7504 - val_masked_f1: 0.7905\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 45s 808ms/step - loss: 0.0151 - masked_accuracy: 0.9734 - masked_precision: 0.9559 - masked_recall: 0.9568 - masked_f1: 0.9559 - val_loss: 0.0788 - val_masked_accuracy: 0.8905 - val_masked_precision: 0.8692 - val_masked_recall: 0.7561 - val_masked_f1: 0.8066\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0141 - masked_accuracy: 0.9751 - masked_precision: 0.9617 - masked_recall: 0.9567 - masked_f1: 0.9588 - val_loss: 0.0774 - val_masked_accuracy: 0.8872 - val_masked_precision: 0.8349 - val_masked_recall: 0.7887 - val_masked_f1: 0.8088\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.0144 - masked_accuracy: 0.9742 - masked_precision: 0.9580 - masked_recall: 0.9576 - masked_f1: 0.9574 - val_loss: 0.0795 - val_masked_accuracy: 0.8779 - val_masked_precision: 0.8488 - val_masked_recall: 0.7349 - val_masked_f1: 0.7841\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0127 - masked_accuracy: 0.9787 - masked_precision: 0.9623 - masked_recall: 0.9667 - masked_f1: 0.9642 - val_loss: 0.0845 - val_masked_accuracy: 0.8866 - val_masked_precision: 0.8666 - val_masked_recall: 0.7474 - val_masked_f1: 0.7997\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0124 - masked_accuracy: 0.9777 - masked_precision: 0.9670 - masked_recall: 0.9599 - masked_f1: 0.9630 - val_loss: 0.0810 - val_masked_accuracy: 0.8860 - val_masked_precision: 0.8463 - val_masked_recall: 0.7654 - val_masked_f1: 0.8023\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0131 - masked_accuracy: 0.9771 - masked_precision: 0.9634 - masked_recall: 0.9611 - masked_f1: 0.9618 - val_loss: 0.0870 - val_masked_accuracy: 0.8799 - val_masked_precision: 0.8492 - val_masked_recall: 0.7433 - val_masked_f1: 0.7894\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.0915 - masked_accuracy: 0.8751 - masked_precision: 0.8209 - masked_recall: 0.7545 - masked_f1: 0.7849\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1359 - masked_accuracy: 0.6598 - masked_precision: 0.4491 - masked_recall: 0.4365 - masked_f1: 0.4344 - val_loss: 0.1243 - val_masked_accuracy: 0.7469 - val_masked_precision: 0.7031 - val_masked_recall: 0.4446 - val_masked_f1: 0.5431\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.1030 - masked_accuracy: 0.7540 - masked_precision: 0.6120 - masked_recall: 0.4790 - masked_f1: 0.5313 - val_loss: 0.0959 - val_masked_accuracy: 0.8017 - val_masked_precision: 0.7677 - val_masked_recall: 0.6007 - val_masked_f1: 0.6730\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0837 - masked_accuracy: 0.8122 - masked_precision: 0.7215 - masked_recall: 0.6173 - masked_f1: 0.6622 - val_loss: 0.0874 - val_masked_accuracy: 0.8285 - val_masked_precision: 0.7363 - val_masked_recall: 0.7729 - val_masked_f1: 0.7534\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0713 - masked_accuracy: 0.8469 - masked_precision: 0.7678 - masked_recall: 0.7124 - masked_f1: 0.7350 - val_loss: 0.0749 - val_masked_accuracy: 0.8566 - val_masked_precision: 0.8256 - val_masked_recall: 0.7325 - val_masked_f1: 0.7754\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0628 - masked_accuracy: 0.8712 - masked_precision: 0.7960 - masked_recall: 0.7632 - masked_f1: 0.7758 - val_loss: 0.0693 - val_masked_accuracy: 0.8658 - val_masked_precision: 0.8526 - val_masked_recall: 0.7318 - val_masked_f1: 0.7869\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0546 - masked_accuracy: 0.8891 - masked_precision: 0.8312 - masked_recall: 0.7886 - masked_f1: 0.8067 - val_loss: 0.0694 - val_masked_accuracy: 0.8631 - val_masked_precision: 0.7880 - val_masked_recall: 0.8170 - val_masked_f1: 0.8014\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0483 - masked_accuracy: 0.9054 - masked_precision: 0.8528 - masked_recall: 0.8258 - masked_f1: 0.8376 - val_loss: 0.0688 - val_masked_accuracy: 0.8700 - val_masked_precision: 0.8400 - val_masked_recall: 0.7635 - val_masked_f1: 0.7990\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0435 - masked_accuracy: 0.9170 - masked_precision: 0.8791 - masked_recall: 0.8380 - masked_f1: 0.8563 - val_loss: 0.0670 - val_masked_accuracy: 0.8763 - val_masked_precision: 0.8231 - val_masked_recall: 0.8098 - val_masked_f1: 0.8151\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0398 - masked_accuracy: 0.9202 - masked_precision: 0.8786 - masked_recall: 0.8495 - masked_f1: 0.8618 - val_loss: 0.0680 - val_masked_accuracy: 0.8757 - val_masked_precision: 0.8140 - val_masked_recall: 0.8207 - val_masked_f1: 0.8166\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0341 - masked_accuracy: 0.9347 - masked_precision: 0.9016 - masked_recall: 0.8764 - masked_f1: 0.8881 - val_loss: 0.0655 - val_masked_accuracy: 0.8848 - val_masked_precision: 0.8363 - val_masked_recall: 0.8218 - val_masked_f1: 0.8276\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0309 - masked_accuracy: 0.9402 - masked_precision: 0.9044 - masked_recall: 0.8921 - masked_f1: 0.8974 - val_loss: 0.0696 - val_masked_accuracy: 0.8874 - val_masked_precision: 0.8427 - val_masked_recall: 0.8184 - val_masked_f1: 0.8293\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0298 - masked_accuracy: 0.9438 - masked_precision: 0.9133 - masked_recall: 0.8995 - masked_f1: 0.9055 - val_loss: 0.0701 - val_masked_accuracy: 0.8855 - val_masked_precision: 0.8231 - val_masked_recall: 0.8442 - val_masked_f1: 0.8323\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0255 - masked_accuracy: 0.9521 - masked_precision: 0.9224 - masked_recall: 0.9154 - masked_f1: 0.9180 - val_loss: 0.0737 - val_masked_accuracy: 0.8813 - val_masked_precision: 0.8149 - val_masked_recall: 0.8416 - val_masked_f1: 0.8263\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0242 - masked_accuracy: 0.9546 - masked_precision: 0.9307 - masked_recall: 0.9184 - masked_f1: 0.9239 - val_loss: 0.0724 - val_masked_accuracy: 0.8880 - val_masked_precision: 0.8496 - val_masked_recall: 0.8142 - val_masked_f1: 0.8305\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0213 - masked_accuracy: 0.9609 - masked_precision: 0.9456 - masked_recall: 0.9232 - masked_f1: 0.9338 - val_loss: 0.0760 - val_masked_accuracy: 0.8841 - val_masked_precision: 0.8188 - val_masked_recall: 0.8453 - val_masked_f1: 0.8307\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0218 - masked_accuracy: 0.9591 - masked_precision: 0.9388 - masked_recall: 0.9260 - masked_f1: 0.9315 - val_loss: 0.0720 - val_masked_accuracy: 0.8912 - val_masked_precision: 0.8380 - val_masked_recall: 0.8447 - val_masked_f1: 0.8405\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0200 - masked_accuracy: 0.9645 - masked_precision: 0.9432 - masked_recall: 0.9373 - masked_f1: 0.9396 - val_loss: 0.0755 - val_masked_accuracy: 0.8863 - val_masked_precision: 0.8489 - val_masked_recall: 0.8116 - val_masked_f1: 0.8286\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0197 - masked_accuracy: 0.9636 - masked_precision: 0.9444 - masked_recall: 0.9330 - masked_f1: 0.9378 - val_loss: 0.0743 - val_masked_accuracy: 0.8875 - val_masked_precision: 0.8367 - val_masked_recall: 0.8333 - val_masked_f1: 0.8335\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0175 - masked_accuracy: 0.9688 - masked_precision: 0.9543 - masked_recall: 0.9422 - masked_f1: 0.9478 - val_loss: 0.0794 - val_masked_accuracy: 0.8867 - val_masked_precision: 0.8473 - val_masked_recall: 0.8136 - val_masked_f1: 0.8289\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0161 - masked_accuracy: 0.9710 - masked_precision: 0.9563 - masked_recall: 0.9474 - masked_f1: 0.9513 - val_loss: 0.0816 - val_masked_accuracy: 0.8869 - val_masked_precision: 0.8496 - val_masked_recall: 0.8117 - val_masked_f1: 0.8293\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0168 - masked_accuracy: 0.9708 - masked_precision: 0.9507 - masked_recall: 0.9511 - masked_f1: 0.9504 - val_loss: 0.0828 - val_masked_accuracy: 0.8925 - val_masked_precision: 0.8602 - val_masked_recall: 0.8171 - val_masked_f1: 0.8370\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0160 - masked_accuracy: 0.9709 - masked_precision: 0.9543 - masked_recall: 0.9482 - masked_f1: 0.9508 - val_loss: 0.0794 - val_masked_accuracy: 0.8873 - val_masked_precision: 0.8355 - val_masked_recall: 0.8342 - val_masked_f1: 0.8337\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.0150 - masked_accuracy: 0.9740 - masked_precision: 0.9610 - masked_recall: 0.9523 - masked_f1: 0.9563 - val_loss: 0.0837 - val_masked_accuracy: 0.8851 - val_masked_precision: 0.8424 - val_masked_recall: 0.8151 - val_masked_f1: 0.8274\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0137 - masked_accuracy: 0.9747 - masked_precision: 0.9577 - masked_recall: 0.9563 - masked_f1: 0.9566 - val_loss: 0.0866 - val_masked_accuracy: 0.8836 - val_masked_precision: 0.8295 - val_masked_recall: 0.8276 - val_masked_f1: 0.8274\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0132 - masked_accuracy: 0.9768 - masked_precision: 0.9643 - masked_recall: 0.9597 - masked_f1: 0.9616 - val_loss: 0.0846 - val_masked_accuracy: 0.8852 - val_masked_precision: 0.8184 - val_masked_recall: 0.8513 - val_masked_f1: 0.8333\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.0130 - masked_accuracy: 0.9771 - masked_precision: 0.9669 - masked_recall: 0.9564 - masked_f1: 0.9613 - val_loss: 0.0822 - val_masked_accuracy: 0.8924 - val_masked_precision: 0.8476 - val_masked_recall: 0.8304 - val_masked_f1: 0.8378\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 0.0842 - masked_accuracy: 0.8893 - masked_precision: 0.8410 - masked_recall: 0.7824 - masked_f1: 0.8093\n",
      "0.8811379194259643 0.006160355964288044 0.8260687470436097 0.020048897845508357 0.7758153676986694 0.02048866604410321 0.797355592250824 0.013219381838732868\n"
     ]
    }
   ],
   "source": [
    "accuracyresultlist=[]\n",
    "precisionresultlist=[]\n",
    "recallresultlist=[]\n",
    "flist=[]\n",
    "for train_index, test_index in kfold.split(X, Y):\n",
    "    # split data into train/test sets\n",
    "    x_train_tfidf = X.iloc[train_index]\n",
    "    y_train_tfidf = Y.iloc[train_index]\n",
    "    x_test_tfidf = X.iloc[test_index]\n",
    "    y_test_tfidf = Y.iloc[test_index]\n",
    "    trainX, validateX, trainyp, validatey = train_test_split(x_train_tfidf, y_train_tfidf, test_size=0.2, random_state=1989)\n",
    "    trainyp=trainyp.reset_index(drop=True)\n",
    "    trainX=trainX.reset_index(drop=True)\n",
    "    validatey=validatey.reset_index(drop=True)\n",
    "    validateX=validateX.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    trainy=trainyp.fillna(-1)\n",
    "    validatey=validatey.fillna(-1)\n",
    "    Testy=pd.DataFrame(y_test_tfidf).fillna(-1)\n",
    "\n",
    "    trainy=trainy.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    validatey=validatey.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    Testy=Testy.replace(['Not defined','Susceptible-dose dependent',0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    #print(trainy)\n",
    "    train_labels = np.array(trainy).astype(np.float32)\n",
    "    val_labels = np.array(validatey).astype(np.float32)\n",
    "    test_labels = np.array(Testy).astype(np.float32)\n",
    "    train_features = np.array(trainX).astype(np.float32)\n",
    "    val_features = np.array(validateX).astype(np.float32)\n",
    "    test_features = np.array(x_test_tfidf).astype(np.float32)\n",
    "    \n",
    "    input_dimension = 1 \n",
    "    train_sample_size = trainX.shape[0] # number of samples in train set\n",
    "    test_sample_size = x_test_tfidf.shape[0] # number of samples in train set\n",
    "    valid_sample_size = validateX.shape[0] # number of samples in train set\n",
    "    time_steps  = x_test_tfidf.shape[1] # number of features in train set\n",
    "\n",
    "    test_data_reshaped = test_features.reshape(test_sample_size,time_steps,input_dimension)\n",
    "    train_data_reshaped = train_features.reshape(train_sample_size,time_steps,input_dimension)\n",
    "    val_data_reshaped = val_features.reshape(valid_sample_size,time_steps,input_dimension)\n",
    "\n",
    "    #weight2=weight[:,1:3]\n",
    "    model = build_conv1D_model(train_data_reshaped)\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss= masked_loss_function,\n",
    "      metrics=METRICS)\n",
    "    #model.summary()\n",
    "    '''explaincallbacks = [\n",
    "    GradientsInputsCallback(\n",
    "        validation_data=(val_data_reshaped, val_labels),\n",
    "         class_index=0,\n",
    "        output_dir=output_dir,\n",
    "    ),\n",
    "]'''\n",
    "    baseline_history = model.fit(\n",
    "        train_data_reshaped,\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(val_data_reshaped, val_labels))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    results = model.evaluate(test_data_reshaped, test_labels, batch_size=BATCH_SIZE, verbose=1)\n",
    "    #print (results)\n",
    "    accuracyresultlist.append(results[1])\n",
    "    precisionresultlist.append(results[2])\n",
    "    recallresultlist.append(results[3])\n",
    "    flist.append(results[4])\n",
    "    #explainer = shap.DeepExplainer(model,train_data_reshaped)\n",
    "    #shap_values = explainer.shap_values(test_data_reshaped)\n",
    "    #print (shap_values)\n",
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811379194259643 0.006160355964288044 0.8260687470436097 0.020048897845508357 0.7758153676986694 0.02048866604410321 0.797355592250824 0.013219381838732868\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Loss','Accuracy'], 0,['loss','masked_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e02cb13512e3e24f59b668a1223e9284df78e57572e82b523044cd80d2e30e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
