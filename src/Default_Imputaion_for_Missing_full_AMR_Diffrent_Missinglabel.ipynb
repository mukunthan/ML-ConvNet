{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\Users\\mt01034\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt01034\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (6,18,29,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Finalplfam_id_Multilabel_Ecoli_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y=df[['ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole']]\n",
    "droppeddf=df.drop(columns=['genome_id', 'genome_name', 'taxon_id', 'ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole'])\n",
    "X=droppeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seeds so that we get the same initialization across different trials\n",
    "seed_numpy = 1989\n",
    "seed_tensorflow = 1989\n",
    "seed_value=1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(seed_numpy)\n",
    "tf.compat.v1.random.set_random_seed(seed_tensorflow)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2775, 16345)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2775, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "nan_mat = np.random.random(Y.shape)<0.3   ### Update to .6 to get more mising labels\n",
    "nan_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.mask(nan_mat)\n",
    "Ycnt=Y\n",
    "Ycnt=Ycnt.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['ampicillin',\n",
    "       'amoxicillin_clavulanic_acid', 'cefoxitin', 'ceftriaxone',\n",
    "       'chloramphenicol', 'ciprofloxacin', 'gentamicin', 'streptomycin',\n",
    "       'tetracycline', 'trimethoprim_sulphamethoxazole', 'meropenem',\n",
    "       'cefepime', 'ceftazidime', 'piperacillin_tazobactam', 'amikacin',\n",
    "       'ampicillin_sulbactam', 'cefotaxime', 'cefalothin', 'ertapenem',\n",
    "       'imipenem', 'levofloxacin', 'nitrofurantoin', 'tigecycline',\n",
    "       'cefazolin', 'aztreonam', 'cefuroxime', 'tobramycin',\n",
    "       'trimethoprim', 'amoxicillin', 'colistin', 'norfloxacin',\n",
    "       'sulfamethoxazole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ampicillin  amoxicillin_clavulanic_acid  cefoxitin  ceftriaxone  \\\n",
      "-1.0        1398                         1251       2346         2425   \n",
      "1.0          983                          507        139          177   \n",
      "0.0          391                          977        268          171   \n",
      "0.5            3                           40         22            2   \n",
      "\n",
      "      chloramphenicol  ciprofloxacin  gentamicin  streptomycin  tetracycline  \\\n",
      "-1.0             2545           1423        1395          2610          2459   \n",
      "1.0                83            453         221            91           199   \n",
      "0.0               143            879        1127            62           112   \n",
      "0.5                 4             20          32            12             1   \n",
      "\n",
      "      trimethoprim_sulphamethoxazole  ...  tigecycline  cefazolin  aztreonam  \\\n",
      "-1.0                            2506  ...         1956       2574       2428   \n",
      "1.0                              166  ...            2        136         71   \n",
      "0.0                               96  ...          805         48        264   \n",
      "0.5                                7  ...            2         17         12   \n",
      "\n",
      "      cefuroxime  tobramycin  trimethoprim  amoxicillin  colistin  \\\n",
      "-1.0      1767.0        2142          2242         2124      2629   \n",
      "1.0        268.0         163           257          372        20   \n",
      "0.0        740.0         447           273          268        66   \n",
      "0.5          NaN          23             3           11         9   \n",
      "\n",
      "      norfloxacin  sulfamethoxazole  \n",
      "-1.0         2659            2665.0  \n",
      "1.0            28              77.0  \n",
      "0.0            86              33.0  \n",
      "0.5             2               NaN  \n",
      "\n",
      "[4 rows x 32 columns]\n",
      "0.7815765765765765\n"
     ]
    }
   ],
   "source": [
    "###Data distribution check\n",
    "nancnt=0\n",
    "for index, label in enumerate(labels):\n",
    "    V= Ycnt[label].value_counts()\n",
    "    if(index==0):\n",
    "        df_val_counts = pd.DataFrame(V)\n",
    "    else:\n",
    "        df_val_counts_t = pd.DataFrame(V)\n",
    "        df_val_counts = df_val_counts.join(df_val_counts_t)\n",
    "    \n",
    "    nancnt=nancnt+V[-1.0]\n",
    "        \n",
    "print (df_val_counts)\n",
    "#df_val_counts.to_csv('../output/Input_Label_0.7_Supplementry_1.csv')\n",
    "print(nancnt/(Y.shape[1]*Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(train_features, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(1000, activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(256, activation='relu'), #LeakyReLU\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(64, activation='relu'), #LeakyReLU\n",
    "      tf.keras.layers.Dropout(0.3),\n",
    "      tf.keras.layers.Dense(32, activation='sigmoid',bias_initializer=output_bias),# activation='softmax' don;t use softmax\n",
    "  ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, Dropout, MaxPooling1D, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1D_model(train_data_reshaped):\n",
    "    n_timesteps = train_data_reshaped.shape[1] #13\n",
    "    n_features  = train_data_reshaped.shape[2] #1 \n",
    "    model = Sequential(name=\"model_conv1D\")\n",
    "    model.add(Input(shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=7, activation='relu', name=\"Conv1D_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', name=\"Conv1D_2\"))\n",
    "    model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_2\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu', name=\"Dense_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='relu', name=\"Dense_1_1\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu',name=\"Dense_2\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='sigmoid',name=\"Dense_3\"))\n",
    "   # model.add(Dense(n_labels, name=\"Dense_2\"))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metric(history, labels, n,metrics):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "  for metric in metrics:\n",
    "        plt.semilogy(history.epoch, history.history[metric],\n",
    "                color=colors[n], label='Train '+labels[n])\n",
    "        plt.semilogy(history.epoch, history.history['val_'+metric],\n",
    "                color=colors[n], label='Val '+labels[n],\n",
    "                linestyle=\"--\")\n",
    "        n=n+1\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Metrics')\n",
    "\n",
    "  plt.legend()\n",
    "  plt.savefig('../output/'+'Plot_Default_'.join(labels)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_f1(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred*mask, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true*mask, 0, 1)))\n",
    "\n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred *mask, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred*mask, 0, 1)))\n",
    "\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "\n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_value=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true, y_pred):\n",
    "    dtype = K.floatx()\n",
    "    total = K.sum(K.cast(K.not_equal(y_true, mask_value), dtype))\n",
    "    #total=K.cast(len(y_true),dtype)\n",
    "    correct = K.sum(K.cast(K.equal(y_true, K.round(y_pred)), dtype))\n",
    "    #print(correct,total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_precision(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred *mask, 0, 1)))\n",
    "    Pred_Positives = K.sum(K.round(K.clip(y_pred*mask, 0, 1)))\n",
    "\n",
    "    precision = TP / (Pred_Positives+K.epsilon())\n",
    "    return precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_recall(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "    TP = K.sum(K.round(K.clip(y_true * y_pred*mask, 0, 1)))\n",
    "    Positives = K.sum(K.round(K.clip(y_true*mask, 0, 1)))\n",
    "\n",
    "    recall = TP / (Positives+K.epsilon())    \n",
    "    return recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      masked_accuracy,\n",
    "      masked_precision,\n",
    "      masked_recall,\n",
    "      masked_f1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_masked_accuracy', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 [==============================] - 4s 48ms/step - loss: 0.5630 - masked_accuracy: 0.7710 - masked_precision: 0.0913 - masked_recall: 0.2327 - masked_f1: 0.1204 - val_loss: 0.2476 - val_masked_accuracy: 0.9229 - val_masked_precision: 0.0102 - val_masked_recall: 0.0011 - val_masked_f1: 0.0019\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2823 - masked_accuracy: 0.9076 - masked_precision: 0.1800 - masked_recall: 0.0860 - masked_f1: 0.1125 - val_loss: 0.2289 - val_masked_accuracy: 0.9233 - val_masked_precision: 0.0179 - val_masked_recall: 0.0011 - val_masked_f1: 0.0020\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2473 - masked_accuracy: 0.9218 - masked_precision: 0.2604 - masked_recall: 0.0686 - masked_f1: 0.1071 - val_loss: 0.2178 - val_masked_accuracy: 0.9235 - val_masked_precision: 0.0714 - val_masked_recall: 0.0011 - val_masked_f1: 0.0021\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2440 - masked_accuracy: 0.9251 - masked_precision: 0.2912 - masked_recall: 0.0533 - masked_f1: 0.0883 - val_loss: 0.2287 - val_masked_accuracy: 0.9235 - val_masked_precision: 0.0714 - val_masked_recall: 0.0021 - val_masked_f1: 0.0041\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2334 - masked_accuracy: 0.9264 - masked_precision: 0.2846 - masked_recall: 0.0405 - masked_f1: 0.0694 - val_loss: 0.2157 - val_masked_accuracy: 0.9235 - val_masked_precision: 0.0714 - val_masked_recall: 0.0021 - val_masked_f1: 0.0041\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2290 - masked_accuracy: 0.9271 - masked_precision: 0.2962 - masked_recall: 0.0374 - masked_f1: 0.0653 - val_loss: 0.2133 - val_masked_accuracy: 0.9234 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2187 - masked_accuracy: 0.9287 - masked_precision: 0.3540 - masked_recall: 0.0273 - masked_f1: 0.0497 - val_loss: 0.2138 - val_masked_accuracy: 0.9234 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2112 - masked_accuracy: 0.9295 - masked_precision: 0.4254 - masked_recall: 0.0324 - masked_f1: 0.0594 - val_loss: 0.2064 - val_masked_accuracy: 0.9234 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2053 - masked_accuracy: 0.9297 - masked_precision: 0.4582 - masked_recall: 0.0352 - masked_f1: 0.0648 - val_loss: 0.2121 - val_masked_accuracy: 0.9234 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.6034 - masked_accuracy: 0.7469 - masked_precision: 0.0910 - masked_recall: 0.2595 - masked_f1: 0.1265 - val_loss: 0.2502 - val_masked_accuracy: 0.9344 - val_masked_precision: 0.1488 - val_masked_recall: 0.0048 - val_masked_f1: 0.0092\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2898 - masked_accuracy: 0.9043 - masked_precision: 0.1678 - masked_recall: 0.0834 - masked_f1: 0.1080 - val_loss: 0.2075 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2507 - masked_accuracy: 0.9208 - masked_precision: 0.2567 - masked_recall: 0.0599 - masked_f1: 0.0949 - val_loss: 0.1903 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2426 - masked_accuracy: 0.9229 - masked_precision: 0.2405 - masked_recall: 0.0460 - masked_f1: 0.0756 - val_loss: 0.2012 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2304 - masked_accuracy: 0.9253 - masked_precision: 0.2892 - masked_recall: 0.0294 - masked_f1: 0.0524 - val_loss: 0.1866 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2265 - masked_accuracy: 0.9266 - masked_precision: 0.2958 - masked_recall: 0.0279 - masked_f1: 0.0504 - val_loss: 0.1907 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2244 - masked_accuracy: 0.9271 - masked_precision: 0.2256 - masked_recall: 0.0112 - masked_f1: 0.0209 - val_loss: 0.1894 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.5623 - masked_accuracy: 0.7865 - masked_precision: 0.0935 - masked_recall: 0.1928 - masked_f1: 0.1117 - val_loss: 0.2444 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2745 - masked_accuracy: 0.9100 - masked_precision: 0.1607 - masked_recall: 0.0729 - masked_f1: 0.0967 - val_loss: 0.2231 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2472 - masked_accuracy: 0.9221 - masked_precision: 0.2121 - masked_recall: 0.0491 - masked_f1: 0.0785 - val_loss: 0.2145 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2357 - masked_accuracy: 0.9263 - masked_precision: 0.2709 - masked_recall: 0.0427 - masked_f1: 0.0716 - val_loss: 0.2236 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2262 - masked_accuracy: 0.9279 - masked_precision: 0.2579 - masked_recall: 0.0288 - masked_f1: 0.0510 - val_loss: 0.2113 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2178 - masked_accuracy: 0.9294 - masked_precision: 0.2248 - masked_recall: 0.0174 - masked_f1: 0.0318 - val_loss: 0.2089 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5766 - masked_accuracy: 0.7744 - masked_precision: 0.0913 - masked_recall: 0.2166 - masked_f1: 0.1170 - val_loss: 0.2453 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2821 - masked_accuracy: 0.9056 - masked_precision: 0.1673 - masked_recall: 0.0891 - masked_f1: 0.1116 - val_loss: 0.2068 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2548 - masked_accuracy: 0.9198 - masked_precision: 0.2050 - masked_recall: 0.0587 - masked_f1: 0.0894 - val_loss: 0.2060 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2365 - masked_accuracy: 0.9247 - masked_precision: 0.2804 - masked_recall: 0.0546 - masked_f1: 0.0891 - val_loss: 0.1993 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2297 - masked_accuracy: 0.9268 - masked_precision: 0.2662 - masked_recall: 0.0329 - masked_f1: 0.0576 - val_loss: 0.1998 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2257 - masked_accuracy: 0.9286 - masked_precision: 0.2810 - masked_recall: 0.0237 - masked_f1: 0.0429 - val_loss: 0.2101 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2162 - masked_accuracy: 0.9295 - masked_precision: 0.2626 - masked_recall: 0.0168 - masked_f1: 0.0313 - val_loss: 0.2092 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.6157 - masked_accuracy: 0.7379 - masked_precision: 0.1021 - masked_recall: 0.3003 - masked_f1: 0.1409 - val_loss: 0.2527 - val_masked_accuracy: 0.9293 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2810 - masked_accuracy: 0.9052 - masked_precision: 0.1621 - masked_recall: 0.0768 - masked_f1: 0.0995 - val_loss: 0.2063 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2480 - masked_accuracy: 0.9205 - masked_precision: 0.2186 - masked_recall: 0.0515 - masked_f1: 0.0820 - val_loss: 0.2116 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2357 - masked_accuracy: 0.9237 - masked_precision: 0.2360 - masked_recall: 0.0399 - masked_f1: 0.0672 - val_loss: 0.1995 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2371 - masked_accuracy: 0.9244 - masked_precision: 0.2271 - masked_recall: 0.0308 - masked_f1: 0.0532 - val_loss: 0.2107 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2278 - masked_accuracy: 0.9268 - masked_precision: 0.2701 - masked_recall: 0.0206 - masked_f1: 0.0379 - val_loss: 0.2142 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2216 - masked_accuracy: 0.9278 - masked_precision: 0.2426 - masked_recall: 0.0130 - masked_f1: 0.0243 - val_loss: 0.2008 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5422 - masked_accuracy: 0.7836 - masked_precision: 0.0656 - masked_recall: 0.1455 - masked_f1: 0.0829 - val_loss: 0.2546 - val_masked_accuracy: 0.9286 - val_masked_precision: 0.0238 - val_masked_recall: 0.0012 - val_masked_f1: 0.0022\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2768 - masked_accuracy: 0.9116 - masked_precision: 0.1769 - masked_recall: 0.0684 - masked_f1: 0.0959 - val_loss: 0.2154 - val_masked_accuracy: 0.9297 - val_masked_precision: 0.7143 - val_masked_recall: 0.0281 - val_masked_f1: 0.0533\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2479 - masked_accuracy: 0.9228 - masked_precision: 0.2534 - masked_recall: 0.0621 - masked_f1: 0.0976 - val_loss: 0.2055 - val_masked_accuracy: 0.9287 - val_masked_precision: 0.1429 - val_masked_recall: 0.0017 - val_masked_f1: 0.0033\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2384 - masked_accuracy: 0.9264 - masked_precision: 0.3352 - masked_recall: 0.0548 - masked_f1: 0.0925 - val_loss: 0.2024 - val_masked_accuracy: 0.9292 - val_masked_precision: 0.6036 - val_masked_recall: 0.0256 - val_masked_f1: 0.0487\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2250 - masked_accuracy: 0.9279 - masked_precision: 0.3913 - masked_recall: 0.0576 - masked_f1: 0.0982 - val_loss: 0.2028 - val_masked_accuracy: 0.9290 - val_masked_precision: 0.6131 - val_masked_recall: 0.0191 - val_masked_f1: 0.0368\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2200 - masked_accuracy: 0.9293 - masked_precision: 0.4278 - masked_recall: 0.0532 - masked_f1: 0.0932 - val_loss: 0.2087 - val_masked_accuracy: 0.9298 - val_masked_precision: 0.7310 - val_masked_recall: 0.0310 - val_masked_f1: 0.0593\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2134 - masked_accuracy: 0.9302 - masked_precision: 0.4643 - masked_recall: 0.0478 - masked_f1: 0.0856 - val_loss: 0.2110 - val_masked_accuracy: 0.9294 - val_masked_precision: 0.5925 - val_masked_recall: 0.0413 - val_masked_f1: 0.0771\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2065 - masked_accuracy: 0.9310 - masked_precision: 0.5409 - masked_recall: 0.0481 - masked_f1: 0.0872 - val_loss: 0.2038 - val_masked_accuracy: 0.9301 - val_masked_precision: 0.6077 - val_masked_recall: 0.0666 - val_masked_f1: 0.1195\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2046 - masked_accuracy: 0.9305 - masked_precision: 0.4997 - masked_recall: 0.0531 - masked_f1: 0.0944 - val_loss: 0.2136 - val_masked_accuracy: 0.9310 - val_masked_precision: 0.6215 - val_masked_recall: 0.0900 - val_masked_f1: 0.1566\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2078 - masked_accuracy: 0.9309 - masked_precision: 0.5176 - masked_recall: 0.0540 - masked_f1: 0.0965 - val_loss: 0.2072 - val_masked_accuracy: 0.9305 - val_masked_precision: 0.6233 - val_masked_recall: 0.0781 - val_masked_f1: 0.1379\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2059 - masked_accuracy: 0.9304 - masked_precision: 0.4780 - masked_recall: 0.0452 - masked_f1: 0.0817 - val_loss: 0.2096 - val_masked_accuracy: 0.9287 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2012 - masked_accuracy: 0.9303 - masked_precision: 0.5037 - masked_recall: 0.0410 - masked_f1: 0.0748 - val_loss: 0.2005 - val_masked_accuracy: 0.9299 - val_masked_precision: 0.6418 - val_masked_recall: 0.0439 - val_masked_f1: 0.0816\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2024 - masked_accuracy: 0.9308 - masked_precision: 0.5294 - masked_recall: 0.0405 - masked_f1: 0.0742 - val_loss: 0.2022 - val_masked_accuracy: 0.9313 - val_masked_precision: 0.6164 - val_masked_recall: 0.1005 - val_masked_f1: 0.1721\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2011 - masked_accuracy: 0.9303 - masked_precision: 0.4734 - masked_recall: 0.0559 - masked_f1: 0.0987 - val_loss: 0.1988 - val_masked_accuracy: 0.9289 - val_masked_precision: 0.5238 - val_masked_recall: 0.0098 - val_masked_f1: 0.0192\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2016 - masked_accuracy: 0.9308 - masked_precision: 0.4917 - masked_recall: 0.0431 - masked_f1: 0.0783 - val_loss: 0.1973 - val_masked_accuracy: 0.9301 - val_masked_precision: 0.6237 - val_masked_recall: 0.0612 - val_masked_f1: 0.1108\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1982 - masked_accuracy: 0.9306 - masked_precision: 0.5032 - masked_recall: 0.0609 - masked_f1: 0.1074 - val_loss: 0.2044 - val_masked_accuracy: 0.9311 - val_masked_precision: 0.6068 - val_masked_recall: 0.0993 - val_masked_f1: 0.1701\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2000 - masked_accuracy: 0.9310 - masked_precision: 0.5330 - masked_recall: 0.0551 - masked_f1: 0.0983 - val_loss: 0.1999 - val_masked_accuracy: 0.9309 - val_masked_precision: 0.6610 - val_masked_recall: 0.0712 - val_masked_f1: 0.1279\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1971 - masked_accuracy: 0.9310 - masked_precision: 0.5365 - masked_recall: 0.0674 - masked_f1: 0.1185 - val_loss: 0.1959 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.6436 - val_masked_recall: 0.0663 - val_masked_f1: 0.1198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.5032 - masked_accuracy: 0.8255 - masked_precision: 0.1279 - masked_recall: 0.2233 - masked_f1: 0.1483 - val_loss: 0.2309 - val_masked_accuracy: 0.9305 - val_masked_precision: 0.0179 - val_masked_recall: 0.0011 - val_masked_f1: 0.0020\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2722 - masked_accuracy: 0.9109 - masked_precision: 0.2143 - masked_recall: 0.0995 - masked_f1: 0.1333 - val_loss: 0.2053 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0357 - val_masked_recall: 0.0011 - val_masked_f1: 0.0020\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2570 - masked_accuracy: 0.9188 - masked_precision: 0.2599 - masked_recall: 0.0800 - masked_f1: 0.1190 - val_loss: 0.2123 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.1071 - val_masked_recall: 0.0021 - val_masked_f1: 0.0041\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2441 - masked_accuracy: 0.9226 - masked_precision: 0.2689 - masked_recall: 0.0626 - masked_f1: 0.1003 - val_loss: 0.2005 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0714 - val_masked_recall: 0.0011 - val_masked_f1: 0.0021\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2342 - masked_accuracy: 0.9246 - masked_precision: 0.2845 - masked_recall: 0.0544 - masked_f1: 0.0895 - val_loss: 0.2010 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2289 - masked_accuracy: 0.9271 - masked_precision: 0.3261 - masked_recall: 0.0361 - masked_f1: 0.0639 - val_loss: 0.2158 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2109 - masked_accuracy: 0.9290 - masked_precision: 0.4283 - masked_recall: 0.0401 - masked_f1: 0.0725 - val_loss: 0.2041 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2103 - masked_accuracy: 0.9286 - masked_precision: 0.3808 - masked_recall: 0.0380 - masked_f1: 0.0685 - val_loss: 0.1976 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.6905 - val_masked_recall: 0.0193 - val_masked_f1: 0.0374\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2039 - masked_accuracy: 0.9294 - masked_precision: 0.4172 - masked_recall: 0.0376 - masked_f1: 0.0683 - val_loss: 0.1989 - val_masked_accuracy: 0.9311 - val_masked_precision: 0.5000 - val_masked_recall: 0.0084 - val_masked_f1: 0.0165\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2083 - masked_accuracy: 0.9290 - masked_precision: 0.4101 - masked_recall: 0.0408 - masked_f1: 0.0735 - val_loss: 0.1941 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.5701 - val_masked_recall: 0.0484 - val_masked_f1: 0.0890\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2076 - masked_accuracy: 0.9296 - masked_precision: 0.4860 - masked_recall: 0.0477 - masked_f1: 0.0853 - val_loss: 0.1922 - val_masked_accuracy: 0.9315 - val_masked_precision: 0.5952 - val_masked_recall: 0.0242 - val_masked_f1: 0.0463\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2031 - masked_accuracy: 0.9302 - masked_precision: 0.5218 - masked_recall: 0.0456 - masked_f1: 0.0830 - val_loss: 0.2028 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.5656 - val_masked_recall: 0.0670 - val_masked_f1: 0.1196\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2022 - masked_accuracy: 0.9301 - masked_precision: 0.5267 - masked_recall: 0.0516 - masked_f1: 0.0931 - val_loss: 0.1927 - val_masked_accuracy: 0.9317 - val_masked_precision: 0.5923 - val_masked_recall: 0.0373 - val_masked_f1: 0.0695\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1989 - masked_accuracy: 0.9303 - masked_precision: 0.5241 - masked_recall: 0.0556 - masked_f1: 0.0989 - val_loss: 0.1938 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.6111 - val_masked_recall: 0.0480 - val_masked_f1: 0.0886\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1992 - masked_accuracy: 0.9308 - masked_precision: 0.5393 - masked_recall: 0.0640 - masked_f1: 0.1130 - val_loss: 0.1973 - val_masked_accuracy: 0.9325 - val_masked_precision: 0.6024 - val_masked_recall: 0.0620 - val_masked_f1: 0.1122\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2046 - masked_accuracy: 0.9295 - masked_precision: 0.4728 - masked_recall: 0.0575 - masked_f1: 0.1008 - val_loss: 0.1929 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2036 - masked_accuracy: 0.9302 - masked_precision: 0.4910 - masked_recall: 0.0520 - masked_f1: 0.0928 - val_loss: 0.1937 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2006 - masked_accuracy: 0.9298 - masked_precision: 0.5065 - masked_recall: 0.0483 - masked_f1: 0.0870 - val_loss: 0.1912 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.6009 - val_masked_recall: 0.0471 - val_masked_f1: 0.0870\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.1964 - masked_accuracy: 0.9298 - masked_precision: 0.4818 - masked_recall: 0.0501 - masked_f1: 0.0896 - val_loss: 0.1914 - val_masked_accuracy: 0.9327 - val_masked_precision: 0.6238 - val_masked_recall: 0.0636 - val_masked_f1: 0.1151\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1978 - masked_accuracy: 0.9305 - masked_precision: 0.5284 - masked_recall: 0.0612 - masked_f1: 0.1088 - val_loss: 0.1905 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.5646 - val_masked_recall: 0.0534 - val_masked_f1: 0.0972\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.2001 - masked_accuracy: 0.9304 - masked_precision: 0.5148 - masked_recall: 0.0632 - masked_f1: 0.1117 - val_loss: 0.1940 - val_masked_accuracy: 0.9323 - val_masked_precision: 0.5954 - val_masked_recall: 0.0686 - val_masked_f1: 0.1225\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1947 - masked_accuracy: 0.9305 - masked_precision: 0.5377 - masked_recall: 0.0637 - masked_f1: 0.1126 - val_loss: 0.1918 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.5691 - val_masked_recall: 0.0705 - val_masked_f1: 0.1252\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1963 - masked_accuracy: 0.9307 - masked_precision: 0.5263 - masked_recall: 0.0705 - masked_f1: 0.1235 - val_loss: 0.1905 - val_masked_accuracy: 0.9321 - val_masked_precision: 0.6429 - val_masked_recall: 0.0485 - val_masked_f1: 0.0893\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.1933 - masked_accuracy: 0.9304 - masked_precision: 0.5131 - masked_recall: 0.0672 - masked_f1: 0.1178 - val_loss: 0.1908 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.6117 - val_masked_recall: 0.0535 - val_masked_f1: 0.0978\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5214 - masked_accuracy: 0.8126 - masked_precision: 0.1013 - masked_recall: 0.1897 - masked_f1: 0.1205 - val_loss: 0.2311 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2777 - masked_accuracy: 0.9087 - masked_precision: 0.1801 - masked_recall: 0.0812 - masked_f1: 0.1091 - val_loss: 0.2170 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2506 - masked_accuracy: 0.9214 - masked_precision: 0.2192 - masked_recall: 0.0483 - masked_f1: 0.0779 - val_loss: 0.2024 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2386 - masked_accuracy: 0.9252 - masked_precision: 0.2943 - masked_recall: 0.0531 - masked_f1: 0.0883 - val_loss: 0.2331 - val_masked_accuracy: 0.9263 - val_masked_precision: 0.0357 - val_masked_recall: 0.0014 - val_masked_f1: 0.0026\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.2371 - masked_accuracy: 0.9249 - masked_precision: 0.2428 - masked_recall: 0.0363 - masked_f1: 0.0619 - val_loss: 0.2102 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2213 - masked_accuracy: 0.9270 - masked_precision: 0.2721 - masked_recall: 0.0302 - masked_f1: 0.0536 - val_loss: 0.2177 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5913 - masked_accuracy: 0.7563 - masked_precision: 0.1016 - masked_recall: 0.2681 - masked_f1: 0.1327 - val_loss: 0.2514 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.1607 - val_masked_recall: 0.0040 - val_masked_f1: 0.0078\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2871 - masked_accuracy: 0.9090 - masked_precision: 0.2059 - masked_recall: 0.0948 - masked_f1: 0.1233 - val_loss: 0.2094 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.1429 - val_masked_recall: 0.0020 - val_masked_f1: 0.0039\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2494 - masked_accuracy: 0.9224 - masked_precision: 0.2816 - masked_recall: 0.0735 - masked_f1: 0.1141 - val_loss: 0.2066 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2358 - masked_accuracy: 0.9252 - masked_precision: 0.3128 - masked_recall: 0.0613 - masked_f1: 0.1010 - val_loss: 0.2153 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2293 - masked_accuracy: 0.9268 - masked_precision: 0.2777 - masked_recall: 0.0369 - masked_f1: 0.0636 - val_loss: 0.1990 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2150 - masked_accuracy: 0.9276 - masked_precision: 0.3167 - masked_recall: 0.0298 - masked_f1: 0.0535 - val_loss: 0.2084 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.2112 - masked_accuracy: 0.9287 - masked_precision: 0.3152 - masked_recall: 0.0211 - masked_f1: 0.0392 - val_loss: 0.2035 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 49ms/step - loss: 0.5404 - masked_accuracy: 0.7912 - masked_precision: 0.1132 - masked_recall: 0.2416 - masked_f1: 0.1420 - val_loss: 0.2555 - val_masked_accuracy: 0.9340 - val_masked_precision: 0.3089 - val_masked_recall: 0.0181 - val_masked_f1: 0.0338\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2899 - masked_accuracy: 0.9035 - masked_precision: 0.1955 - masked_recall: 0.0977 - masked_f1: 0.1252 - val_loss: 0.2039 - val_masked_accuracy: 0.9354 - val_masked_precision: 0.0357 - val_masked_recall: 0.0012 - val_masked_f1: 0.0024\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2585 - masked_accuracy: 0.9174 - masked_precision: 0.2546 - masked_recall: 0.0673 - masked_f1: 0.1045 - val_loss: 0.1954 - val_masked_accuracy: 0.9361 - val_masked_precision: 0.4762 - val_masked_recall: 0.0122 - val_masked_f1: 0.0237\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2444 - masked_accuracy: 0.9203 - masked_precision: 0.3108 - masked_recall: 0.0675 - masked_f1: 0.1081 - val_loss: 0.2082 - val_masked_accuracy: 0.9362 - val_masked_precision: 0.5914 - val_masked_recall: 0.0346 - val_masked_f1: 0.0648\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2386 - masked_accuracy: 0.9236 - masked_precision: 0.3661 - masked_recall: 0.0558 - masked_f1: 0.0948 - val_loss: 0.2012 - val_masked_accuracy: 0.9367 - val_masked_precision: 0.6726 - val_masked_recall: 0.0229 - val_masked_f1: 0.0439\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2290 - masked_accuracy: 0.9248 - masked_precision: 0.3721 - masked_recall: 0.0448 - masked_f1: 0.0789 - val_loss: 0.2246 - val_masked_accuracy: 0.9368 - val_masked_precision: 0.5481 - val_masked_recall: 0.0633 - val_masked_f1: 0.1130\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2277 - masked_accuracy: 0.9256 - masked_precision: 0.4073 - masked_recall: 0.0421 - masked_f1: 0.0751 - val_loss: 0.1924 - val_masked_accuracy: 0.9368 - val_masked_precision: 0.7548 - val_masked_recall: 0.0319 - val_masked_f1: 0.0608\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2202 - masked_accuracy: 0.9269 - masked_precision: 0.4631 - masked_recall: 0.0413 - masked_f1: 0.0750 - val_loss: 0.1843 - val_masked_accuracy: 0.9356 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2187 - masked_accuracy: 0.9266 - masked_precision: 0.4593 - masked_recall: 0.0367 - masked_f1: 0.0671 - val_loss: 0.1870 - val_masked_accuracy: 0.9365 - val_masked_precision: 0.6131 - val_masked_recall: 0.0272 - val_masked_f1: 0.0516\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2160 - masked_accuracy: 0.9263 - masked_precision: 0.4657 - masked_recall: 0.0472 - masked_f1: 0.0846 - val_loss: 0.2046 - val_masked_accuracy: 0.9367 - val_masked_precision: 0.5361 - val_masked_recall: 0.0793 - val_masked_f1: 0.1380\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2128 - masked_accuracy: 0.9274 - masked_precision: 0.5344 - masked_recall: 0.0397 - masked_f1: 0.0729 - val_loss: 0.1833 - val_masked_accuracy: 0.9362 - val_masked_precision: 0.6250 - val_masked_recall: 0.0143 - val_masked_f1: 0.0279\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5259 - masked_accuracy: 0.7970 - masked_precision: 0.1176 - masked_recall: 0.2484 - masked_f1: 0.1450 - val_loss: 0.2293 - val_masked_accuracy: 0.9240 - val_masked_precision: 0.0179 - val_masked_recall: 0.0013 - val_masked_f1: 0.0023\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2775 - masked_accuracy: 0.9087 - masked_precision: 0.1715 - masked_recall: 0.0838 - masked_f1: 0.1095 - val_loss: 0.2168 - val_masked_accuracy: 0.9243 - val_masked_precision: 0.1429 - val_masked_recall: 0.0021 - val_masked_f1: 0.0041\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 3s 46ms/step - loss: 0.2484 - masked_accuracy: 0.9221 - masked_precision: 0.2807 - masked_recall: 0.0686 - masked_f1: 0.1081 - val_loss: 0.2102 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.7032 - val_masked_recall: 0.0573 - val_masked_f1: 0.1053\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2391 - masked_accuracy: 0.9247 - masked_precision: 0.2864 - masked_recall: 0.0515 - masked_f1: 0.0858 - val_loss: 0.2184 - val_masked_accuracy: 0.9242 - val_masked_precision: 0.0714 - val_masked_recall: 0.0013 - val_masked_f1: 0.0025\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2289 - masked_accuracy: 0.9261 - masked_precision: 0.2910 - masked_recall: 0.0462 - masked_f1: 0.0784 - val_loss: 0.2262 - val_masked_accuracy: 0.9247 - val_masked_precision: 0.4643 - val_masked_recall: 0.0097 - val_masked_f1: 0.0189\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2182 - masked_accuracy: 0.9283 - masked_precision: 0.3562 - masked_recall: 0.0420 - masked_f1: 0.0743 - val_loss: 0.2120 - val_masked_accuracy: 0.9248 - val_masked_precision: 0.5000 - val_masked_recall: 0.0111 - val_masked_f1: 0.0217\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2140 - masked_accuracy: 0.9289 - masked_precision: 0.3766 - masked_recall: 0.0350 - masked_f1: 0.0629 - val_loss: 0.2171 - val_masked_accuracy: 0.9250 - val_masked_precision: 0.6429 - val_masked_recall: 0.0159 - val_masked_f1: 0.0310\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.2090 - masked_accuracy: 0.9293 - masked_precision: 0.3650 - masked_recall: 0.0243 - masked_f1: 0.0450 - val_loss: 0.2113 - val_masked_accuracy: 0.9255 - val_masked_precision: 0.6476 - val_masked_recall: 0.0236 - val_masked_f1: 0.0453\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.5073 - masked_accuracy: 0.8172 - masked_precision: 0.1083 - masked_recall: 0.1892 - masked_f1: 0.1210 - val_loss: 0.2347 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.3869 - val_masked_recall: 0.0098 - val_masked_f1: 0.0190\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2713 - masked_accuracy: 0.9125 - masked_precision: 0.1918 - masked_recall: 0.0781 - masked_f1: 0.1080 - val_loss: 0.2247 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2490 - masked_accuracy: 0.9217 - masked_precision: 0.2591 - masked_recall: 0.0721 - masked_f1: 0.1103 - val_loss: 0.2002 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.2143 - val_masked_recall: 0.0024 - val_masked_f1: 0.0048\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2396 - masked_accuracy: 0.9235 - masked_precision: 0.2743 - masked_recall: 0.0620 - masked_f1: 0.0988 - val_loss: 0.2060 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0952 - val_masked_recall: 0.0017 - val_masked_f1: 0.0034\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2282 - masked_accuracy: 0.9264 - masked_precision: 0.3167 - masked_recall: 0.0559 - masked_f1: 0.0935 - val_loss: 0.2080 - val_masked_accuracy: 0.9320 - val_masked_precision: 0.5595 - val_masked_recall: 0.0154 - val_masked_f1: 0.0299\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2219 - masked_accuracy: 0.9265 - masked_precision: 0.2941 - masked_recall: 0.0445 - masked_f1: 0.0760 - val_loss: 0.2073 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2154 - masked_accuracy: 0.9282 - masked_precision: 0.3090 - masked_recall: 0.0246 - masked_f1: 0.0450 - val_loss: 0.2010 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2078 - masked_accuracy: 0.9289 - masked_precision: 0.3168 - masked_recall: 0.0208 - masked_f1: 0.0386 - val_loss: 0.2035 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2016 - masked_accuracy: 0.9295 - masked_precision: 0.3332 - masked_recall: 0.0239 - masked_f1: 0.0438 - val_loss: 0.1964 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2020 - masked_accuracy: 0.9298 - masked_precision: 0.3292 - masked_recall: 0.0153 - masked_f1: 0.0290 - val_loss: 0.2000 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5370 - masked_accuracy: 0.7988 - masked_precision: 0.1055 - masked_recall: 0.2201 - masked_f1: 0.1311 - val_loss: 0.2212 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2841 - masked_accuracy: 0.9060 - masked_precision: 0.1873 - masked_recall: 0.0936 - masked_f1: 0.1209 - val_loss: 0.2054 - val_masked_accuracy: 0.9324 - val_masked_precision: 0.6429 - val_masked_recall: 0.0175 - val_masked_f1: 0.0339\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2499 - masked_accuracy: 0.9192 - masked_precision: 0.2374 - masked_recall: 0.0641 - masked_f1: 0.0993 - val_loss: 0.1940 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2380 - masked_accuracy: 0.9236 - masked_precision: 0.2748 - masked_recall: 0.0543 - masked_f1: 0.0895 - val_loss: 0.1917 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2327 - masked_accuracy: 0.9248 - masked_precision: 0.3011 - masked_recall: 0.0501 - masked_f1: 0.0846 - val_loss: 0.1922 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2240 - masked_accuracy: 0.9266 - masked_precision: 0.3569 - masked_recall: 0.0501 - masked_f1: 0.0869 - val_loss: 0.2106 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2245 - masked_accuracy: 0.9274 - masked_precision: 0.3800 - masked_recall: 0.0378 - masked_f1: 0.0675 - val_loss: 0.2202 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 47ms/step - loss: 0.5444 - masked_accuracy: 0.8012 - masked_precision: 0.1040 - masked_recall: 0.2057 - masked_f1: 0.1247 - val_loss: 0.2378 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2783 - masked_accuracy: 0.9112 - masked_precision: 0.1685 - masked_recall: 0.0665 - masked_f1: 0.0924 - val_loss: 0.2071 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 43ms/step - loss: 0.2488 - masked_accuracy: 0.9212 - masked_precision: 0.2518 - masked_recall: 0.0620 - masked_f1: 0.0977 - val_loss: 0.1981 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2438 - masked_accuracy: 0.9224 - masked_precision: 0.2062 - masked_recall: 0.0413 - masked_f1: 0.0667 - val_loss: 0.2117 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2362 - masked_accuracy: 0.9266 - masked_precision: 0.2675 - masked_recall: 0.0252 - masked_f1: 0.0450 - val_loss: 0.2097 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2156 - masked_accuracy: 0.9276 - masked_precision: 0.3078 - masked_recall: 0.0289 - masked_f1: 0.0521 - val_loss: 0.2050 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 3s 48ms/step - loss: 0.5343 - masked_accuracy: 0.7927 - masked_precision: 0.1045 - masked_recall: 0.2126 - masked_f1: 0.1266 - val_loss: 0.2484 - val_masked_accuracy: 0.9233 - val_masked_precision: 0.4896 - val_masked_recall: 0.0542 - val_masked_f1: 0.0970\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2760 - masked_accuracy: 0.9106 - masked_precision: 0.1744 - masked_recall: 0.0769 - masked_f1: 0.1036 - val_loss: 0.2284 - val_masked_accuracy: 0.9235 - val_masked_precision: 0.5179 - val_masked_recall: 0.0108 - val_masked_f1: 0.0211\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2475 - masked_accuracy: 0.9223 - masked_precision: 0.2579 - masked_recall: 0.0604 - masked_f1: 0.0953 - val_loss: 0.2197 - val_masked_accuracy: 0.9230 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 2s 45ms/step - loss: 0.2384 - masked_accuracy: 0.9242 - masked_precision: 0.2624 - masked_recall: 0.0516 - masked_f1: 0.0854 - val_loss: 0.2326 - val_masked_accuracy: 0.9231 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2321 - masked_accuracy: 0.9267 - masked_precision: 0.2414 - masked_recall: 0.0330 - masked_f1: 0.0567 - val_loss: 0.2431 - val_masked_accuracy: 0.9231 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2243 - masked_accuracy: 0.9283 - masked_precision: 0.3029 - masked_recall: 0.0342 - masked_f1: 0.0605 - val_loss: 0.2351 - val_masked_accuracy: 0.9231 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 44ms/step - loss: 0.2182 - masked_accuracy: 0.9293 - masked_precision: 0.3317 - masked_recall: 0.0220 - masked_f1: 0.0405 - val_loss: 0.2134 - val_masked_accuracy: 0.9231 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "0.7032275199890137 0.013419068339825285 0.36242232521375023 0.41412307516776065 0.020690651920934517 0.029697115947712967 0.03837715685367584 0.05429835133687909\n"
     ]
    }
   ],
   "source": [
    "accuracyresultlist=[]\n",
    "precisionresultlist=[]\n",
    "recallresultlist=[]\n",
    "aoclist=[]\n",
    "flist=[]\n",
    "for train_index, test_index in kfold.split(X, Y):\n",
    "    # split data into train/test sets\n",
    "    x_train_tfidf = X.iloc[train_index]\n",
    "    y_train_tfidf = Y.iloc[train_index]\n",
    "    x_test_tfidf = X.iloc[test_index]\n",
    "    y_test_tfidf = Y.iloc[test_index]\n",
    "    #y_train_tfidf=y_train_tfidf.fillna(0)\n",
    "    trainX, validateX, trainyp, validatey = train_test_split(x_train_tfidf, y_train_tfidf, test_size=0.2, random_state=1989)\n",
    "    #print(trainyp.shape)\n",
    "    trainyp=trainyp.reset_index(drop=True)\n",
    "    trainX=trainX.reset_index(drop=True)\n",
    "    validatey=validatey.reset_index(drop=True)\n",
    "    validateX=validateX.reset_index(drop=True)\n",
    "    #trainyp.to_csv('Test_before.csv')\n",
    "    #trainy, labelweight =getLikelihood(trainyp,labels)\n",
    "    #trainy.to_csv('Test_after.csv')\n",
    "    #print(labelweight.shape)\n",
    "    trainy=trainyp.fillna(0)\n",
    "    validatey=validatey.fillna(0)\n",
    "    Testy=pd.DataFrame(y_test_tfidf).fillna(-1)\n",
    "\n",
    "    trainy=trainy.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [0,0,1,1])\n",
    "    validatey=validatey.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [0,0,1,1])\n",
    "    Testy=Testy.replace(['Not defined','Susceptible-dose dependent',0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    #print(trainy)\n",
    "    train_labels = np.array(trainy).astype(np.float32)\n",
    "    val_labels = np.array(validatey).astype(np.float32)\n",
    "    test_labels = np.array(Testy).astype(np.float32)\n",
    "    train_features = np.array(trainX).astype(np.float32)\n",
    "    val_features = np.array(validateX).astype(np.float32)\n",
    "    test_features = np.array(x_test_tfidf).astype(np.float32)\n",
    "    #weight=calculating_class_weights_3(trainy.values)\n",
    "    #weight2=weight[:,1:3]\n",
    "    model = make_model(train_features)\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), ###RMS\n",
    "      loss= tf.keras.losses.binary_crossentropy, ###Categoriacal\n",
    "      metrics=METRICS)\n",
    "    #model.summary()\n",
    "    baseline_history = model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        #class_weight=weight2,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(val_features, val_labels))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    results = model.evaluate(test_features, test_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "    accuracyresultlist.append(results[1])\n",
    "    precisionresultlist.append(results[2])\n",
    "    recallresultlist.append(results[3])\n",
    "    flist.append(results[4])\n",
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7032275199890137 0.013419068339825285 0.36242232521375023 0.41412307516776065 0.020690651920934517 0.029697115947712967 0.03837715685367584 0.05429835133687909\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Loss','Accuracy'], 0,['loss','masked_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Precision','Recall'], 0,['masked_precision','masked_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['F1'], 0,['masked_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 802ms/step - loss: 0.3915 - masked_accuracy: 0.8496 - masked_precision: 0.1340 - masked_recall: 0.1568 - masked_f1: 0.1264 - val_loss: 0.3792 - val_masked_accuracy: 0.9234 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.2354 - masked_accuracy: 0.9227 - masked_precision: 0.3115 - masked_recall: 0.0765 - masked_f1: 0.1205 - val_loss: 0.2625 - val_masked_accuracy: 0.9252 - val_masked_precision: 0.6375 - val_masked_recall: 0.0449 - val_masked_f1: 0.0837\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.2016 - masked_accuracy: 0.9276 - masked_precision: 0.4071 - masked_recall: 0.0892 - masked_f1: 0.1450 - val_loss: 0.2254 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.6645 - val_masked_recall: 0.0820 - val_masked_f1: 0.1452\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1847 - masked_accuracy: 0.9309 - masked_precision: 0.5221 - masked_recall: 0.1221 - masked_f1: 0.1954 - val_loss: 0.1994 - val_masked_accuracy: 0.9272 - val_masked_precision: 0.6747 - val_masked_recall: 0.1018 - val_masked_f1: 0.1762\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1708 - masked_accuracy: 0.9343 - masked_precision: 0.5835 - masked_recall: 0.1864 - masked_f1: 0.2779 - val_loss: 0.1783 - val_masked_accuracy: 0.9281 - val_masked_precision: 0.5961 - val_masked_recall: 0.1893 - val_masked_f1: 0.2864\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1566 - masked_accuracy: 0.9361 - masked_precision: 0.6025 - masked_recall: 0.2437 - masked_f1: 0.3444 - val_loss: 0.1721 - val_masked_accuracy: 0.9290 - val_masked_precision: 0.6317 - val_masked_recall: 0.1685 - val_masked_f1: 0.2641\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1455 - masked_accuracy: 0.9402 - masked_precision: 0.6523 - masked_recall: 0.3253 - masked_f1: 0.4296 - val_loss: 0.1671 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6228 - val_masked_recall: 0.3083 - val_masked_f1: 0.4105\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.1351 - masked_accuracy: 0.9431 - masked_precision: 0.6588 - masked_recall: 0.3876 - masked_f1: 0.4841 - val_loss: 0.1679 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.6258 - val_masked_recall: 0.2664 - val_masked_f1: 0.3701\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1277 - masked_accuracy: 0.9452 - masked_precision: 0.6624 - masked_recall: 0.4319 - masked_f1: 0.5184 - val_loss: 0.1659 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.6135 - val_masked_recall: 0.2924 - val_masked_f1: 0.3920\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 795ms/step - loss: 0.1190 - masked_accuracy: 0.9485 - masked_precision: 0.6885 - masked_recall: 0.4823 - masked_f1: 0.5624 - val_loss: 0.1667 - val_masked_accuracy: 0.9330 - val_masked_precision: 0.6122 - val_masked_recall: 0.3297 - val_masked_f1: 0.4231\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.1137 - masked_accuracy: 0.9504 - masked_precision: 0.6982 - masked_recall: 0.5148 - masked_f1: 0.5891 - val_loss: 0.1691 - val_masked_accuracy: 0.9330 - val_masked_precision: 0.6014 - val_masked_recall: 0.3690 - val_masked_f1: 0.4539\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.1084 - masked_accuracy: 0.9530 - masked_precision: 0.7168 - masked_recall: 0.5433 - masked_f1: 0.6156 - val_loss: 0.1689 - val_masked_accuracy: 0.9326 - val_masked_precision: 0.5852 - val_masked_recall: 0.4164 - val_masked_f1: 0.4837\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 786ms/step - loss: 0.3472 - masked_accuracy: 0.8758 - masked_precision: 0.1280 - masked_recall: 0.0962 - masked_f1: 0.0930 - val_loss: 0.2370 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.2361 - masked_accuracy: 0.9219 - masked_precision: 0.2470 - masked_recall: 0.0497 - masked_f1: 0.0807 - val_loss: 0.2385 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.2066 - masked_accuracy: 0.9268 - masked_precision: 0.4031 - masked_recall: 0.0696 - masked_f1: 0.1168 - val_loss: 0.1939 - val_masked_accuracy: 0.9360 - val_masked_precision: 0.5207 - val_masked_recall: 0.0407 - val_masked_f1: 0.0752\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1881 - masked_accuracy: 0.9296 - masked_precision: 0.5173 - masked_recall: 0.1236 - masked_f1: 0.1960 - val_loss: 0.1828 - val_masked_accuracy: 0.9380 - val_masked_precision: 0.5734 - val_masked_recall: 0.1534 - val_masked_f1: 0.2412\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1736 - masked_accuracy: 0.9322 - masked_precision: 0.5612 - masked_recall: 0.1969 - masked_f1: 0.2889 - val_loss: 0.1604 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.5964 - val_masked_recall: 0.1679 - val_masked_f1: 0.2608\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1609 - masked_accuracy: 0.9350 - masked_precision: 0.5898 - masked_recall: 0.2631 - masked_f1: 0.3604 - val_loss: 0.1575 - val_masked_accuracy: 0.9404 - val_masked_precision: 0.6185 - val_masked_recall: 0.2016 - val_masked_f1: 0.3022\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1501 - masked_accuracy: 0.9393 - masked_precision: 0.6364 - masked_recall: 0.3271 - masked_f1: 0.4273 - val_loss: 0.1507 - val_masked_accuracy: 0.9411 - val_masked_precision: 0.5902 - val_masked_recall: 0.2883 - val_masked_f1: 0.3843\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1389 - masked_accuracy: 0.9411 - masked_precision: 0.6398 - masked_recall: 0.3784 - masked_f1: 0.4720 - val_loss: 0.1553 - val_masked_accuracy: 0.9397 - val_masked_precision: 0.5542 - val_masked_recall: 0.3645 - val_masked_f1: 0.4352\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1322 - masked_accuracy: 0.9446 - masked_precision: 0.6674 - masked_recall: 0.4282 - masked_f1: 0.5172 - val_loss: 0.1493 - val_masked_accuracy: 0.9410 - val_masked_precision: 0.5657 - val_masked_recall: 0.3542 - val_masked_f1: 0.4314\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1255 - masked_accuracy: 0.9464 - masked_precision: 0.6758 - masked_recall: 0.4668 - masked_f1: 0.5477 - val_loss: 0.1462 - val_masked_accuracy: 0.9406 - val_masked_precision: 0.5590 - val_masked_recall: 0.3656 - val_masked_f1: 0.4376\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 45s 805ms/step - loss: 0.1192 - masked_accuracy: 0.9490 - masked_precision: 0.6983 - masked_recall: 0.4986 - masked_f1: 0.5778 - val_loss: 0.1520 - val_masked_accuracy: 0.9398 - val_masked_precision: 0.5498 - val_masked_recall: 0.3526 - val_masked_f1: 0.4240\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1125 - masked_accuracy: 0.9510 - masked_precision: 0.7073 - masked_recall: 0.5249 - masked_f1: 0.5993 - val_loss: 0.1560 - val_masked_accuracy: 0.9403 - val_masked_precision: 0.5562 - val_masked_recall: 0.3476 - val_masked_f1: 0.4229\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 787ms/step - loss: 0.3777 - masked_accuracy: 0.8678 - masked_precision: 0.1546 - masked_recall: 0.1529 - masked_f1: 0.1320 - val_loss: 0.2714 - val_masked_accuracy: 0.9228 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.2362 - masked_accuracy: 0.9230 - masked_precision: 0.2519 - masked_recall: 0.0675 - masked_f1: 0.1036 - val_loss: 0.2339 - val_masked_accuracy: 0.9238 - val_masked_precision: 0.6310 - val_masked_recall: 0.0201 - val_masked_f1: 0.0386\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.2036 - masked_accuracy: 0.9291 - masked_precision: 0.4104 - masked_recall: 0.0845 - masked_f1: 0.1384 - val_loss: 0.2152 - val_masked_accuracy: 0.9271 - val_masked_precision: 0.7192 - val_masked_recall: 0.0992 - val_masked_f1: 0.1733\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1852 - masked_accuracy: 0.9318 - masked_precision: 0.5091 - masked_recall: 0.1393 - masked_f1: 0.2161 - val_loss: 0.2093 - val_masked_accuracy: 0.9278 - val_masked_precision: 0.6363 - val_masked_recall: 0.1684 - val_masked_f1: 0.2647\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 45s 803ms/step - loss: 0.1704 - masked_accuracy: 0.9340 - masked_precision: 0.5478 - masked_recall: 0.1905 - masked_f1: 0.2792 - val_loss: 0.1812 - val_masked_accuracy: 0.9282 - val_masked_precision: 0.6664 - val_masked_recall: 0.1418 - val_masked_f1: 0.2315\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1581 - masked_accuracy: 0.9369 - masked_precision: 0.5843 - masked_recall: 0.2527 - masked_f1: 0.3468 - val_loss: 0.1779 - val_masked_accuracy: 0.9305 - val_masked_precision: 0.6592 - val_masked_recall: 0.2203 - val_masked_f1: 0.3273\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1478 - masked_accuracy: 0.9395 - masked_precision: 0.6138 - masked_recall: 0.3017 - masked_f1: 0.3996 - val_loss: 0.1717 - val_masked_accuracy: 0.9332 - val_masked_precision: 0.6756 - val_masked_recall: 0.2766 - val_masked_f1: 0.3888\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1402 - masked_accuracy: 0.9416 - masked_precision: 0.6375 - masked_recall: 0.3453 - masked_f1: 0.4419 - val_loss: 0.1716 - val_masked_accuracy: 0.9326 - val_masked_precision: 0.6462 - val_masked_recall: 0.2962 - val_masked_f1: 0.4027\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1310 - masked_accuracy: 0.9444 - masked_precision: 0.6613 - masked_recall: 0.3907 - masked_f1: 0.4863 - val_loss: 0.1731 - val_masked_accuracy: 0.9330 - val_masked_precision: 0.6462 - val_masked_recall: 0.3060 - val_masked_f1: 0.4134\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1235 - masked_accuracy: 0.9481 - masked_precision: 0.6952 - masked_recall: 0.4425 - masked_f1: 0.5376 - val_loss: 0.1686 - val_masked_accuracy: 0.9346 - val_masked_precision: 0.6225 - val_masked_recall: 0.3943 - val_masked_f1: 0.4798\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1179 - masked_accuracy: 0.9491 - masked_precision: 0.6852 - masked_recall: 0.4819 - masked_f1: 0.5626 - val_loss: 0.1711 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6192 - val_masked_recall: 0.3574 - val_masked_f1: 0.4511\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 777ms/step - loss: 0.1132 - masked_accuracy: 0.9513 - masked_precision: 0.6990 - masked_recall: 0.5052 - masked_f1: 0.5831 - val_loss: 0.1721 - val_masked_accuracy: 0.9349 - val_masked_precision: 0.6358 - val_masked_recall: 0.3710 - val_masked_f1: 0.4653\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1049 - masked_accuracy: 0.9546 - masked_precision: 0.7222 - masked_recall: 0.5554 - masked_f1: 0.6245 - val_loss: 0.1726 - val_masked_accuracy: 0.9339 - val_masked_precision: 0.6102 - val_masked_recall: 0.4046 - val_masked_f1: 0.4840\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1010 - masked_accuracy: 0.9559 - masked_precision: 0.7311 - masked_recall: 0.5743 - masked_f1: 0.6397 - val_loss: 0.1732 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.5896 - val_masked_recall: 0.3912 - val_masked_f1: 0.4684\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0984 - masked_accuracy: 0.9577 - masked_precision: 0.7375 - masked_recall: 0.6016 - masked_f1: 0.6599 - val_loss: 0.1731 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.5771 - val_masked_recall: 0.4086 - val_masked_f1: 0.4765\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0932 - masked_accuracy: 0.9591 - masked_precision: 0.7524 - masked_recall: 0.6135 - masked_f1: 0.6729 - val_loss: 0.1761 - val_masked_accuracy: 0.9329 - val_masked_precision: 0.5996 - val_masked_recall: 0.3953 - val_masked_f1: 0.4749\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0910 - masked_accuracy: 0.9603 - masked_precision: 0.7494 - masked_recall: 0.6457 - masked_f1: 0.6909 - val_loss: 0.1783 - val_masked_accuracy: 0.9331 - val_masked_precision: 0.5984 - val_masked_recall: 0.3974 - val_masked_f1: 0.4750\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 777ms/step - loss: 0.3826 - masked_accuracy: 0.8600 - masked_precision: 0.1377 - masked_recall: 0.1546 - masked_f1: 0.1212 - val_loss: 0.2830 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.2395 - masked_accuracy: 0.9235 - masked_precision: 0.2232 - masked_recall: 0.0430 - masked_f1: 0.0698 - val_loss: 0.2588 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2110 - masked_accuracy: 0.9271 - masked_precision: 0.3258 - masked_recall: 0.0465 - masked_f1: 0.0805 - val_loss: 0.2097 - val_masked_accuracy: 0.9311 - val_masked_precision: 0.5744 - val_masked_recall: 0.0229 - val_masked_f1: 0.0435\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1908 - masked_accuracy: 0.9303 - masked_precision: 0.4733 - masked_recall: 0.1003 - masked_f1: 0.1626 - val_loss: 0.1823 - val_masked_accuracy: 0.9327 - val_masked_precision: 0.6382 - val_masked_recall: 0.0929 - val_masked_f1: 0.1593\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1770 - masked_accuracy: 0.9326 - masked_precision: 0.5469 - masked_recall: 0.1550 - masked_f1: 0.2377 - val_loss: 0.1665 - val_masked_accuracy: 0.9334 - val_masked_precision: 0.6137 - val_masked_recall: 0.1163 - val_masked_f1: 0.1916\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1656 - masked_accuracy: 0.9353 - masked_precision: 0.5780 - masked_recall: 0.2052 - masked_f1: 0.2978 - val_loss: 0.1709 - val_masked_accuracy: 0.9336 - val_masked_precision: 0.5750 - val_masked_recall: 0.1710 - val_masked_f1: 0.2599\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1520 - masked_accuracy: 0.9381 - masked_precision: 0.6198 - masked_recall: 0.2779 - masked_f1: 0.3772 - val_loss: 0.1538 - val_masked_accuracy: 0.9364 - val_masked_precision: 0.6226 - val_masked_recall: 0.2119 - val_masked_f1: 0.3120\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1411 - masked_accuracy: 0.9408 - masked_precision: 0.6272 - masked_recall: 0.3480 - masked_f1: 0.4440 - val_loss: 0.1530 - val_masked_accuracy: 0.9377 - val_masked_precision: 0.6365 - val_masked_recall: 0.2512 - val_masked_f1: 0.3545\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1332 - masked_accuracy: 0.9447 - masked_precision: 0.6575 - masked_recall: 0.4056 - masked_f1: 0.4969 - val_loss: 0.1528 - val_masked_accuracy: 0.9370 - val_masked_precision: 0.5837 - val_masked_recall: 0.3325 - val_masked_f1: 0.4199\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.1249 - masked_accuracy: 0.9469 - masked_precision: 0.6672 - masked_recall: 0.4570 - masked_f1: 0.5376 - val_loss: 0.1522 - val_masked_accuracy: 0.9387 - val_masked_precision: 0.5812 - val_masked_recall: 0.4119 - val_masked_f1: 0.4786\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1192 - masked_accuracy: 0.9494 - masked_precision: 0.6947 - masked_recall: 0.4831 - masked_f1: 0.5656 - val_loss: 0.1523 - val_masked_accuracy: 0.9402 - val_masked_precision: 0.6208 - val_masked_recall: 0.3589 - val_masked_f1: 0.4513\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1154 - masked_accuracy: 0.9505 - masked_precision: 0.7017 - masked_recall: 0.4971 - masked_f1: 0.5782 - val_loss: 0.1500 - val_masked_accuracy: 0.9398 - val_masked_precision: 0.6052 - val_masked_recall: 0.3935 - val_masked_f1: 0.4712\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.1087 - masked_accuracy: 0.9531 - masked_precision: 0.7157 - masked_recall: 0.5406 - masked_f1: 0.6118 - val_loss: 0.1499 - val_masked_accuracy: 0.9404 - val_masked_precision: 0.6031 - val_masked_recall: 0.4215 - val_masked_f1: 0.4917\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1043 - masked_accuracy: 0.9559 - masked_precision: 0.7358 - masked_recall: 0.5673 - masked_f1: 0.6374 - val_loss: 0.1537 - val_masked_accuracy: 0.9392 - val_masked_precision: 0.5898 - val_masked_recall: 0.4102 - val_masked_f1: 0.4801\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1001 - masked_accuracy: 0.9572 - masked_precision: 0.7391 - masked_recall: 0.5897 - masked_f1: 0.6525 - val_loss: 0.1547 - val_masked_accuracy: 0.9420 - val_masked_precision: 0.6287 - val_masked_recall: 0.4051 - val_masked_f1: 0.4871\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.0944 - masked_accuracy: 0.9591 - masked_precision: 0.7529 - masked_recall: 0.6180 - masked_f1: 0.6762 - val_loss: 0.1511 - val_masked_accuracy: 0.9399 - val_masked_precision: 0.5917 - val_masked_recall: 0.4123 - val_masked_f1: 0.4838\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0940 - masked_accuracy: 0.9596 - masked_precision: 0.7566 - masked_recall: 0.6188 - masked_f1: 0.6784 - val_loss: 0.1529 - val_masked_accuracy: 0.9411 - val_masked_precision: 0.6091 - val_masked_recall: 0.4334 - val_masked_f1: 0.5026\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0896 - masked_accuracy: 0.9617 - masked_precision: 0.7677 - masked_recall: 0.6420 - masked_f1: 0.6964 - val_loss: 0.1587 - val_masked_accuracy: 0.9418 - val_masked_precision: 0.6127 - val_masked_recall: 0.4384 - val_masked_f1: 0.5075\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.0870 - masked_accuracy: 0.9626 - masked_precision: 0.7762 - masked_recall: 0.6539 - masked_f1: 0.7068 - val_loss: 0.1552 - val_masked_accuracy: 0.9384 - val_masked_precision: 0.5673 - val_masked_recall: 0.4458 - val_masked_f1: 0.4967\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.0822 - masked_accuracy: 0.9645 - masked_precision: 0.7815 - masked_recall: 0.6788 - masked_f1: 0.7246 - val_loss: 0.1625 - val_masked_accuracy: 0.9387 - val_masked_precision: 0.5692 - val_masked_recall: 0.4616 - val_masked_f1: 0.5069\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 775ms/step - loss: 0.4199 - masked_accuracy: 0.8516 - masked_precision: 0.1299 - masked_recall: 0.1506 - masked_f1: 0.1199 - val_loss: 0.3654 - val_masked_accuracy: 0.9295 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.2410 - masked_accuracy: 0.9202 - masked_precision: 0.2723 - masked_recall: 0.0749 - masked_f1: 0.1161 - val_loss: 0.2165 - val_masked_accuracy: 0.9321 - val_masked_precision: 0.6949 - val_masked_recall: 0.0722 - val_masked_f1: 0.1294\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.2091 - masked_accuracy: 0.9269 - masked_precision: 0.4334 - masked_recall: 0.1022 - masked_f1: 0.1631 - val_loss: 0.2058 - val_masked_accuracy: 0.9324 - val_masked_precision: 0.6456 - val_masked_recall: 0.0957 - val_masked_f1: 0.1648\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1910 - masked_accuracy: 0.9300 - masked_precision: 0.5109 - masked_recall: 0.1558 - masked_f1: 0.2352 - val_loss: 0.2072 - val_masked_accuracy: 0.9306 - val_masked_precision: 0.5306 - val_masked_recall: 0.1814 - val_masked_f1: 0.2678\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1793 - masked_accuracy: 0.9326 - masked_precision: 0.5719 - masked_recall: 0.1939 - masked_f1: 0.2857 - val_loss: 0.1969 - val_masked_accuracy: 0.9341 - val_masked_precision: 0.6124 - val_masked_recall: 0.1934 - val_masked_f1: 0.2913\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1656 - masked_accuracy: 0.9347 - masked_precision: 0.5905 - masked_recall: 0.2499 - masked_f1: 0.3447 - val_loss: 0.1713 - val_masked_accuracy: 0.9350 - val_masked_precision: 0.6069 - val_masked_recall: 0.2477 - val_masked_f1: 0.3480\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 43s 773ms/step - loss: 0.1536 - masked_accuracy: 0.9373 - masked_precision: 0.6143 - masked_recall: 0.2924 - masked_f1: 0.3915 - val_loss: 0.1614 - val_masked_accuracy: 0.9349 - val_masked_precision: 0.6103 - val_masked_recall: 0.2283 - val_masked_f1: 0.3282\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1457 - masked_accuracy: 0.9399 - masked_precision: 0.6359 - masked_recall: 0.3479 - masked_f1: 0.4447 - val_loss: 0.1602 - val_masked_accuracy: 0.9371 - val_masked_precision: 0.6305 - val_masked_recall: 0.2921 - val_masked_f1: 0.3946\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1366 - masked_accuracy: 0.9420 - masked_precision: 0.6484 - masked_recall: 0.3990 - masked_f1: 0.4887 - val_loss: 0.1648 - val_masked_accuracy: 0.9351 - val_masked_precision: 0.5870 - val_masked_recall: 0.3090 - val_masked_f1: 0.3998\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 43s 778ms/step - loss: 0.1251 - masked_accuracy: 0.9475 - masked_precision: 0.6907 - masked_recall: 0.4529 - masked_f1: 0.5434 - val_loss: 0.1603 - val_masked_accuracy: 0.9358 - val_masked_precision: 0.5798 - val_masked_recall: 0.3584 - val_masked_f1: 0.4402\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1206 - masked_accuracy: 0.9477 - masked_precision: 0.6826 - masked_recall: 0.4799 - masked_f1: 0.5610 - val_loss: 0.1624 - val_masked_accuracy: 0.9357 - val_masked_precision: 0.5681 - val_masked_recall: 0.3869 - val_masked_f1: 0.4571\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1174 - masked_accuracy: 0.9498 - masked_precision: 0.6970 - masked_recall: 0.5135 - masked_f1: 0.5881 - val_loss: 0.1636 - val_masked_accuracy: 0.9356 - val_masked_precision: 0.5613 - val_masked_recall: 0.3857 - val_masked_f1: 0.4547\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1120 - masked_accuracy: 0.9525 - masked_precision: 0.7254 - masked_recall: 0.5370 - masked_f1: 0.6133 - val_loss: 0.1630 - val_masked_accuracy: 0.9377 - val_masked_precision: 0.5720 - val_masked_recall: 0.4522 - val_masked_f1: 0.5027\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.1054 - masked_accuracy: 0.9547 - masked_precision: 0.7199 - masked_recall: 0.5769 - masked_f1: 0.6370 - val_loss: 0.1623 - val_masked_accuracy: 0.9369 - val_masked_precision: 0.5729 - val_masked_recall: 0.4215 - val_masked_f1: 0.4816\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.1014 - masked_accuracy: 0.9562 - masked_precision: 0.7357 - masked_recall: 0.5979 - masked_f1: 0.6567 - val_loss: 0.1648 - val_masked_accuracy: 0.9366 - val_masked_precision: 0.5670 - val_masked_recall: 0.4182 - val_masked_f1: 0.4780\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.0985 - masked_accuracy: 0.9580 - masked_precision: 0.7525 - masked_recall: 0.6026 - masked_f1: 0.6667 - val_loss: 0.1644 - val_masked_accuracy: 0.9358 - val_masked_precision: 0.5507 - val_masked_recall: 0.4437 - val_masked_f1: 0.4891\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.0953 - masked_accuracy: 0.9593 - masked_precision: 0.7568 - masked_recall: 0.6317 - masked_f1: 0.6858 - val_loss: 0.1697 - val_masked_accuracy: 0.9352 - val_masked_precision: 0.5521 - val_masked_recall: 0.4166 - val_masked_f1: 0.4712\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.0940 - masked_accuracy: 0.9602 - masked_precision: 0.7524 - masked_recall: 0.6524 - masked_f1: 0.6959 - val_loss: 0.1663 - val_masked_accuracy: 0.9382 - val_masked_precision: 0.5836 - val_masked_recall: 0.4401 - val_masked_f1: 0.4993\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0878 - masked_accuracy: 0.9615 - masked_precision: 0.7679 - masked_recall: 0.6638 - masked_f1: 0.7096 - val_loss: 0.1760 - val_masked_accuracy: 0.9372 - val_masked_precision: 0.5632 - val_masked_recall: 0.4443 - val_masked_f1: 0.4947\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0865 - masked_accuracy: 0.9632 - masked_precision: 0.7783 - masked_recall: 0.6758 - masked_f1: 0.7211 - val_loss: 0.1746 - val_masked_accuracy: 0.9370 - val_masked_precision: 0.5702 - val_masked_recall: 0.4577 - val_masked_f1: 0.5041\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.0826 - masked_accuracy: 0.9644 - masked_precision: 0.7788 - masked_recall: 0.6941 - masked_f1: 0.7314 - val_loss: 0.1802 - val_masked_accuracy: 0.9369 - val_masked_precision: 0.5676 - val_masked_recall: 0.4567 - val_masked_f1: 0.5021\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 43s 777ms/step - loss: 0.0805 - masked_accuracy: 0.9646 - masked_precision: 0.7840 - masked_recall: 0.6958 - masked_f1: 0.7357 - val_loss: 0.1805 - val_masked_accuracy: 0.9357 - val_masked_precision: 0.5530 - val_masked_recall: 0.4785 - val_masked_f1: 0.5101\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0777 - masked_accuracy: 0.9676 - masked_precision: 0.8016 - masked_recall: 0.7273 - masked_f1: 0.7606 - val_loss: 0.1821 - val_masked_accuracy: 0.9361 - val_masked_precision: 0.5576 - val_masked_recall: 0.4668 - val_masked_f1: 0.5045\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.4353 - masked_accuracy: 0.8277 - masked_precision: 0.1058 - masked_recall: 0.1526 - masked_f1: 0.1071 - val_loss: 0.3474 - val_masked_accuracy: 0.9287 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2476 - masked_accuracy: 0.9194 - masked_precision: 0.2074 - masked_recall: 0.0534 - masked_f1: 0.0829 - val_loss: 0.2645 - val_masked_accuracy: 0.9290 - val_masked_precision: 0.4821 - val_masked_recall: 0.0125 - val_masked_f1: 0.0243\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2137 - masked_accuracy: 0.9269 - masked_precision: 0.3550 - masked_recall: 0.0638 - masked_f1: 0.1065 - val_loss: 0.2200 - val_masked_accuracy: 0.9303 - val_masked_precision: 0.8274 - val_masked_recall: 0.0279 - val_masked_f1: 0.0535\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1970 - masked_accuracy: 0.9293 - masked_precision: 0.4463 - masked_recall: 0.1059 - masked_f1: 0.1683 - val_loss: 0.2067 - val_masked_accuracy: 0.9321 - val_masked_precision: 0.6946 - val_masked_recall: 0.0826 - val_masked_f1: 0.1466\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1805 - masked_accuracy: 0.9316 - masked_precision: 0.5166 - masked_recall: 0.1565 - masked_f1: 0.2360 - val_loss: 0.1756 - val_masked_accuracy: 0.9342 - val_masked_precision: 0.7036 - val_masked_recall: 0.1336 - val_masked_f1: 0.2237\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1684 - masked_accuracy: 0.9347 - masked_precision: 0.5804 - masked_recall: 0.2252 - masked_f1: 0.3197 - val_loss: 0.1707 - val_masked_accuracy: 0.9348 - val_masked_precision: 0.6669 - val_masked_recall: 0.1715 - val_masked_f1: 0.2717\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.1561 - masked_accuracy: 0.9366 - masked_precision: 0.5948 - masked_recall: 0.2805 - masked_f1: 0.3763 - val_loss: 0.1639 - val_masked_accuracy: 0.9343 - val_masked_precision: 0.6031 - val_masked_recall: 0.2361 - val_masked_f1: 0.3380\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1469 - masked_accuracy: 0.9401 - masked_precision: 0.6288 - masked_recall: 0.3417 - masked_f1: 0.4383 - val_loss: 0.1639 - val_masked_accuracy: 0.9347 - val_masked_precision: 0.5899 - val_masked_recall: 0.2699 - val_masked_f1: 0.3682\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1389 - masked_accuracy: 0.9419 - masked_precision: 0.6308 - masked_recall: 0.3784 - masked_f1: 0.4681 - val_loss: 0.1560 - val_masked_accuracy: 0.9357 - val_masked_precision: 0.5874 - val_masked_recall: 0.3409 - val_masked_f1: 0.4294\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1328 - masked_accuracy: 0.9441 - masked_precision: 0.6468 - masked_recall: 0.4123 - masked_f1: 0.5004 - val_loss: 0.1593 - val_masked_accuracy: 0.9345 - val_masked_precision: 0.5771 - val_masked_recall: 0.3215 - val_masked_f1: 0.4102\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1261 - masked_accuracy: 0.9460 - masked_precision: 0.6703 - masked_recall: 0.4430 - masked_f1: 0.5287 - val_loss: 0.1643 - val_masked_accuracy: 0.9326 - val_masked_precision: 0.5385 - val_masked_recall: 0.4228 - val_masked_f1: 0.4717\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1210 - masked_accuracy: 0.9485 - masked_precision: 0.6939 - masked_recall: 0.4786 - masked_f1: 0.5618 - val_loss: 0.1577 - val_masked_accuracy: 0.9365 - val_masked_precision: 0.5868 - val_masked_recall: 0.3891 - val_masked_f1: 0.4659\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1138 - masked_accuracy: 0.9499 - masked_precision: 0.6876 - masked_recall: 0.5108 - masked_f1: 0.5827 - val_loss: 0.1610 - val_masked_accuracy: 0.9373 - val_masked_precision: 0.5874 - val_masked_recall: 0.4280 - val_masked_f1: 0.4932\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1105 - masked_accuracy: 0.9525 - masked_precision: 0.7105 - masked_recall: 0.5328 - masked_f1: 0.6044 - val_loss: 0.1623 - val_masked_accuracy: 0.9378 - val_masked_precision: 0.5883 - val_masked_recall: 0.4376 - val_masked_f1: 0.4998\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1054 - masked_accuracy: 0.9546 - masked_precision: 0.7195 - masked_recall: 0.5746 - masked_f1: 0.6351 - val_loss: 0.1682 - val_masked_accuracy: 0.9370 - val_masked_precision: 0.5962 - val_masked_recall: 0.3636 - val_masked_f1: 0.4491\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1014 - masked_accuracy: 0.9564 - masked_precision: 0.7337 - masked_recall: 0.5859 - masked_f1: 0.6492 - val_loss: 0.1680 - val_masked_accuracy: 0.9358 - val_masked_precision: 0.5735 - val_masked_recall: 0.4039 - val_masked_f1: 0.4723\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0987 - masked_accuracy: 0.9580 - masked_precision: 0.7403 - masked_recall: 0.6104 - masked_f1: 0.6663 - val_loss: 0.1681 - val_masked_accuracy: 0.9368 - val_masked_precision: 0.5820 - val_masked_recall: 0.4248 - val_masked_f1: 0.4882\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.0949 - masked_accuracy: 0.9587 - masked_precision: 0.7511 - masked_recall: 0.6088 - masked_f1: 0.6695 - val_loss: 0.1661 - val_masked_accuracy: 0.9346 - val_masked_precision: 0.5555 - val_masked_recall: 0.4351 - val_masked_f1: 0.4856\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 45s 806ms/step - loss: 0.0908 - masked_accuracy: 0.9606 - masked_precision: 0.7603 - masked_recall: 0.6409 - masked_f1: 0.6918 - val_loss: 0.1799 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.5748 - val_masked_recall: 0.3749 - val_masked_f1: 0.4487\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 778ms/step - loss: 0.4206 - masked_accuracy: 0.8434 - masked_precision: 0.0971 - masked_recall: 0.1271 - masked_f1: 0.0930 - val_loss: 0.2912 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.2427 - masked_accuracy: 0.9203 - masked_precision: 0.2256 - masked_recall: 0.0567 - masked_f1: 0.0877 - val_loss: 0.2187 - val_masked_accuracy: 0.9307 - val_masked_precision: 0.0714 - val_masked_recall: 0.0011 - val_masked_f1: 0.0022\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.2123 - masked_accuracy: 0.9266 - masked_precision: 0.3776 - masked_recall: 0.0680 - masked_f1: 0.1132 - val_loss: 0.2154 - val_masked_accuracy: 0.9328 - val_masked_precision: 0.6387 - val_masked_recall: 0.0750 - val_masked_f1: 0.1333\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1936 - masked_accuracy: 0.9294 - masked_precision: 0.4894 - masked_recall: 0.1054 - masked_f1: 0.1709 - val_loss: 0.1910 - val_masked_accuracy: 0.9331 - val_masked_precision: 0.6759 - val_masked_recall: 0.0632 - val_masked_f1: 0.1142\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1808 - masked_accuracy: 0.9313 - masked_precision: 0.5282 - masked_recall: 0.1479 - masked_f1: 0.2285 - val_loss: 0.1747 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6610 - val_masked_recall: 0.0849 - val_masked_f1: 0.1476\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1663 - masked_accuracy: 0.9339 - masked_precision: 0.5742 - masked_recall: 0.2139 - masked_f1: 0.3063 - val_loss: 0.1720 - val_masked_accuracy: 0.9352 - val_masked_precision: 0.6409 - val_masked_recall: 0.1618 - val_masked_f1: 0.2564\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.1551 - masked_accuracy: 0.9367 - masked_precision: 0.6037 - masked_recall: 0.2870 - masked_f1: 0.3840 - val_loss: 0.1658 - val_masked_accuracy: 0.9372 - val_masked_precision: 0.6109 - val_masked_recall: 0.2606 - val_masked_f1: 0.3611\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1417 - masked_accuracy: 0.9403 - masked_precision: 0.6361 - masked_recall: 0.3466 - masked_f1: 0.4435 - val_loss: 0.1616 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.6161 - val_masked_recall: 0.3321 - val_masked_f1: 0.4261\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.1352 - masked_accuracy: 0.9432 - masked_precision: 0.6477 - masked_recall: 0.4128 - masked_f1: 0.4990 - val_loss: 0.1642 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.6228 - val_masked_recall: 0.3548 - val_masked_f1: 0.4451\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1248 - masked_accuracy: 0.9469 - masked_precision: 0.6819 - masked_recall: 0.4514 - masked_f1: 0.5404 - val_loss: 0.1598 - val_masked_accuracy: 0.9384 - val_masked_precision: 0.5919 - val_masked_recall: 0.3843 - val_masked_f1: 0.4616\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1187 - masked_accuracy: 0.9490 - masked_precision: 0.6854 - masked_recall: 0.4880 - masked_f1: 0.5676 - val_loss: 0.1587 - val_masked_accuracy: 0.9392 - val_masked_precision: 0.5855 - val_masked_recall: 0.4128 - val_masked_f1: 0.4797\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.1133 - masked_accuracy: 0.9518 - masked_precision: 0.7103 - masked_recall: 0.5307 - masked_f1: 0.6032 - val_loss: 0.1605 - val_masked_accuracy: 0.9389 - val_masked_precision: 0.5963 - val_masked_recall: 0.3939 - val_masked_f1: 0.4687\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.1079 - masked_accuracy: 0.9529 - masked_precision: 0.7140 - masked_recall: 0.5539 - masked_f1: 0.6207 - val_loss: 0.1586 - val_masked_accuracy: 0.9396 - val_masked_precision: 0.5930 - val_masked_recall: 0.4450 - val_masked_f1: 0.5024\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1034 - masked_accuracy: 0.9553 - masked_precision: 0.7233 - masked_recall: 0.5806 - masked_f1: 0.6407 - val_loss: 0.1653 - val_masked_accuracy: 0.9384 - val_masked_precision: 0.5861 - val_masked_recall: 0.4212 - val_masked_f1: 0.4837\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0991 - masked_accuracy: 0.9568 - masked_precision: 0.7339 - masked_recall: 0.5924 - masked_f1: 0.6523 - val_loss: 0.1660 - val_masked_accuracy: 0.9372 - val_masked_precision: 0.5648 - val_masked_recall: 0.4235 - val_masked_f1: 0.4801\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0971 - masked_accuracy: 0.9586 - masked_precision: 0.7568 - masked_recall: 0.6109 - masked_f1: 0.6737 - val_loss: 0.1666 - val_masked_accuracy: 0.9363 - val_masked_precision: 0.5520 - val_masked_recall: 0.4620 - val_masked_f1: 0.4987\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0935 - masked_accuracy: 0.9602 - masked_precision: 0.7663 - masked_recall: 0.6266 - masked_f1: 0.6864 - val_loss: 0.1714 - val_masked_accuracy: 0.9361 - val_masked_precision: 0.5480 - val_masked_recall: 0.4721 - val_masked_f1: 0.5028\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0895 - masked_accuracy: 0.9610 - masked_precision: 0.7630 - masked_recall: 0.6505 - masked_f1: 0.7004 - val_loss: 0.1733 - val_masked_accuracy: 0.9402 - val_masked_precision: 0.5992 - val_masked_recall: 0.4503 - val_masked_f1: 0.5079\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0869 - masked_accuracy: 0.9625 - masked_precision: 0.7726 - masked_recall: 0.6663 - masked_f1: 0.7125 - val_loss: 0.1748 - val_masked_accuracy: 0.9364 - val_masked_precision: 0.5583 - val_masked_recall: 0.4291 - val_masked_f1: 0.4811\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.0866 - masked_accuracy: 0.9637 - masked_precision: 0.7887 - masked_recall: 0.6679 - masked_f1: 0.7210 - val_loss: 0.1765 - val_masked_accuracy: 0.9392 - val_masked_precision: 0.5822 - val_masked_recall: 0.4654 - val_masked_f1: 0.5131\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.0809 - masked_accuracy: 0.9647 - masked_precision: 0.7825 - masked_recall: 0.6942 - masked_f1: 0.7330 - val_loss: 0.1744 - val_masked_accuracy: 0.9407 - val_masked_precision: 0.6019 - val_masked_recall: 0.4370 - val_masked_f1: 0.5020\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.0799 - masked_accuracy: 0.9666 - masked_precision: 0.7968 - masked_recall: 0.7075 - masked_f1: 0.7476 - val_loss: 0.1872 - val_masked_accuracy: 0.9375 - val_masked_precision: 0.5653 - val_masked_recall: 0.4630 - val_masked_f1: 0.5050\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0760 - masked_accuracy: 0.9679 - masked_precision: 0.8088 - masked_recall: 0.7133 - masked_f1: 0.7558 - val_loss: 0.1909 - val_masked_accuracy: 0.9379 - val_masked_precision: 0.5757 - val_masked_recall: 0.4080 - val_masked_f1: 0.4747\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.0767 - masked_accuracy: 0.9674 - masked_precision: 0.8013 - masked_recall: 0.7197 - masked_f1: 0.7557 - val_loss: 0.1911 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.5860 - val_masked_recall: 0.4217 - val_masked_f1: 0.4864\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0760 - masked_accuracy: 0.9672 - masked_precision: 0.7969 - masked_recall: 0.7210 - masked_f1: 0.7547 - val_loss: 0.1850 - val_masked_accuracy: 0.9366 - val_masked_precision: 0.5572 - val_masked_recall: 0.4524 - val_masked_f1: 0.4954\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0722 - masked_accuracy: 0.9688 - masked_precision: 0.8068 - masked_recall: 0.7365 - masked_f1: 0.7679 - val_loss: 0.1916 - val_masked_accuracy: 0.9373 - val_masked_precision: 0.5648 - val_masked_recall: 0.4651 - val_masked_f1: 0.5047\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.4999 - masked_accuracy: 0.7968 - masked_precision: 0.1172 - masked_recall: 0.2559 - masked_f1: 0.1483 - val_loss: 0.2973 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.2695 - masked_accuracy: 0.9118 - masked_precision: 0.1853 - masked_recall: 0.0740 - masked_f1: 0.1011 - val_loss: 0.2367 - val_masked_accuracy: 0.9264 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.2269 - masked_accuracy: 0.9254 - masked_precision: 0.2902 - masked_recall: 0.0493 - masked_f1: 0.0830 - val_loss: 0.2162 - val_masked_accuracy: 0.9271 - val_masked_precision: 0.6310 - val_masked_recall: 0.0180 - val_masked_f1: 0.0348\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.2075 - masked_accuracy: 0.9268 - masked_precision: 0.3699 - masked_recall: 0.0719 - masked_f1: 0.1185 - val_loss: 0.2285 - val_masked_accuracy: 0.9288 - val_masked_precision: 0.6343 - val_masked_recall: 0.0828 - val_masked_f1: 0.1437\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.1924 - masked_accuracy: 0.9297 - masked_precision: 0.4840 - masked_recall: 0.1204 - masked_f1: 0.1905 - val_loss: 0.1858 - val_masked_accuracy: 0.9296 - val_masked_precision: 0.6005 - val_masked_recall: 0.1386 - val_masked_f1: 0.2215\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1820 - masked_accuracy: 0.9315 - masked_precision: 0.5310 - masked_recall: 0.1578 - masked_f1: 0.2389 - val_loss: 0.1900 - val_masked_accuracy: 0.9298 - val_masked_precision: 0.5862 - val_masked_recall: 0.1700 - val_masked_f1: 0.2604\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.1741 - masked_accuracy: 0.9325 - masked_precision: 0.5537 - masked_recall: 0.1942 - masked_f1: 0.2829 - val_loss: 0.1782 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.6634 - val_masked_recall: 0.1666 - val_masked_f1: 0.2618\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1631 - masked_accuracy: 0.9350 - masked_precision: 0.5754 - masked_recall: 0.2248 - masked_f1: 0.3183 - val_loss: 0.1729 - val_masked_accuracy: 0.9315 - val_masked_precision: 0.6223 - val_masked_recall: 0.1869 - val_masked_f1: 0.2816\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1526 - masked_accuracy: 0.9382 - masked_precision: 0.6233 - masked_recall: 0.2831 - masked_f1: 0.3832 - val_loss: 0.1651 - val_masked_accuracy: 0.9335 - val_masked_precision: 0.6283 - val_masked_recall: 0.2530 - val_masked_f1: 0.3562\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1440 - masked_accuracy: 0.9399 - masked_precision: 0.6318 - masked_recall: 0.3292 - masked_f1: 0.4287 - val_loss: 0.1621 - val_masked_accuracy: 0.9342 - val_masked_precision: 0.6037 - val_masked_recall: 0.3281 - val_masked_f1: 0.4190\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1384 - masked_accuracy: 0.9410 - masked_precision: 0.6421 - masked_recall: 0.3727 - masked_f1: 0.4646 - val_loss: 0.1584 - val_masked_accuracy: 0.9342 - val_masked_precision: 0.6109 - val_masked_recall: 0.3086 - val_masked_f1: 0.4058\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1341 - masked_accuracy: 0.9440 - masked_precision: 0.6664 - masked_recall: 0.4004 - masked_f1: 0.4952 - val_loss: 0.1571 - val_masked_accuracy: 0.9339 - val_masked_precision: 0.5960 - val_masked_recall: 0.3383 - val_masked_f1: 0.4256\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1261 - masked_accuracy: 0.9449 - masked_precision: 0.6584 - masked_recall: 0.4276 - masked_f1: 0.5138 - val_loss: 0.1580 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.5864 - val_masked_recall: 0.3392 - val_masked_f1: 0.4232\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1211 - masked_accuracy: 0.9482 - masked_precision: 0.6949 - masked_recall: 0.4631 - masked_f1: 0.5528 - val_loss: 0.1543 - val_masked_accuracy: 0.9344 - val_masked_precision: 0.6007 - val_masked_recall: 0.3449 - val_masked_f1: 0.4326\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1156 - masked_accuracy: 0.9503 - masked_precision: 0.7090 - masked_recall: 0.4959 - masked_f1: 0.5799 - val_loss: 0.1565 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.6155 - val_masked_recall: 0.3464 - val_masked_f1: 0.4354\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1132 - masked_accuracy: 0.9508 - masked_precision: 0.7040 - masked_recall: 0.5150 - masked_f1: 0.5911 - val_loss: 0.1557 - val_masked_accuracy: 0.9352 - val_masked_precision: 0.5973 - val_masked_recall: 0.3877 - val_masked_f1: 0.4640\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1073 - masked_accuracy: 0.9532 - masked_precision: 0.7122 - masked_recall: 0.5582 - masked_f1: 0.6216 - val_loss: 0.1573 - val_masked_accuracy: 0.9343 - val_masked_precision: 0.5946 - val_masked_recall: 0.3641 - val_masked_f1: 0.4451\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1038 - masked_accuracy: 0.9554 - masked_precision: 0.7357 - masked_recall: 0.5610 - masked_f1: 0.6334 - val_loss: 0.1587 - val_masked_accuracy: 0.9350 - val_masked_precision: 0.6019 - val_masked_recall: 0.3593 - val_masked_f1: 0.4442\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.1004 - masked_accuracy: 0.9556 - masked_precision: 0.7328 - masked_recall: 0.5764 - masked_f1: 0.6438 - val_loss: 0.1592 - val_masked_accuracy: 0.9343 - val_masked_precision: 0.5884 - val_masked_recall: 0.3829 - val_masked_f1: 0.4564\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0982 - masked_accuracy: 0.9568 - masked_precision: 0.7402 - masked_recall: 0.5950 - masked_f1: 0.6568 - val_loss: 0.1591 - val_masked_accuracy: 0.9346 - val_masked_precision: 0.5895 - val_masked_recall: 0.3850 - val_masked_f1: 0.4597\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 790ms/step - loss: 0.4218 - masked_accuracy: 0.8432 - masked_precision: 0.1148 - masked_recall: 0.1575 - masked_f1: 0.1121 - val_loss: 0.3555 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.2515 - masked_accuracy: 0.9180 - masked_precision: 0.2141 - masked_recall: 0.0599 - masked_f1: 0.0914 - val_loss: 0.2396 - val_masked_accuracy: 0.9330 - val_masked_precision: 0.5833 - val_masked_recall: 0.0216 - val_masked_f1: 0.0414\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.2163 - masked_accuracy: 0.9256 - masked_precision: 0.3505 - masked_recall: 0.0753 - masked_f1: 0.1214 - val_loss: 0.2203 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6121 - val_masked_recall: 0.0548 - val_masked_f1: 0.0990\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1991 - masked_accuracy: 0.9292 - masked_precision: 0.4649 - masked_recall: 0.1116 - masked_f1: 0.1774 - val_loss: 0.2171 - val_masked_accuracy: 0.9342 - val_masked_precision: 0.5638 - val_masked_recall: 0.1288 - val_masked_f1: 0.2086\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.1831 - masked_accuracy: 0.9320 - masked_precision: 0.5169 - masked_recall: 0.1610 - masked_f1: 0.2428 - val_loss: 0.1753 - val_masked_accuracy: 0.9350 - val_masked_precision: 0.5940 - val_masked_recall: 0.1220 - val_masked_f1: 0.2010\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 49s 878ms/step - loss: 0.1685 - masked_accuracy: 0.9348 - masked_precision: 0.5806 - masked_recall: 0.2181 - masked_f1: 0.3123 - val_loss: 0.1871 - val_masked_accuracy: 0.9356 - val_masked_precision: 0.5847 - val_masked_recall: 0.1968 - val_masked_f1: 0.2931\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 45s 800ms/step - loss: 0.1567 - masked_accuracy: 0.9370 - masked_precision: 0.6012 - masked_recall: 0.2623 - masked_f1: 0.3622 - val_loss: 0.1652 - val_masked_accuracy: 0.9363 - val_masked_precision: 0.5850 - val_masked_recall: 0.2168 - val_masked_f1: 0.3155\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1489 - masked_accuracy: 0.9384 - masked_precision: 0.6167 - masked_recall: 0.3044 - masked_f1: 0.4040 - val_loss: 0.1612 - val_masked_accuracy: 0.9375 - val_masked_precision: 0.6013 - val_masked_recall: 0.2498 - val_masked_f1: 0.3511\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1414 - masked_accuracy: 0.9400 - masked_precision: 0.6147 - masked_recall: 0.3451 - masked_f1: 0.4379 - val_loss: 0.1604 - val_masked_accuracy: 0.9383 - val_masked_precision: 0.6064 - val_masked_recall: 0.2702 - val_masked_f1: 0.3707\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1314 - masked_accuracy: 0.9434 - masked_precision: 0.6504 - masked_recall: 0.4018 - masked_f1: 0.4919 - val_loss: 0.1544 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.6135 - val_masked_recall: 0.2811 - val_masked_f1: 0.3827\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1275 - masked_accuracy: 0.9456 - masked_precision: 0.6704 - masked_recall: 0.4441 - masked_f1: 0.5299 - val_loss: 0.1594 - val_masked_accuracy: 0.9389 - val_masked_precision: 0.5891 - val_masked_recall: 0.3164 - val_masked_f1: 0.4077\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1224 - masked_accuracy: 0.9481 - masked_precision: 0.6825 - masked_recall: 0.4765 - masked_f1: 0.5559 - val_loss: 0.1579 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.6020 - val_masked_recall: 0.3059 - val_masked_f1: 0.4026\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1161 - masked_accuracy: 0.9499 - masked_precision: 0.6928 - masked_recall: 0.4963 - masked_f1: 0.5743 - val_loss: 0.1574 - val_masked_accuracy: 0.9394 - val_masked_precision: 0.5915 - val_masked_recall: 0.3753 - val_masked_f1: 0.4567\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1121 - masked_accuracy: 0.9515 - masked_precision: 0.7070 - masked_recall: 0.5294 - masked_f1: 0.6014 - val_loss: 0.1579 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.5760 - val_masked_recall: 0.4368 - val_masked_f1: 0.4947\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1062 - masked_accuracy: 0.9536 - masked_precision: 0.7135 - masked_recall: 0.5630 - masked_f1: 0.6260 - val_loss: 0.1571 - val_masked_accuracy: 0.9380 - val_masked_precision: 0.5666 - val_masked_recall: 0.4072 - val_masked_f1: 0.4714\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1036 - masked_accuracy: 0.9547 - masked_precision: 0.7192 - masked_recall: 0.5754 - masked_f1: 0.6363 - val_loss: 0.1639 - val_masked_accuracy: 0.9388 - val_masked_precision: 0.5770 - val_masked_recall: 0.3853 - val_masked_f1: 0.4600\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1001 - masked_accuracy: 0.9555 - masked_precision: 0.7268 - masked_recall: 0.5839 - masked_f1: 0.6444 - val_loss: 0.1665 - val_masked_accuracy: 0.9383 - val_masked_precision: 0.5680 - val_masked_recall: 0.4090 - val_masked_f1: 0.4729\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0970 - masked_accuracy: 0.9589 - masked_precision: 0.7437 - masked_recall: 0.6292 - masked_f1: 0.6770 - val_loss: 0.1613 - val_masked_accuracy: 0.9392 - val_masked_precision: 0.5787 - val_masked_recall: 0.4005 - val_masked_f1: 0.4720\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 785ms/step - loss: 0.4390 - masked_accuracy: 0.8219 - masked_precision: 0.1265 - masked_recall: 0.1686 - masked_f1: 0.1260 - val_loss: 0.3262 - val_masked_accuracy: 0.9356 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.2559 - masked_accuracy: 0.9160 - masked_precision: 0.2539 - masked_recall: 0.0709 - masked_f1: 0.1083 - val_loss: 0.2360 - val_masked_accuracy: 0.9370 - val_masked_precision: 0.5865 - val_masked_recall: 0.0702 - val_masked_f1: 0.1249\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2221 - masked_accuracy: 0.9236 - masked_precision: 0.4088 - masked_recall: 0.0905 - masked_f1: 0.1458 - val_loss: 0.1964 - val_masked_accuracy: 0.9385 - val_masked_precision: 0.6959 - val_masked_recall: 0.0734 - val_masked_f1: 0.1321\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.2019 - masked_accuracy: 0.9267 - masked_precision: 0.4974 - masked_recall: 0.1223 - masked_f1: 0.1944 - val_loss: 0.1728 - val_masked_accuracy: 0.9395 - val_masked_precision: 0.6693 - val_masked_recall: 0.1186 - val_masked_f1: 0.2006\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1879 - masked_accuracy: 0.9287 - masked_precision: 0.5347 - masked_recall: 0.1548 - masked_f1: 0.2383 - val_loss: 0.1656 - val_masked_accuracy: 0.9402 - val_masked_precision: 0.7050 - val_masked_recall: 0.1260 - val_masked_f1: 0.2126\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1749 - masked_accuracy: 0.9314 - masked_precision: 0.5848 - masked_recall: 0.1981 - masked_f1: 0.2925 - val_loss: 0.1632 - val_masked_accuracy: 0.9419 - val_masked_precision: 0.6537 - val_masked_recall: 0.2087 - val_masked_f1: 0.3136\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1626 - masked_accuracy: 0.9339 - masked_precision: 0.6073 - masked_recall: 0.2588 - masked_f1: 0.3581 - val_loss: 0.1562 - val_masked_accuracy: 0.9419 - val_masked_precision: 0.6267 - val_masked_recall: 0.2410 - val_masked_f1: 0.3458\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1542 - masked_accuracy: 0.9363 - masked_precision: 0.6191 - masked_recall: 0.3090 - masked_f1: 0.4076 - val_loss: 0.1524 - val_masked_accuracy: 0.9427 - val_masked_precision: 0.6478 - val_masked_recall: 0.2480 - val_masked_f1: 0.3551\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1438 - masked_accuracy: 0.9397 - masked_precision: 0.6512 - masked_recall: 0.3725 - masked_f1: 0.4678 - val_loss: 0.1499 - val_masked_accuracy: 0.9416 - val_masked_precision: 0.5928 - val_masked_recall: 0.2869 - val_masked_f1: 0.3833\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1373 - masked_accuracy: 0.9400 - masked_precision: 0.6477 - masked_recall: 0.4020 - masked_f1: 0.4910 - val_loss: 0.1518 - val_masked_accuracy: 0.9445 - val_masked_precision: 0.6055 - val_masked_recall: 0.3844 - val_masked_f1: 0.4678\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.1309 - masked_accuracy: 0.9437 - masked_precision: 0.6723 - masked_recall: 0.4448 - masked_f1: 0.5313 - val_loss: 0.1465 - val_masked_accuracy: 0.9448 - val_masked_precision: 0.6052 - val_masked_recall: 0.4214 - val_masked_f1: 0.4929\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1230 - masked_accuracy: 0.9462 - masked_precision: 0.6767 - masked_recall: 0.4987 - masked_f1: 0.5705 - val_loss: 0.1486 - val_masked_accuracy: 0.9438 - val_masked_precision: 0.6023 - val_masked_recall: 0.3657 - val_masked_f1: 0.4504\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1161 - masked_accuracy: 0.9506 - masked_precision: 0.7160 - masked_recall: 0.5372 - masked_f1: 0.6100 - val_loss: 0.1463 - val_masked_accuracy: 0.9434 - val_masked_precision: 0.5819 - val_masked_recall: 0.4440 - val_masked_f1: 0.4997\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1114 - masked_accuracy: 0.9514 - masked_precision: 0.7068 - masked_recall: 0.5695 - masked_f1: 0.6279 - val_loss: 0.1476 - val_masked_accuracy: 0.9415 - val_masked_precision: 0.5512 - val_masked_recall: 0.4763 - val_masked_f1: 0.5082\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1055 - masked_accuracy: 0.9542 - masked_precision: 0.7308 - masked_recall: 0.5875 - masked_f1: 0.6483 - val_loss: 0.1500 - val_masked_accuracy: 0.9427 - val_masked_precision: 0.5755 - val_masked_recall: 0.4266 - val_masked_f1: 0.4875\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1016 - masked_accuracy: 0.9559 - masked_precision: 0.7389 - masked_recall: 0.6167 - masked_f1: 0.6702 - val_loss: 0.1469 - val_masked_accuracy: 0.9429 - val_masked_precision: 0.5734 - val_masked_recall: 0.4420 - val_masked_f1: 0.4965\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.3996 - masked_accuracy: 0.8559 - masked_precision: 0.1303 - masked_recall: 0.1423 - masked_f1: 0.1165 - val_loss: 0.2871 - val_masked_accuracy: 0.9241 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.2439 - masked_accuracy: 0.9217 - masked_precision: 0.2525 - masked_recall: 0.0542 - masked_f1: 0.0871 - val_loss: 0.2412 - val_masked_accuracy: 0.9256 - val_masked_precision: 0.6837 - val_masked_recall: 0.0299 - val_masked_f1: 0.0569\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.2094 - masked_accuracy: 0.9280 - masked_precision: 0.4088 - masked_recall: 0.0771 - masked_f1: 0.1273 - val_loss: 0.2184 - val_masked_accuracy: 0.9289 - val_masked_precision: 0.7262 - val_masked_recall: 0.1018 - val_masked_f1: 0.1777\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 43s 774ms/step - loss: 0.1924 - masked_accuracy: 0.9306 - masked_precision: 0.5018 - masked_recall: 0.1171 - masked_f1: 0.1878 - val_loss: 0.2083 - val_masked_accuracy: 0.9314 - val_masked_precision: 0.7554 - val_masked_recall: 0.1421 - val_masked_f1: 0.2376\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1771 - masked_accuracy: 0.9330 - masked_precision: 0.5565 - masked_recall: 0.1745 - masked_f1: 0.2618 - val_loss: 0.1822 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.6672 - val_masked_recall: 0.1987 - val_masked_f1: 0.3024\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 43s 778ms/step - loss: 0.1658 - masked_accuracy: 0.9351 - masked_precision: 0.5890 - masked_recall: 0.2294 - masked_f1: 0.3251 - val_loss: 0.1787 - val_masked_accuracy: 0.9326 - val_masked_precision: 0.6712 - val_masked_recall: 0.2200 - val_masked_f1: 0.3262\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1539 - masked_accuracy: 0.9378 - masked_precision: 0.6195 - masked_recall: 0.2814 - masked_f1: 0.3821 - val_loss: 0.1639 - val_masked_accuracy: 0.9328 - val_masked_precision: 0.6397 - val_masked_recall: 0.2674 - val_masked_f1: 0.3719\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1453 - masked_accuracy: 0.9399 - masked_precision: 0.6237 - masked_recall: 0.3363 - masked_f1: 0.4326 - val_loss: 0.1630 - val_masked_accuracy: 0.9352 - val_masked_precision: 0.6332 - val_masked_recall: 0.3407 - val_masked_f1: 0.4397\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1388 - masked_accuracy: 0.9422 - masked_precision: 0.6446 - masked_recall: 0.3835 - masked_f1: 0.4760 - val_loss: 0.1565 - val_masked_accuracy: 0.9373 - val_masked_precision: 0.6556 - val_masked_recall: 0.3579 - val_masked_f1: 0.4609\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1257 - masked_accuracy: 0.9477 - masked_precision: 0.6886 - masked_recall: 0.4560 - masked_f1: 0.5433 - val_loss: 0.1572 - val_masked_accuracy: 0.9361 - val_masked_precision: 0.6224 - val_masked_recall: 0.4021 - val_masked_f1: 0.4856\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1221 - masked_accuracy: 0.9480 - masked_precision: 0.6771 - masked_recall: 0.4774 - masked_f1: 0.5559 - val_loss: 0.1599 - val_masked_accuracy: 0.9356 - val_masked_precision: 0.6084 - val_masked_recall: 0.4235 - val_masked_f1: 0.4966\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1147 - masked_accuracy: 0.9509 - masked_precision: 0.7069 - masked_recall: 0.5133 - masked_f1: 0.5907 - val_loss: 0.1589 - val_masked_accuracy: 0.9358 - val_masked_precision: 0.6258 - val_masked_recall: 0.3866 - val_masked_f1: 0.4756\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 780ms/step - loss: 0.1095 - masked_accuracy: 0.9543 - masked_precision: 0.7263 - masked_recall: 0.5585 - masked_f1: 0.6271 - val_loss: 0.1629 - val_masked_accuracy: 0.9330 - val_masked_precision: 0.5799 - val_masked_recall: 0.4253 - val_masked_f1: 0.4877\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1044 - masked_accuracy: 0.9550 - masked_precision: 0.7312 - masked_recall: 0.5595 - masked_f1: 0.6315 - val_loss: 0.1627 - val_masked_accuracy: 0.9367 - val_masked_precision: 0.6223 - val_masked_recall: 0.4276 - val_masked_f1: 0.5030\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 767ms/step - loss: 0.5092 - masked_accuracy: 0.7775 - masked_precision: 0.1167 - masked_recall: 0.2959 - masked_f1: 0.1490 - val_loss: 0.3116 - val_masked_accuracy: 0.9316 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 43s 767ms/step - loss: 0.2501 - masked_accuracy: 0.9159 - masked_precision: 0.2279 - masked_recall: 0.0808 - masked_f1: 0.1146 - val_loss: 0.2620 - val_masked_accuracy: 0.9326 - val_masked_precision: 0.6258 - val_masked_recall: 0.0344 - val_masked_f1: 0.0649\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.2119 - masked_accuracy: 0.9269 - masked_precision: 0.3853 - masked_recall: 0.0928 - masked_f1: 0.1471 - val_loss: 0.2121 - val_masked_accuracy: 0.9337 - val_masked_precision: 0.5986 - val_masked_recall: 0.0978 - val_masked_f1: 0.1666\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 43s 769ms/step - loss: 0.1925 - masked_accuracy: 0.9293 - masked_precision: 0.4612 - masked_recall: 0.1104 - masked_f1: 0.1753 - val_loss: 0.1936 - val_masked_accuracy: 0.9344 - val_masked_precision: 0.6193 - val_masked_recall: 0.1035 - val_masked_f1: 0.1760\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1792 - masked_accuracy: 0.9315 - masked_precision: 0.5120 - masked_recall: 0.1563 - masked_f1: 0.2360 - val_loss: 0.1901 - val_masked_accuracy: 0.9345 - val_masked_precision: 0.6343 - val_masked_recall: 0.1049 - val_masked_f1: 0.1784\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 43s 767ms/step - loss: 0.1688 - masked_accuracy: 0.9341 - masked_precision: 0.5674 - masked_recall: 0.2025 - masked_f1: 0.2949 - val_loss: 0.1770 - val_masked_accuracy: 0.9366 - val_masked_precision: 0.6270 - val_masked_recall: 0.1881 - val_masked_f1: 0.2866\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 45s 806ms/step - loss: 0.1578 - masked_accuracy: 0.9360 - masked_precision: 0.5911 - masked_recall: 0.2538 - masked_f1: 0.3512 - val_loss: 0.1712 - val_masked_accuracy: 0.9359 - val_masked_precision: 0.5848 - val_masked_recall: 0.2279 - val_masked_f1: 0.3243\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 45s 813ms/step - loss: 0.1474 - masked_accuracy: 0.9398 - masked_precision: 0.6362 - masked_recall: 0.3125 - masked_f1: 0.4145 - val_loss: 0.1679 - val_masked_accuracy: 0.9375 - val_masked_precision: 0.6151 - val_masked_recall: 0.2497 - val_masked_f1: 0.3489\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1367 - masked_accuracy: 0.9434 - masked_precision: 0.6447 - masked_recall: 0.3924 - masked_f1: 0.4834 - val_loss: 0.1691 - val_masked_accuracy: 0.9364 - val_masked_precision: 0.5582 - val_masked_recall: 0.3502 - val_masked_f1: 0.4260\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1301 - masked_accuracy: 0.9449 - masked_precision: 0.6598 - masked_recall: 0.4235 - masked_f1: 0.5114 - val_loss: 0.1650 - val_masked_accuracy: 0.9367 - val_masked_precision: 0.5660 - val_masked_recall: 0.3252 - val_masked_f1: 0.4101\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1231 - masked_accuracy: 0.9483 - masked_precision: 0.6817 - masked_recall: 0.4772 - masked_f1: 0.5585 - val_loss: 0.1625 - val_masked_accuracy: 0.9382 - val_masked_precision: 0.5938 - val_masked_recall: 0.3158 - val_masked_f1: 0.4059\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 45s 797ms/step - loss: 0.1190 - masked_accuracy: 0.9496 - masked_precision: 0.6848 - masked_recall: 0.4994 - masked_f1: 0.5744 - val_loss: 0.1644 - val_masked_accuracy: 0.9359 - val_masked_precision: 0.5409 - val_masked_recall: 0.3786 - val_masked_f1: 0.4412\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 45s 799ms/step - loss: 0.1118 - masked_accuracy: 0.9515 - masked_precision: 0.7017 - masked_recall: 0.5245 - masked_f1: 0.5967 - val_loss: 0.1630 - val_masked_accuracy: 0.9355 - val_masked_precision: 0.5430 - val_masked_recall: 0.3835 - val_masked_f1: 0.4447\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 45s 795ms/step - loss: 0.1058 - masked_accuracy: 0.9543 - masked_precision: 0.7182 - masked_recall: 0.5661 - masked_f1: 0.6303 - val_loss: 0.1678 - val_masked_accuracy: 0.9376 - val_masked_precision: 0.5733 - val_masked_recall: 0.3357 - val_masked_f1: 0.4197\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 793ms/step - loss: 0.1012 - masked_accuracy: 0.9569 - masked_precision: 0.7390 - masked_recall: 0.5866 - masked_f1: 0.6510 - val_loss: 0.1698 - val_masked_accuracy: 0.9365 - val_masked_precision: 0.5545 - val_masked_recall: 0.3475 - val_masked_f1: 0.4237\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 794ms/step - loss: 0.0978 - masked_accuracy: 0.9584 - masked_precision: 0.7435 - masked_recall: 0.6146 - masked_f1: 0.6693 - val_loss: 0.1731 - val_masked_accuracy: 0.9345 - val_masked_precision: 0.5278 - val_masked_recall: 0.3537 - val_masked_f1: 0.4191\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 792ms/step - loss: 0.5101 - masked_accuracy: 0.7631 - masked_precision: 0.1036 - masked_recall: 0.2646 - masked_f1: 0.1341 - val_loss: 0.3196 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.2646 - masked_accuracy: 0.9155 - masked_precision: 0.1897 - masked_recall: 0.0571 - masked_f1: 0.0831 - val_loss: 0.2170 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.2228 - masked_accuracy: 0.9255 - masked_precision: 0.3386 - masked_recall: 0.0579 - masked_f1: 0.0972 - val_loss: 0.2056 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6456 - val_masked_recall: 0.0451 - val_masked_f1: 0.0836\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 792ms/step - loss: 0.2024 - masked_accuracy: 0.9289 - masked_precision: 0.4789 - masked_recall: 0.0919 - masked_f1: 0.1522 - val_loss: 0.1828 - val_masked_accuracy: 0.9337 - val_masked_precision: 0.6577 - val_masked_recall: 0.0643 - val_masked_f1: 0.1161\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 791ms/step - loss: 0.1873 - masked_accuracy: 0.9310 - masked_precision: 0.5240 - masked_recall: 0.1657 - masked_f1: 0.2483 - val_loss: 0.1769 - val_masked_accuracy: 0.9365 - val_masked_precision: 0.6580 - val_masked_recall: 0.1378 - val_masked_f1: 0.2256\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.1742 - masked_accuracy: 0.9344 - masked_precision: 0.6036 - masked_recall: 0.2161 - masked_f1: 0.3131 - val_loss: 0.1682 - val_masked_accuracy: 0.9373 - val_masked_precision: 0.6535 - val_masked_recall: 0.1730 - val_masked_f1: 0.2706\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1606 - masked_accuracy: 0.9351 - masked_precision: 0.6028 - masked_recall: 0.2446 - masked_f1: 0.3429 - val_loss: 0.1634 - val_masked_accuracy: 0.9380 - val_masked_precision: 0.6289 - val_masked_recall: 0.2319 - val_masked_f1: 0.3364\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1521 - masked_accuracy: 0.9387 - masked_precision: 0.6320 - masked_recall: 0.2985 - masked_f1: 0.4026 - val_loss: 0.1591 - val_masked_accuracy: 0.9374 - val_masked_precision: 0.6330 - val_masked_recall: 0.2132 - val_masked_f1: 0.3144\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1446 - masked_accuracy: 0.9405 - masked_precision: 0.6491 - masked_recall: 0.3342 - masked_f1: 0.4374 - val_loss: 0.1550 - val_masked_accuracy: 0.9388 - val_masked_precision: 0.6193 - val_masked_recall: 0.2799 - val_masked_f1: 0.3791\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1370 - masked_accuracy: 0.9431 - masked_precision: 0.6593 - masked_recall: 0.3933 - masked_f1: 0.4882 - val_loss: 0.1548 - val_masked_accuracy: 0.9393 - val_masked_precision: 0.6278 - val_masked_recall: 0.2749 - val_masked_f1: 0.3798\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1292 - masked_accuracy: 0.9443 - masked_precision: 0.6663 - masked_recall: 0.4315 - masked_f1: 0.5189 - val_loss: 0.1537 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.5937 - val_masked_recall: 0.3344 - val_masked_f1: 0.4239\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1230 - masked_accuracy: 0.9469 - masked_precision: 0.6833 - masked_recall: 0.4617 - masked_f1: 0.5469 - val_loss: 0.1538 - val_masked_accuracy: 0.9384 - val_masked_precision: 0.5731 - val_masked_recall: 0.3885 - val_masked_f1: 0.4577\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1180 - masked_accuracy: 0.9497 - masked_precision: 0.6974 - masked_recall: 0.5086 - masked_f1: 0.5838 - val_loss: 0.1537 - val_masked_accuracy: 0.9365 - val_masked_precision: 0.5552 - val_masked_recall: 0.3372 - val_masked_f1: 0.4155\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1142 - masked_accuracy: 0.9508 - masked_precision: 0.7133 - masked_recall: 0.5104 - masked_f1: 0.5905 - val_loss: 0.1552 - val_masked_accuracy: 0.9381 - val_masked_precision: 0.5736 - val_masked_recall: 0.3755 - val_masked_f1: 0.4478\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1113 - masked_accuracy: 0.9520 - masked_precision: 0.7089 - masked_recall: 0.5443 - masked_f1: 0.6122 - val_loss: 0.1596 - val_masked_accuracy: 0.9391 - val_masked_precision: 0.5889 - val_masked_recall: 0.3535 - val_masked_f1: 0.4371\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 45s 790ms/step - loss: 0.4256 - masked_accuracy: 0.8297 - masked_precision: 0.1082 - masked_recall: 0.1566 - masked_f1: 0.1058 - val_loss: 0.3452 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.2431 - masked_accuracy: 0.9220 - masked_precision: 0.2158 - masked_recall: 0.0421 - masked_f1: 0.0686 - val_loss: 0.2541 - val_masked_accuracy: 0.9300 - val_masked_precision: 0.0000e+00 - val_masked_recall: 0.0000e+00 - val_masked_f1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.2104 - masked_accuracy: 0.9271 - masked_precision: 0.3684 - masked_recall: 0.0511 - masked_f1: 0.0882 - val_loss: 0.2096 - val_masked_accuracy: 0.9336 - val_masked_precision: 0.7244 - val_masked_recall: 0.0752 - val_masked_f1: 0.1349\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1910 - masked_accuracy: 0.9296 - masked_precision: 0.4848 - masked_recall: 0.1077 - masked_f1: 0.1737 - val_loss: 0.2072 - val_masked_accuracy: 0.9346 - val_masked_precision: 0.6722 - val_masked_recall: 0.1298 - val_masked_f1: 0.2148\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1749 - masked_accuracy: 0.9321 - masked_precision: 0.5327 - masked_recall: 0.1659 - masked_f1: 0.2488 - val_loss: 0.1665 - val_masked_accuracy: 0.9366 - val_masked_precision: 0.6746 - val_masked_recall: 0.1825 - val_masked_f1: 0.2824\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1576 - masked_accuracy: 0.9357 - masked_precision: 0.5942 - masked_recall: 0.2592 - masked_f1: 0.3572 - val_loss: 0.1628 - val_masked_accuracy: 0.9377 - val_masked_precision: 0.6383 - val_masked_recall: 0.2642 - val_masked_f1: 0.3637\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1481 - masked_accuracy: 0.9386 - masked_precision: 0.6175 - masked_recall: 0.3311 - masked_f1: 0.4250 - val_loss: 0.1560 - val_masked_accuracy: 0.9377 - val_masked_precision: 0.6116 - val_masked_recall: 0.3088 - val_masked_f1: 0.4010\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.1387 - masked_accuracy: 0.9411 - masked_precision: 0.6411 - masked_recall: 0.3598 - masked_f1: 0.4553 - val_loss: 0.1541 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.6428 - val_masked_recall: 0.3001 - val_masked_f1: 0.3966\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1287 - masked_accuracy: 0.9449 - masked_precision: 0.6647 - masked_recall: 0.4271 - masked_f1: 0.5161 - val_loss: 0.1530 - val_masked_accuracy: 0.9386 - val_masked_precision: 0.6052 - val_masked_recall: 0.3764 - val_masked_f1: 0.4539\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 787ms/step - loss: 0.1250 - masked_accuracy: 0.9470 - masked_precision: 0.6783 - masked_recall: 0.4654 - masked_f1: 0.5464 - val_loss: 0.1498 - val_masked_accuracy: 0.9404 - val_masked_precision: 0.6328 - val_masked_recall: 0.3760 - val_masked_f1: 0.4600\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.1190 - masked_accuracy: 0.9481 - masked_precision: 0.6807 - masked_recall: 0.4808 - masked_f1: 0.5594 - val_loss: 0.1530 - val_masked_accuracy: 0.9411 - val_masked_precision: 0.6304 - val_masked_recall: 0.3911 - val_masked_f1: 0.4728\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1115 - masked_accuracy: 0.9515 - masked_precision: 0.6982 - masked_recall: 0.5321 - masked_f1: 0.6010 - val_loss: 0.1557 - val_masked_accuracy: 0.9394 - val_masked_precision: 0.6060 - val_masked_recall: 0.3832 - val_masked_f1: 0.4628\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1083 - masked_accuracy: 0.9525 - masked_precision: 0.7167 - masked_recall: 0.5400 - masked_f1: 0.6116 - val_loss: 0.1551 - val_masked_accuracy: 0.9397 - val_masked_precision: 0.5988 - val_masked_recall: 0.4244 - val_masked_f1: 0.4875\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1036 - masked_accuracy: 0.9555 - masked_precision: 0.7276 - masked_recall: 0.5858 - masked_f1: 0.6464 - val_loss: 0.1629 - val_masked_accuracy: 0.9398 - val_masked_precision: 0.6122 - val_masked_recall: 0.3992 - val_masked_f1: 0.4728\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0991 - masked_accuracy: 0.9570 - masked_precision: 0.7437 - masked_recall: 0.5950 - masked_f1: 0.6577 - val_loss: 0.1682 - val_masked_accuracy: 0.9398 - val_masked_precision: 0.6213 - val_masked_recall: 0.3707 - val_masked_f1: 0.4515\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.0958 - masked_accuracy: 0.9585 - masked_precision: 0.7479 - masked_recall: 0.6205 - masked_f1: 0.6752 - val_loss: 0.1621 - val_masked_accuracy: 0.9413 - val_masked_precision: 0.6141 - val_masked_recall: 0.4555 - val_masked_f1: 0.5148\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0922 - masked_accuracy: 0.9599 - masked_precision: 0.7555 - masked_recall: 0.6329 - masked_f1: 0.6865 - val_loss: 0.1586 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.5845 - val_masked_recall: 0.4565 - val_masked_f1: 0.5031\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 44s 786ms/step - loss: 0.0887 - masked_accuracy: 0.9605 - masked_precision: 0.7565 - masked_recall: 0.6496 - masked_f1: 0.6964 - val_loss: 0.1736 - val_masked_accuracy: 0.9390 - val_masked_precision: 0.6047 - val_masked_recall: 0.3871 - val_masked_f1: 0.4591\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.0860 - masked_accuracy: 0.9630 - masked_precision: 0.7752 - masked_recall: 0.6691 - masked_f1: 0.7155 - val_loss: 0.1703 - val_masked_accuracy: 0.9398 - val_masked_precision: 0.5984 - val_masked_recall: 0.4384 - val_masked_f1: 0.4965\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 44s 788ms/step - loss: 0.0847 - masked_accuracy: 0.9636 - masked_precision: 0.7770 - masked_recall: 0.6832 - masked_f1: 0.7236 - val_loss: 0.1700 - val_masked_accuracy: 0.9377 - val_masked_precision: 0.5692 - val_masked_recall: 0.4672 - val_masked_f1: 0.5049\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 44s 785ms/step - loss: 0.0809 - masked_accuracy: 0.9652 - masked_precision: 0.7876 - masked_recall: 0.6941 - masked_f1: 0.7357 - val_loss: 0.1716 - val_masked_accuracy: 0.9387 - val_masked_precision: 0.5850 - val_masked_recall: 0.4358 - val_masked_f1: 0.4907\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.4107 - masked_accuracy: 0.8474 - masked_precision: 0.1040 - masked_recall: 0.1311 - masked_f1: 0.0990 - val_loss: 0.3707 - val_masked_accuracy: 0.9232 - val_masked_precision: 0.0714 - val_masked_recall: 0.0012 - val_masked_f1: 0.0023\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 43s 778ms/step - loss: 0.2397 - masked_accuracy: 0.9203 - masked_precision: 0.2291 - masked_recall: 0.0642 - masked_f1: 0.0985 - val_loss: 0.2217 - val_masked_accuracy: 0.9233 - val_masked_precision: 0.1429 - val_masked_recall: 0.0044 - val_masked_f1: 0.0086\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.2074 - masked_accuracy: 0.9271 - masked_precision: 0.3614 - masked_recall: 0.0777 - masked_f1: 0.1257 - val_loss: 0.2293 - val_masked_accuracy: 0.9275 - val_masked_precision: 0.6485 - val_masked_recall: 0.1322 - val_masked_f1: 0.2180\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1872 - masked_accuracy: 0.9300 - masked_precision: 0.4854 - masked_recall: 0.1431 - masked_f1: 0.2171 - val_loss: 0.2008 - val_masked_accuracy: 0.9291 - val_masked_precision: 0.6521 - val_masked_recall: 0.1745 - val_masked_f1: 0.2735\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 44s 783ms/step - loss: 0.1699 - masked_accuracy: 0.9333 - masked_precision: 0.5369 - masked_recall: 0.2042 - masked_f1: 0.2924 - val_loss: 0.1798 - val_masked_accuracy: 0.9308 - val_masked_precision: 0.6432 - val_masked_recall: 0.2260 - val_masked_f1: 0.3329\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1587 - masked_accuracy: 0.9359 - masked_precision: 0.5840 - masked_recall: 0.2511 - masked_f1: 0.3467 - val_loss: 0.1727 - val_masked_accuracy: 0.9305 - val_masked_precision: 0.6052 - val_masked_recall: 0.2887 - val_masked_f1: 0.3882\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1471 - masked_accuracy: 0.9397 - masked_precision: 0.6222 - masked_recall: 0.3309 - masked_f1: 0.4278 - val_loss: 0.1685 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.6448 - val_masked_recall: 0.2705 - val_masked_f1: 0.3787\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 44s 782ms/step - loss: 0.1419 - masked_accuracy: 0.9408 - masked_precision: 0.6220 - masked_recall: 0.3574 - masked_f1: 0.4487 - val_loss: 0.1652 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6402 - val_masked_recall: 0.3070 - val_masked_f1: 0.4126\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.1311 - masked_accuracy: 0.9450 - masked_precision: 0.6567 - masked_recall: 0.4198 - masked_f1: 0.5053 - val_loss: 0.1662 - val_masked_accuracy: 0.9319 - val_masked_precision: 0.5971 - val_masked_recall: 0.3756 - val_masked_f1: 0.4578\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 44s 778ms/step - loss: 0.1233 - masked_accuracy: 0.9472 - masked_precision: 0.6704 - masked_recall: 0.4528 - masked_f1: 0.5363 - val_loss: 0.1633 - val_masked_accuracy: 0.9331 - val_masked_precision: 0.6114 - val_masked_recall: 0.3847 - val_masked_f1: 0.4677\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 44s 779ms/step - loss: 0.1181 - masked_accuracy: 0.9494 - masked_precision: 0.6903 - masked_recall: 0.4997 - masked_f1: 0.5755 - val_loss: 0.1646 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.6091 - val_masked_recall: 0.3946 - val_masked_f1: 0.4752\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 44s 784ms/step - loss: 0.1122 - masked_accuracy: 0.9525 - masked_precision: 0.7050 - masked_recall: 0.5354 - masked_f1: 0.6056 - val_loss: 0.1633 - val_masked_accuracy: 0.9336 - val_masked_precision: 0.5946 - val_masked_recall: 0.4458 - val_masked_f1: 0.5063\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 44s 789ms/step - loss: 0.1070 - masked_accuracy: 0.9539 - masked_precision: 0.7130 - masked_recall: 0.5558 - masked_f1: 0.6201 - val_loss: 0.1672 - val_masked_accuracy: 0.9312 - val_masked_precision: 0.5774 - val_masked_recall: 0.4210 - val_masked_f1: 0.4833\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 43s 775ms/step - loss: 0.1037 - masked_accuracy: 0.9556 - masked_precision: 0.7251 - masked_recall: 0.5731 - masked_f1: 0.6373 - val_loss: 0.1668 - val_masked_accuracy: 0.9322 - val_masked_precision: 0.5820 - val_masked_recall: 0.4443 - val_masked_f1: 0.5010\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 43s 776ms/step - loss: 0.0991 - masked_accuracy: 0.9569 - masked_precision: 0.7397 - masked_recall: 0.5940 - masked_f1: 0.6556 - val_loss: 0.1670 - val_masked_accuracy: 0.9324 - val_masked_precision: 0.5862 - val_masked_recall: 0.4347 - val_masked_f1: 0.4961\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0943 - masked_accuracy: 0.9588 - masked_precision: 0.7441 - masked_recall: 0.6188 - masked_f1: 0.6736 - val_loss: 0.1780 - val_masked_accuracy: 0.9318 - val_masked_precision: 0.5796 - val_masked_recall: 0.4455 - val_masked_f1: 0.5007\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 44s 781ms/step - loss: 0.0893 - masked_accuracy: 0.9619 - masked_precision: 0.7628 - masked_recall: 0.6517 - masked_f1: 0.7004 - val_loss: 0.1725 - val_masked_accuracy: 0.9333 - val_masked_precision: 0.5906 - val_masked_recall: 0.4495 - val_masked_f1: 0.5085\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "0.7998409191767375 0.015431550768808436 0.8871670722961426 0.022071691703041272 0.387681523958842 0.04302660946810271 0.5321684896945953 0.0419995517545934\n"
     ]
    }
   ],
   "source": [
    "accuracyresultlist=[]\n",
    "precisionresultlist=[]\n",
    "recallresultlist=[]\n",
    "aoclist=[]\n",
    "flist=[]\n",
    "for train_index, test_index in kfold.split(X, Y):\n",
    "    # split data into train/test sets\n",
    "    x_train_tfidf = X.iloc[train_index]\n",
    "    y_train_tfidf = Y.iloc[train_index]\n",
    "    x_test_tfidf = X.iloc[test_index]\n",
    "    y_test_tfidf = Y.iloc[test_index]\n",
    "    #y_train_tfidf=y_train_tfidf.fillna(0)\n",
    "    trainX, validateX, trainyp, validatey = train_test_split(x_train_tfidf, y_train_tfidf, test_size=0.2, random_state=1989)\n",
    "    #print(trainyp.shape)\n",
    "    trainyp=trainyp.reset_index(drop=True)\n",
    "    trainX=trainX.reset_index(drop=True)\n",
    "    validatey=validatey.reset_index(drop=True)\n",
    "    validateX=validateX.reset_index(drop=True)\n",
    "    #trainyp.to_csv('Test_before.csv')\n",
    "    #trainy, labelweight =getLikelihood(trainyp,labels)\n",
    "    #trainy.to_csv('Test_after.csv')\n",
    "    #print(labelweight.shape)\n",
    "    trainy=trainyp.fillna(0)\n",
    "    validatey=validatey.fillna(0)\n",
    "    Testy=pd.DataFrame(y_test_tfidf).fillna(-1)\n",
    "\n",
    "    trainy=trainy.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [0,0,1,1])\n",
    "    validatey=validatey.replace(['Not defined','Susceptible-dose dependent', 0.5,'0.5'], [0,0,1,1])\n",
    "    Testy=Testy.replace(['Not defined','Susceptible-dose dependent',0.5,'0.5'], [-1,-1,-1,-1])\n",
    "    #print(trainy)\n",
    "    train_labels = np.array(trainy).astype(np.float32)\n",
    "    val_labels = np.array(validatey).astype(np.float32)\n",
    "    test_labels = np.array(Testy).astype(np.float32)\n",
    "    train_features = np.array(trainX).astype(np.float32)\n",
    "    val_features = np.array(validateX).astype(np.float32)\n",
    "    test_features = np.array(x_test_tfidf).astype(np.float32)\n",
    "    #weight=calculating_class_weights_3(trainy.values)\n",
    "    #weight2=weight[:,1:3]\n",
    "    input_dimension = 1 \n",
    "    train_sample_size = trainX.shape[0] # number of samples in train set\n",
    "    test_sample_size = x_test_tfidf.shape[0] # number of samples in train set\n",
    "    valid_sample_size = validateX.shape[0] # number of samples in train set\n",
    "    time_steps  = x_test_tfidf.shape[1] # number of features in train set\n",
    "\n",
    "    test_data_reshaped = test_features.reshape(test_sample_size,time_steps,input_dimension)\n",
    "    train_data_reshaped = trainX.values.reshape(train_sample_size,time_steps,input_dimension)\n",
    "    val_data_reshaped = validateX.values.reshape(valid_sample_size,time_steps,input_dimension)\n",
    "    \n",
    "    model = build_conv1D_model(train_data_reshaped)\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), ###RMS\n",
    "      loss= tf.keras.losses.binary_crossentropy, ###Categoriacal\n",
    "      metrics=METRICS)\n",
    "    #model.summary()\n",
    "    baseline_history = model.fit(\n",
    "        train_data_reshaped,\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        #class_weight=weight2,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(val_data_reshaped, val_labels))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    results = model.evaluate(test_data_reshaped, test_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "    accuracyresultlist.append(results[1])\n",
    "    precisionresultlist.append(results[2])\n",
    "    recallresultlist.append(results[3])\n",
    "    flist.append(results[4])\n",
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998409191767375 0.015431550768808436 0.8871670722961426 0.022071691703041272 0.387681523958842 0.04302660946810271 0.5321684896945953 0.0419995517545934\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracyresultlist),np.std(accuracyresultlist), np.mean(precisionresultlist),np.std(precisionresultlist), np.mean(recallresultlist), np.std(recallresultlist), np.mean(flist), np.std(flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(baseline_history, ['Loss','Accuracy'], 0,['loss','masked_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e02cb13512e3e24f59b668a1223e9284df78e57572e82b523044cd80d2e30e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
